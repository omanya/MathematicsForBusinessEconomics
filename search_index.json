[["index.html", "Mathematics for Business and Economics Chapter 1 Introduction Why do we need the mathematics for business and economics? Example: utility maximization", " Mathematics for Business and Economics Maria Osipenko 2024-08-30 Chapter 1 Introduction Some comments before we start Consider the following precepts for achieving a mathematical mindset, courtesy of Jo Boaler of youcubed at Stanford University: Everyone Can Learn Math to the Highest Levels. Everyone can reach the highest levels they want to, with hard work. Mistakes are Valuable. Mistakes grow your brain! It is good to struggle and make mistakes. Questions are Really Important. Always ask questions, always answer questions. Ask yourself: why does that make sense? Math is about Creativity and Making Sense. Math is a very creative subject that is, at its core, about visualizing patterns and creating solution paths that others can see, discuss and critique. Math is about Connections and Communicating. Math is a connected subject, and a form of communication. Represent math in different forms; e.g., words, a picture, a graph, an equation; and link them. Math Class is about Learning, Not Performing. Math is a growth subject. It takes time to learn and it is all about effort. Why do we need the mathematics for business and economics? Your Thoughts A generic answer üòÑ Business mathematics enables us to solve complex economic problems using mathematical methods. Many economic variables are quantitative in nature (prices, quantities,‚Ä¶). Economic models capture the relationships between these variables. Mathematics has the accuracy, precision and capacity to grasp complex systems. Here are some examples of how mathematical models are used to explain business relationships: maximizing sales, key performance indicators, break-even point, optimization of operational processes in production and warehousing. Example: utility maximization Here is an example of a possible question: Example 1.1 (Utility maximization) Student Alex likes to eat donuts and coffee. A donut costs \\(P_x = 2 ~Euro\\). A cup of coffee costs \\(P_y = 4~ Euro\\). Alex‚Äôs budget for donuts and coffee is \\(200~Euros\\) per month. Questions: How many donuts and how many cups of coffee will Alex ideally consume? If Alex‚Äôs budget increases, what will he spend an extra dollar on? What are the benefits of a budget increase of one euro/¬†an extra donut/¬†an extra cup of coffee? To describe the problem mathematically we need: A relation that ensures that Alex sticks to his budget \\(\\leadsto\\) budget restriction. A concept that describes the enjoyment of the consumed amounts of donuts and coffee \\(\\leadsto\\) utility function. Example 1.2 (Budget constraint) Alex can spend a maximum of 200 euros per month on donuts and coffee. If he exhausts his budget, he can make the following budget splits, for example: If Alex skips coffee, he can eat 100 donuts. If he skips donuts, he can Drink 50 cups of coffee. Alternatively he can choose 50 donuts and 25 cups of coffee. If Alex exhausts his budget, the following applies: \\[x \\cdot P_X + y \\cdot P_Y = Budget.\\] ‚Äì Inserting \\(P_X = 2\\) and \\(P_Y = 4\\) yields: \\[2x + 4y = 200\\] ‚Äì The number \\(y\\) of the coffee cups can be expressed as a function of the number \\(x\\) of the donuts consumed: \\[y(x)=\\frac{200-2x}{4}=\\frac{200}{4}-\\frac 12 x\\] or \\[y(x)=50 -0.5 x\\] This is called the budget constraint. The budget constraint connects all the points that represent all ‚Äúfinanceable‚Äù combinations of donat and coffee quantities if the budget is exhausted. Note that the slope of the budget line is \\(-\\frac 12\\) in the example. In the In general, the negative slope results from the quotient of the prices: \\(-\\frac{P_X}{P_Y}\\). Frage: \\((20;50)\\) \\((90;10)\\) \\((50;40)\\) \\((70;50)\\) Submit Example 1.3 (Utility function) Alex ponders the benefits of consuming different amounts of donuts and coffee: Alex‚Äôs first consideration suggests that Alex‚Äôs utility function is represented by an increasing function of the quantities consumed. That‚Äôs because the enjoyment level increases with more donuts and more coffee. The second consideration means that although the benefit increases with the amounts, the increase becomes progressively smaller as the amounts are increased. (You are certainly familiar with this effect from your own consumption: You are no longer so happy when you have already consumed a lot of the same thing.) This effect is called diminishing marginal utility A concrete functional form such as \\[U(x,y) = \\sqrt{x} + \\sqrt{y}\\] allows the utility level to be represented as a number, which makes it easier to compare different consumption options. In this the utility is: since \\(U(1;1)=\\sqrt{1} + \\sqrt{1} = 2\\),since ¬†\\(U(4;4)=\\sqrt{4} + \\sqrt{4} = 4\\) andsince(U(4;1)= = 3). If donuts and coffee cups are divisible, one can imagine consuming all possible (and not just integer) amounts, e.g.¬†\\(x=3.2\\) and \\(y=2.4\\), or \\(U( 3.2;2.4) = \\sqrt{3.2} + \\sqrt{2.4} = 3.338\\). Submit Example 1.1 (Utility maximization) Alex strives for maximum utility while adhering to budget restrictions Maximization problem: \\[\\max_{x,y} U(x,y) = \\max_{x,y} (\\sqrt x + \\sqrt y) \\] under the restriction: \\[2x + 4y = 200\\] Solution By reshaping the budget constraint to: \\(y (x) = (100 ‚àí x)/2\\) \\[\\max_{x,y} U(x,y (x)) = \\max_x (\\sqrt x + \\sqrt{(100 ‚àí x)/2}.\\] Derivative: \\[U^\\prime (x,y (x)) = \\frac 1{2\\sqrt x} - \\frac 1{4\\sqrt{(100-x)/2}}.\\] Equate to \\(0\\); Solving for \\(x\\) yields \\(x = \\frac{200}3 = 66.6667\\) , \\(y (\\frac{200}3) = \\frac {50}3 = 16.6667\\). Check that there is a maximum: \\[U^{\\prime\\prime} = -\\frac 1{4x^{3/2}} - \\frac 1{8\\left\\{(100 - x)/2\\right\\}^{3/2}} \\stackrel{x=\\frac {200}3}{=} -0.0023&lt;0\\] If reshaping the budget restriction is not possible \\(\\rightarrow\\) method of Lagrange. Example 1.4 (Marginal Utility) The marginal utility associated with the additional consumption of a donut is given by the partial derivative with respect to \\(x\\): \\[\\frac{\\partial U(x,y)}{\\partial x} = \\frac\\partial{\\partial x}(\\sqrt x + \\sqrt y) = \\frac 1{2\\sqrt x}\\] Analogous, marginal utility for espresso: \\[\\frac{\\partial U(x,y)}{\\partial y} = \\frac 1{2\\sqrt y}\\] "],["the-basics.html", "Chapter 2 The basics 2.1 Sets and Number Sets 2.2 Number sets 2.3 Point sets in \\(\\mathbb R^n\\) 2.4 Functions 2.5 Power, exponential and logarithmic functions", " Chapter 2 The basics 2.1 Sets and Number Sets In our utility maximization example, we considered which consumption options (\\(x=\\# donuts\\) and \\(y= \\# coffee\\)) that the student Alex can afford. As we have seen, there are several financeable consumption combinations \\((x,y)\\) for Alex to choose from. It makes sense to consider those consumption options that meet certain criteria as a set. Alex will maximize his utility by selecting the consumption combination that brings him the maximum utility from this set of consumption bundles available to him. Doch was ist eine Menge und wie kann man sie definieren? Definition 2.1 (Sets) A set is a collection of objects, called elements. The set can be either a finite collection or an infinite collection of objects. The set can be specified through: listing its elements using ‚Äù {‚Äù and ‚Äù }‚Äú, with the elements separated by commas (explicit representation): \\[M=\\{x_1,x_2,\\ldots\\},\\] giving a property that characterizes the elements (implicit representation): \\[M=\\{x:P(x)\\}\\] Example 2.1 (The set of even numbers between 1 and 11) The set of even numbers between 1 and 11 can be specified via an explicit representation: \\[M=\\{2,4,6,8,10\\}\\] or via an implicit representation: \\[M=\\{x:x \\text{ is an even number between 1 and 11}\\}\\] If the object \\(x\\) is an element of the set \\(M\\), we write \\(x\\in M\\), otherwise \\(x\\not\\in M\\). In the case of Alex‚Äôs budget set, the implicit representation is used because writing down all the possible combinations would take too long. Example 2.2 (Alex' consumption set) Given enough time, Alex can consume any amount (positive or zero) of coffee and donuts. Its consumption amount can then be written as follows: \\(C=\\{(x,y):x\\geq 0,y\\geq 0\\}\\) The set of consumption bundles with coffee and donuts that Alex can reach is defined as: \\(B=\\{(x,y):xP_X+yP_Y\\leq Budget\\}\\) Then for \\(Budget=200\\), \\(P_X=2\\) and \\(P_Y=4\\) holds: \\[(30;10)\\in B\\] \\[(99;1)\\not \\in B \\] Now let‚Äôs say Alex wants to limit his consumption of sweet and not-so-healthy donuts. He doesn‚Äôt want to consume more than 30 donuts per month. Does this restriction change his consumption set? The set relations help us to find the answer. Definition 2.2 (Subsets and equal sets) If all elements of a set \\(X\\) are also elements of a set \\(Y\\), then \\(X\\) is a subset of \\(Y\\), formally: \\[X\\subseteq Y\\] Furthermore, if not all elements of \\(Y\\) are in \\(X\\), then \\(X\\) is a proper subset of \\(Y\\), formally: \\[X\\subset Y\\] Two sets \\(X\\) and \\(Y\\) are equal if they contain the same elements, formally: \\[X=Y\\] That is: \\(X=Y\\Leftrightarrow X\\subseteq Y\\text{ und } Y\\subseteq X\\). Example 2.3 (Sets and their subsets) Let \\[\\mathbb Z_+ = \\{x:x \\text{ ist eine positive ganze Zahl},\\] \\[A=\\{x\\in \\mathbb Z_+:x\\leq 11\\}=\\{1,2,3,4,5,6,7,8,9,10,11\\}\\] Then, it holds: \\(A\\subseteq \\mathbb Z_+\\) and \\(A\\subset \\mathbb Z_+\\). Now back to Alex and his self-imposed condition of no more than \\(30\\) eat donuts a month. Example 2.3 (Alex's consumption set under the condition) His new consumption set is: \\[C_{new} = \\{(x;y):0\\leq x\\leq 30,y\\geq 0\\}\\] It holds: \\(C_{new}\\subset C\\). 2.1.1 Operations on Sets Alex has another problem: his favorite donuts have become more expensive and cost now \\(5\\) euros. Nevertheless, there is good news also - a cup of coffee in the canteen costs only \\(1\\) euro. This changes Alex‚Äôs budget constraint. How can one compare the new situation with the situation before? This is where the set operations help us. We define the universal set, here expressed with \\(U\\). This is the largest set we work with in any given context. The empty set or null set contains no elements, this is noted as \\(\\emptyset\\). For example, it makes sense for Alex‚Äôs decision to set the hypothetical consumption quantity \\(C=\\{(x,y):x\\geq 0,y\\geq 0\\}\\) to be the universal quantity. If Alex‚Äôs budget is \\(0\\) Euro, then his budget set is an empty set. Definition 2.3 (Intersections and unions of sets) The intersection of two sets \\(X\\) and \\(Y\\) is the set whose elements are in both \\(X\\) and \\(Y\\); formally: \\(X\\cap Y=\\{x:x\\in X \\text{ and } x\\in Y\\}\\) If \\(X\\cap Y=\\emptyset\\), then \\(X\\) and \\(Y\\) are disjoint. The union of two sets \\(X\\) and \\(Y\\) is the set whose elements are contained in at least one of the sets \\(X\\) and \\(Y\\); formally: \\(X\\cup Y=\\{x:x\\in X \\text{ oder } x\\in Y\\}\\) Exercise 2.1 (Set operations 1) Let \\(\\mathbb Z_+\\) be the universal set, furthermore \\(X=\\{x\\in \\mathbb Z_+:x\\leq 20 \\text{ and } x/2\\in \\mathbb Z_+\\}\\), as well as \\(Y=\\{x\\in \\mathbb Z_+:10\\leq x\\leq 24 \\text{ and } x/2\\in \\mathbb Z_+\\}\\) What are \\(X\\cap Y\\) and \\(X\\cup Y\\)? What are \\(X\\cap \\mathbb Z_+, X\\cup \\mathbb Z_+, Y\\cap \\mathbb Z_+\\text{ and } Y\\cup\\mathbb Z_+\\)? Answer \\(X\\cap Y = \\{x\\in Z_+: 10\\leq x\\leq 20\\text{ and } x/2\\in Z_+\\}\\), \\(X\\cup Y = \\{x\\in Z_+: x\\leq 24\\text{ and } x/2\\in Z_+\\}\\), \\(X \\cap Z_+=X\\),\\(X \\cup Z_+=Z_+\\), \\(Y \\cap Z_+=Y\\)and \\(Y \\cup Z_+=Z_+\\) In addition to the intersection and union of two sets, complement formation and set difference are often required. Definition 2.4 (Complement and difference) The complement of a set \\(X\\) is the set of all elements contained in \\(U\\) but not in \\(X\\); Notation: \\(\\overline X\\) or \\(X^c\\). \\(\\overline X=\\{x\\in U:x\\not \\in X\\}\\) The difference \\(X\\setminus Y\\), sometimes also \\(X‚àíY\\), is the set of all elements in \\(X\\) that are not contained in \\(Y\\): \\(X\\setminus Y=\\{x\\in U:x\\in X \\text{ und } x\\not\\in Y\\}\\) Exercise 2.2 (Set operations 2) Show via Venn diagram that \\(X\\setminus Y=X\\cap\\overline Y\\) Answer See alsoVisualizing sets with Geogebra Let \\(\\mathbb Z_+, X, Y\\) be as in the previous exercise. What are the complements of \\(\\mathbb Z_+, X, Y\\) What is \\(\\overline{X\\cap Y}\\)? What is \\(\\overline{X\\cup Y}\\)? Answer \\(\\overline{Z_+}=\\emptyset\\), \\(\\overline{X}=\\{x\\in Z_+: x\\geq 21 \\text{ oder } x \\text{ odd }\\}\\), \\(\\overline{Y}=\\{x\\in Z_+: x\\leq 9 \\text{ oder }x\\geq 25 \\text{ or } x \\text{ odd }\\}\\) \\(\\overline{X\\cap Y} = \\{x\\in Z_+: x\\leq 9 \\text{ or }x\\geq 20 \\text{ or } x \\text{ odd }\\}\\), \\(\\overline{X\\cup Y}=\\{x\\in Z_+: x\\geq 25 \\text{ or } x \\text{ odd }\\}\\) Let \\(\\mathbb Z_+, X, Y\\) be as in the previous exercise. What is the difference \\(X\\setminus Y\\)? What is \\(Y\\setminus X\\)? Answer \\(X\\setminus Y =\\{x\\in \\mathbb Z_+, x &lt; 10 \\text{ und } x/2\\in\\mathbb Z_+\\}\\) \\(Y\\setminus X = \\{x\\in \\mathbb Z_+: 20&lt;x\\leq 24 \\text{ und } x/2\\in \\mathbb Z_+\\}\\) Exercise 2.3 (Alex's consumption set and budget) Alex‚Äôs consumption set is given as \\(C=\\{(x_1,x_2):x_1\\geq 0,x_2\\geq 0\\}\\). The corresponding budget constraint set for Alex is \\(B=\\{(x_1,x_2):p_1x_1+p_2x_2\\leq M\\}\\), where \\(x_1,x_2\\) denotes the quantities of goods, \\(p_1,p_2\\) the prices and \\(M\\) the income. Illustrate the following quantities in a diagram: \\(B,C\\) \\(B\\cap C\\) Interpret each of the sets. Answer 2.2 Number sets Definition 2.4 (Some number sets) The set of natural numbers is \\(\\mathbb N= \\mathbb Z_+ = \\{1,2,3,...\\}\\) The set of integers is \\(\\mathbb Z = \\{...,‚àí3,‚àí2,‚àí1,0,1,2,3,...\\}\\) The set of rational numbers is \\(\\mathbb Q=\\{a,b:a\\in \\mathbb Z, b\\in \\mathbb Z\\setminus\\{0\\}\\}\\) Properties: The following applies: \\(\\mathbb{N}\\subset \\mathbb{Z}\\subset \\mathbb{Q}\\). The set \\(\\mathbb {N}\\) is closed under addition and multiplication, i.e.¬†for all \\(a, b \\in \\mathbb {N}\\) the following applies: \\(a + b \\in \\mathbb { N}\\), \\(a\\in {N}\\). The set \\(\\mathbb {Z}\\) is closed uncdot b addition, subtraction and multiplication, i.e.¬†for all \\(a, b \\in \\mathbb {Z}\\) the following applies: \\(a + b \\in \\mathbb{Z}\\), \\(a - b \\in \\mathbb{Z}\\), \\(a \\cdot b \\in\\) \\(\\mathbb {Z}\\). The set \\(\\mathbb{Q}\\) is closed under addition, subtraction, multiplication and division (with the exception of division by 0), i.e.¬†for all \\(a, b \\in \\mathbb{Q}\\) , c \\(\\neq 0\\) holds: \\(a + b \\in \\mathbb{Q}\\), \\(a - b \\in \\mathbb{Q}\\), \\(a \\cdot b \\in \\mathbb {Q}\\), \\(a/c \\in \\mathbb {Q}\\). examples The set \\(\\mathbb N\\): number of employees in a company, number of customers in a company The quantity \\(\\mathbb Z\\): Growth of customers or employees numbers (absolute) The quantity \\(\\mathbb Q\\): Percentage of existing customers/employees working full-time Exercise 2.4 (Number sets) Show by counterexample that \\(\\mathbb N\\) is not closed under subtraction and division. Answer take \\(4; 5\\in\\mathbb{N}\\) \\(4-5=-1 \\notin\\mathbb{N}\\rightarrow\\mathbb{N}\\) is not closed under subtraction \\(4 / 5\\notin\\mathbb{N}\\rightarrow\\mathbb{N}\\) is not closed under subtraction division Definition 2.5 (Irrational numbers) There are numbers outside of \\(\\mathbb Q\\), the so-called irrational numbers. Example: \\(\\sqrt2\\) is irrational. The union of the rational and irrational numbers gives the set of real numbers \\(\\mathbb R\\). The following properties are assumed as axioms: Completeness: for all \\(a,b\\in \\mathbb R\\) applies \\(a+b\\in \\mathbb R\\) and \\(a\\cdot b\\in \\mathbb R\\) Commutative laws: for all \\(a,b\\in \\mathbb R\\) applies \\(a+b=b+a\\), \\(a\\cdot b=b\\cdot a\\) Associative laws: for all \\(a,b,c\\in \\mathbb R\\) applies \\(a+(b+c)=(a+b)+c\\) and \\(a\\cdot (b\\cdot c )=(a\\cdot b)\\cdot c\\) Distributive law: for all \\(a,b,c\\in \\mathbb R\\) applies \\(a\\cdot (b+c)=a\\cdot b+a\\cdot c\\) Null element: the element \\(0\\in\\mathbb R\\) has the property \\(a\\in\\mathbb R\\) then \\(a+0=a\\) and (a=0¬†) One element: the element \\(1\\in\\mathbb R\\) has the property \\(1\\cdot a=a\\) Inverse additive element: for each \\(a\\in \\mathbb R\\) \\(‚àía\\in \\mathbb R\\) has the property \\(a+(‚àía)=0\\) Inverse multiplicative element: for \\(a\\in \\mathbb R \\setminus\\{0\\}\\), \\(\\frac 1a \\in \\mathbb R\\) has the property \\(a\\cdot\\frac 1a=1\\). Definition 2.5 (Subsets on real numbers) The set \\(\\mathbb R_{++}\\subset \\mathbb R\\) contains the (strictly) positive numbers. The following applies: \\(\\mathbb R++\\) is closed under addition and multiplication. Exactly one of the following properties applies to each \\(a\\in\\mathbb R\\): \\(a\\in \\mathbb R_{++}\\) or \\(a=0\\) or \\(‚àía\\in \\mathbb R_{++}\\). The set \\(\\mathbb R_+ = \\mathbb R_{++}\\cup \\{0\\}\\) is the set of non-negative numbers. Sometimes you need to compare the numbers or specify a property that is related to a number. In this case, inequalities are useful. Definition 2.6 (Inequalities) The strict inequality \\(&gt;\\) and the weak inequality \\(\\geq\\) are defined as follows: If \\(a+b\\in \\mathbb R_{++}\\), then \\(a&gt;b\\) If \\(‚àí(a‚àíb)\\in \\mathbb R_{++}\\), then \\(b&gt;a\\) If \\(a ‚àí b\\in \\mathbb R_+\\), then \\(a\\geq b\\) If \\(‚àí(a‚àíb)\\in \\mathbb R_+\\), then \\(b\\geq a\\). As an example, if you plan to interview the employees with the properties at least 5 years of service (\\(X\\)), more than 1000 euros monthly earnings (\\(Y\\)), less than 10 sick days in the last year (\\(K\\)), the highest are 45 years old (\\(Z\\)) you can use inequalities to specify your target group as follows: \\(X\\geq 5,Y&gt;1,K&lt;10 \\text{ and } Z\\leq 45\\). Often one does not want to look at mere numbers, but rather at the deviations from a target value without considerring the direction of the deviation. In this case you need the amounts of these deviations. Definition 2.7 (Absolute value) The absolute value (also absolute value, ‚Äúsign killer‚Äù) of \\(x\\in\\mathbb R\\) is defined as \\(v=\\begin{cases}x, &amp;\\text{ if } x\\geq 0,\\\\ -x, &amp;\\text{ if } x&lt;0\\end{cases}\\) As an example, consider the deviations of monthly sales from the annual average: Month 1: \\(‚àí1250.2\\) euros Month 2: \\(‚àí135.5\\) euros Month 3: \\(680\\) euros Month 4: \\(55\\) euros What is the mean deviation? The amounts of the sales variances are: \\(1250.2;135.5;680;55\\) euros. The mean deviation is therefore: \\(530.175\\) euros. If you had determined the mean deviation without first taking the amount, positive and negative deviations would cancel each other out, so that the result could not be regarded as the mean deviation. This is illustrated by the following triangle inequality. Theorem 2.1 (Triangle inequality) For all \\(x,y\\in \\mathbb R\\) the following applies: \\[|x+y|\\leq|x|+|y|\\] Proof: \\(x\\leq|x|\\) and \\(y\\leq|y|\\) apply, from which it follows: \\(x+y\\leq |x|+|y|\\). Similarly: \\(‚àíx\\leq|x|\\) and \\(‚àíy\\leq |y|\\), so that \\(‚àí(x+y)\\leq |x|+|y|\\). The absolute values of the sum of the deviations from month 2 and month 3 is \\(544.5=|‚àí135.5+680|\\), which is smaller than the sum of the individual absolute values \\(815.5=|‚àí135.5| +|680|\\). ‚Äò\\(\\mathbb N\\)‚Äô ‚Äò\\(\\mathbb Z\\)‚Äô ‚Äò\\(\\mathbb Q\\)‚Äô ‚Äò\\(\\mathbb R\\)‚Äô ‚Äò\\(\\mathbb R_{++}\\)‚Äô Submit ‚Äò\\(\\mathbb N\\)‚Äô ‚Äò\\(\\mathbb Z\\)‚Äô ‚Äò\\(\\mathbb Q\\)‚Äô ‚Äò\\(\\mathbb R\\)‚Äô ‚Äò\\(\\mathbb R_{++}\\)‚Äô Submit ‚Äò\\(\\mathbb N\\)‚Äô ‚Äò\\(\\mathbb Z\\)‚Äô ‚Äò\\(\\mathbb Q\\)‚Äô ‚Äò\\(\\mathbb R\\)‚Äô ‚Äò\\(\\mathbb R_{++}\\)‚Äô Submit ‚Äò\\(\\mathbb N\\)‚Äô ‚Äò\\(\\mathbb Z\\)‚Äô ‚Äò\\(\\mathbb Q\\)‚Äô ‚Äò\\(\\mathbb R\\)‚Äô ‚Äò\\(\\mathbb R_{++}\\)‚Äô Submit ‚Äò\\(\\mathbb N\\)‚Äô ‚Äò\\(\\mathbb Z\\)‚Äô ‚Äò\\(\\mathbb Q\\)‚Äô ‚Äò\\(\\mathbb R\\)‚Äô ‚Äò\\(\\mathbb R_{++}\\)‚Äô Submit 2.3 Point sets in \\(\\mathbb R^n\\) Often one has the situation in which several objects or persons or their behavior have to be compared. The latter are represented by one or more values. We can always represent these individual values ‚Äã‚Äãfrom \\(\\mathbb R\\) or tuples of several values ‚Äã‚Äãfrom \\(\\mathbb R ^ 2, \\mathbb R^3,\\ldots\\) as points in the appropriate coordinate system. This makes it possible to determine the similarity of objects or people by measuring the distance between points. The real line \\(\\mathbb {R}\\) is suitable if each object is described by only one number. This then marks a point on the number line: Example 2.4 (Real line) The consumers Alex, Tina and Amy are compared with regard to their account balance (\\(x\\)). Alex has \\(500\\) euros, Tina has \\(250\\) euros and Amy has \\(-600\\) euros in the account. What do these account balances look like as points on the real line? The space \\(\\mathbb {R^2}\\), defines the two-dimensional view via the Cartesian product: \\(\\mathbb R ‚äó \\mathbb R = \\left\\{ {(x,y) : x \\in \\mathbb R, y \\in \\mathbb R} \\right\\} =\\mathbb R^2\\) Example 2.5 (Two dimensional real space) The consumers Alex, Tina and Amy are compared with regard to their account balance (\\(x\\)) and the change in their consumer spending (\\(y\\)) over the last month. Alex‚Äôs behavior is represented by the tuple (balance; change in consumer spending \\(=(x;y)\\)) \\((500; 300)\\), Tinas by \\((250; -200)\\) and Amy‚Äôs by \\((-600; 200)\\) described. What do the different consumer behaviors of these consumers look like as points in the coordinate system? The space \\(\\mathbb{R^3} \\left\\{ {(x, y, z) : x \\in \\mathbb R, y \\in \\mathbb R, z \\in \\mathbb R}\\right\\}\\) enables the analysis of three-dimensional points. Example 2.6 (Three dimensional real space) Alex, Tina and Amy as employees are shown in terms of their salary \\(x\\), change in productivity \\(y\\) and target achievement score \\(z\\). Their behavior is represented by the tuple (salary; productivity; goal achievement) \\(=(x;y;z)\\). Tina‚Äôs description is \\((3; 2.5; 2)\\), Alex \\((-2; -5; -2.5)\\) and Amy‚Äôs \\((-3; 1.2; 1.5)\\). What do the various characteristics of the employees look like as points in the coordinate system? The space \\(\\mathbb {R^n}\\): allows the mapping of multidimensional points. For example, if you include other characteristics of employees. The visualization is difficult at this point, but the multivariate analysis of these points and the calculation of distance can be performed without any problems. \\[ R^n = \\left\\{ {(x_1,x_2, ... , x_n) : x_i \\in \\mathbb R, 1 \\leq i \\leq n}\\right\\} \\] Subsets of \\(\\mathbb{R^n}\\): sets of points. 2.3.1 Intervals as sets of points in \\(\\mathbb{R^n}\\) Important sets of points in \\(\\mathbb {R}\\) are intervals. Example 2.7 (Intervals as point sets) For example, the HR manager of Alex, Tina and Amy could only consider employees with a negative salary score in the interval \\(-5\\) to \\(-1\\) in an evaluation. She would have a number of options to choose from. Should the employees with the score \\(0\\) be taken into account or are they still left out? So far there have been no salary scores beyond \\(-5\\). But should people with a lower score than \\(-5\\) also be included in the evaluation in the future? In the first case we would write the corresponding interval as \\([-5;0]\\), in the second - as \\([-5;0)\\) and in the third case (if yes) - \\((-\\infty ; 0)\\) write down. Accordingly, for \\(a, b \\in R, \\ a &lt; b\\) one distinguishes: limited quantities: Closed interval: \\(\\left[ a, b \\right] = \\left\\{ {x ‚àà \\mathbb{R} : a \\leq x \\leq b} \\right\\}\\) Half-open interval: \\([a, b) = \\left\\{ {x ‚àà \\mathbb{R} : a \\leq x &lt; b}\\right\\}\\) \\((a, \\infty) = \\left\\{ {x \\in \\mathbb{R} : a &lt; x}\\right\\}\\) Open interval: \\((a, b) = \\left\\{ {x \\in R : a &lt; x &lt; b}\\right\\}\\) Unlimited quantities: Unlimited interval \\([a, ‚àû) = \\left\\{ {x \\in \\mathbb R : a \\leq x}\\right\\}\\) \\((a, \\infty) = \\left\\{ {x \\in \\mathbb R : a &lt; x}\\right\\}\\) Down unlimited interval: \\((‚àí\\infty, b] = \\left\\{ {x \\in \\mathbb R : x \\leq b}\\right\\}\\) \\((‚àí\\infty, b) = \\left\\{ {x \\in \\mathbb R : x &lt; b} \\right\\}\\) \\((3;5)\\) \\([3;5)\\) \\((3;5]\\) \\([3;5]\\) Submit 1.5 years 2 years 2.5 years 3.5 years Submit 2.3.2 Properties of \\(\\mathbb R^n\\): Distance How could the HR manager now compare the employees Alex, Tina and Amy in terms of their salary \\(x\\), productivity change \\(y\\) and target achievement score \\(z\\)?. Their behavior has so far been represented by the tuple (salary; productivity; goal achievement) \\(=(x;y;z)\\). Tina‚Äôs description is \\((3; 2.5; 2)\\), Alex \\((-2; -5; -2.5)\\) and Amy‚Äôs \\((-3; 1.2; 1.5)\\). Which employees are most similar? It is useful here to find the Euclidean distance between the points representing Alex, Tina, and Emy. Definition 2.8 (Euclidean distance) The Euclidean distance between two points \\(a = (a_1, ... , a_n)\\) and \\(b = (b_1, ... , b_n)\\) in \\(\\mathbb {R}^ n\\), \\(n \\geq 1\\), is defined as \\(d(a, b) =\\) \\(\\sqrt{ \\ \\sum_{i=1}^{n} (a _{i} -b_{i}) ^{2} }\\) Example 2.8 (Pythagor) According to the Pythagorean theorem, the length of the straight line connecting \\(a\\) and \\(b\\) is \\(d(a, b) =\\) \\(\\sqrt{(a_{1}-b_{1})^{2} + (a_{2}-b_{2})^{2}}\\) The personnel manager calculates: Example 2.9 (employee comparison) \\[\\begin{align*}d(Tina, Alex) &amp;= \\sqrt{(3-(-2))^2 + (2.5-(-5))^2 + (2-(-2.5))^2}\\\\ &amp;= 10.074\\end{align*}\\] \\[\\begin{align*}d(Tina, Amy) &amp;= \\sqrt{(3-(-3))^2 + (2.5-1.2)^2 + (2-1.5))^2}\\\\ &amp;= 6.1595\\end{align*}\\] \\[\\begin{align*}d(Alex, Amy) &amp;= \\sqrt{(-2-(-3))^2 + (-5-1.2)^2 + (-2.5-1.5))^2} \\\\ &amp;= 7.446\\end{align*}\\] So Tina and Amy are the most similar of the three employees in terms of the description of changes in salary, productivity and goal achievement, since the Euclidean distance between their characteristics is the smallest. Exercise 2.5 (The Euclidean distance) Find the Euclidean distance between the following points: \\(2\\) and \\(3\\) in \\(\\mathbb {R}\\) \\((2; 3)\\) and \\((4; 1)\\) in \\(\\mathbb {R^2}\\) \\((2; 3; 4)\\) and \\((4; 1; ‚àí5)\\) in \\(\\mathbb{R^3}\\) \\((2; 3; 4; 5)\\) and \\((‚àí2; 4; 1; ‚àí5)\\) in \\(\\mathbb{R^4}\\) Antwort 1.\\(\\sqrt{(2-3)^2} = 1\\) 2.\\(\\sqrt{(2-4)^2 +(3-1)^2 } =\\sqrt{4+4} =\\sqrt{8}\\) 3.\\(\\sqrt{(2-4)^2 +(3-1)^2 + (4-(-5))^2} =\\sqrt{4+4+81} =\\sqrt{89}\\) 4.\\(\\sqrt{(2-(-2))^2 +(3-4)^2 + (4-1)^2 + (5-(-5))^2}\\) \\(=\\sqrt{16+1+9+100} =\\sqrt{126}\\) Submit 2.3.3 Properties of \\(\\mathbb R^n\\): \\(\\epsilon-\\)neighborhood We need one more concept to determine if given points are ‚Äúclose enough‚Äù to each other. Later in the course we want to see if a sequence tends towards a certain point, or comes arbitrarily close to it. This ‚Äúarbitrarily close‚Äù is also formalized with the help of the \\(\\epsilon-\\)neighborhood. Definition 2.9 (œµ-neighborhood) Let \\(\\epsilon\\) be a positive real number. The \\(\\epsilon\\) neighborhood of a point \\(x_0 ‚àà R^n\\) is defined as the set \\(N_ \\epsilon (x_0) = {x \\in R^n : d(x_0, x) &lt; \\epsilon }\\). In other words, \\(N_ \\epsilon \\left( x_0 \\right)\\) is the set of points whose distance to \\(x_0\\) is less than \\(\\epsilon\\). Example 2.10 (œµ-neighborhood) \\(N _\\epsilon (2) = \\left\\{ x \\in \\mathbb{R : } \\sqrt{(x-2)^2} &lt; \\epsilon \\right\\} = \\left\\{ x \\in \\mathbb{R} : \\lvert x-2\\rvert &lt; \\epsilon \\right\\} = (2- \\epsilon ; 2+ \\epsilon )\\) If \\(\\epsilon = 0.1\\) is set, then it is all points in the interval \\((1.9; 2.1)\\). \\(N _\\epsilon (2,3) = \\left\\{ ( x, y) \\in \\mathbb{R^2 : } \\sqrt{(x-2)^2 + (y-3)^ 2} &lt; \\epsilon \\right\\}\\) This is the set of points in \\(\\mathbb{R^2}\\) that lie within a circle of radius \\(\\epsilon\\) around the point \\((2; 3)\\). 3. \\(N _\\epsilon (2,3,1) = \\left\\{ ( x, y, z) \\in \\mathbb{R^3 : } \\sqrt{(x-2)^2 + (y -3)^2+(z-1)^2} &lt; \\epsilon \\right\\}\\) This is the set of points in \\(\\mathbb{R^3}\\) that lie within a sphere of radius \\(\\epsilon\\) around the point \\((2, 3, 1)\\). The HR manager has determined that a productivity deviation of \\(\\epsilon = 0.5\\) is an unusual development and can indicate that the employees concerned are overworked. Example 2.10 (œµ-neighbourhood in HR) If the average productivity score is \\(1.5\\) and \\(\\epsilon=0.5\\) is specified, Amy‚Äôs score is still in the \\(\\epsilon\\) environment of the average score and Tina‚Äôs scores and Alex - not. This can be seen by writing down the \\(\\epsilon\\) neighborhood for the one-dimensional case: \\[ N _{\\epsilon=0.5} (1.5) = \\left\\{ x \\in \\mathbb{R : } \\sqrt{(x-1.5)^2} &lt; 0.5 \\right\\} = \\left\\{ x \\in \\mathbb{R} : \\lvert x-1.5\\rvert &lt; 0.5 \\right\\} \\]\\[= (1.5- 0.5 ; 1.5+ 0.5 ) \\] Since this interval is an open interval, Tina‚Äôs score of \\(2\\) is no longer part of it. The personnel manager will therefore have discussions with Alex and Tina about their professional stress. 2.4 Functions We have already seen with Alex‚Äôs utility-budget representation how helpful it can be to express the problem using suitable functions. A functional form can also be very helpful in other contexts such as production and production costs to make optimal production decisions. Now let‚Äôs take a closer look at how functions are defined and what types of functions are commonly used in a business or economic context. Definition 2.10 (Function) Let \\(X, Y \\subset\\mathbb R\\). A function (also mapping) from \\(X\\) to \\(Y\\) is a rule that assigns exactly one element of \\(Y\\) to each element in \\(X\\). The set \\(X\\) is called the domain of the function. The set \\(Y\\) is called the codomain of the function. Notation: If \\(f\\) is a function, then we write \\(f : X \\rightarrow Y\\) and \\(y = f (x)\\), \\(x \\in X\\), where \\(y\\) is called the image or the function value of \\(f\\) at the position \\(x\\). Definition 2.11 (Inverse function) Let \\(f : X \\rightarrow Y\\) with \\(y = f (x)\\). If each element \\(y \\in Y\\) is the image of exactly one point \\(x \\in X\\), then the inverse function exists, written as \\(f^{(‚àí1)}\\), and it satisfies the following equation : \\[ {f}^{-1} \\ ( y )= x.\\] Example 2.11 (Function and its inverse) Let \\(y = f (x) = {x}^{2}\\) with \\(X = \\mathbb{R^+}\\). Then, \\[{f}^{-1} ( y ) = \\sqrt{ y}, \\] because \\(\\sqrt{y} = \\sqrt{x^2} = x\\). Let \\(g : Y \\rightarrow Z\\) be another function with \\(z = g( y )\\). Definition 2.12 (Composition) The composition of \\(f\\) and \\(g\\) is given by \\[g \\circ f : X \\rightarrow Z \\text{ with } z = g(f (x)) \\] Example 2.12 (Composition) \\(f (x) = x + 2, \\ g( y ) = {y}^{2}\\) and \\(g(f (x)) = {(x+2)}^{2}\\). 2.4.1 Linear Functions In the utility maximization example, Alex had the budget constraint \\(x \\cdot P_X + y \\cdot P_Y = 100.\\), which was expressed as a linear function \\(y(x)=\\frac{100}{P_Y}-\\frac {P_X} {P_Y} x\\) could be represented. In addition, many cost functions can be modeled as linear functions of the quantities produced. In this case, the costs consist of a fixed amount \\(b\\) and grow proportionally to the produced quantity \\(x\\) with the factor \\(b\\), so that \\(K(x) = ax+b\\) . Definition 2.13 (Linear function) Let \\(a, b\\) be real numbers. The function \\(f : \\mathbb{R} ‚Üí \\mathbb{R}\\) with \\(f (x) = a \\cdot x + b\\), \\(x ‚àà \\mathbb{R}\\), is a linear function. Example 2.13 (Linear Functions) Linear functions: positive \\(a\\) in \\((a)\\) and \\((c)\\); negative \\(a\\) in \\((b)\\); \\(b = 0\\) in \\((a)\\) and \\((b)\\), positive \\(b\\) in \\((c)\\): The parameter \\(a\\) determines the gradient of the linear function. Let \\(y_1 = a \\cdot x_1 + b\\), \\(y_2 = a \\cdot x_2 + b\\), it follows \\(y_2 ‚àí y_1 = a\\ (x_2 ‚àí x_1)\\), so that \\(a = \\frac{y_2-y_1}{x_2-x_1} = \\frac{\\Delta y}{\\Delta x} .\\) \\(\\Delta y\\) denotes the ‚Äúchange in \\(y\\)‚Äù, \\(\\Delta x\\) denotes the ‚Äúchange in \\(x\\)‚Äù. The ratio \\(\\Delta y/\\Delta x\\) is the slope, \\(a\\) is the slope coefficient. The parameter \\(b\\) is the \\(y\\)-intercept / ordinate-intercept / intercept. Example 2.14 (Cost function and marginal cost function) The cost of a bicycle manufactory is ‚Ç¨50,000 per month and ‚Ç¨25 per bicycle. The cost function (in EUR) is \\[ C(q) = 50,000 + 25q \\] The marginal cost, i.e.¬†the cost of producing an additional bike, is \\[C^\\prime (q) = 25\\] Because of the linearity, the marginal cost is ‚Ç¨25 independent of the production level/amount \\(q\\) produced. 2.4.2 Quadratic Functions Some cost functions cannot be represented by a linear function. Then the costs grow disproportionately to the quantity. To describe such costs one then uses quadratic terms in the quantity produced. Definition 2.14 (Quadatic function) Let \\(a, b, c\\) be constant real numbers. A quadratic function has the form \\[ y = a \\cdot x^2 + b \\cdot x + c, ~~x \\in \\mathbb {R}, a \\neq 0 \\] Example 2.15 (Quadatic Functions) Quadratic functions: positive \\(a\\) in \\((a)\\); negative \\(a\\) in }((b)}): The graph of a quadratic function is a parabola. Example 2.16 (Squared cost function) We consider again the bicycle factory from the previous example. It is more realistic to assume that greater output comes with additional costs. For example, increased demand can increase the price of commodities. This is captured by an additional term, e.g.¬†\\(0.001 q^2\\). This term is very small for small \\(q\\), but grows strongly with increasing production level \\(q\\). Now the cost function is \\(C(q) = 50,000 + 25q + 0.001q^2\\), with marginal costs \\(C^\\prime (q) = 25 + 0.002q\\). The marginal cost is ‚Ç¨25.20 for a production of 100 bikes per week, rising to ‚Ç¨45 for an increase in production to 10,000 bikes per week. 2.5 Power, exponential and logarithmic functions Growth processes are usually neither linear nor quadratic in the variable time. Rapid growth well described using exponential and power functions. During the corona pandemic, the number of infections was monitored very closely. Suppose every infected person infects two more people per week. Then the growth looks like this: At this point we need the definition and calculation rules for the exponents that can describe such a growth. We write \\({a}^{n}\\) for the \\(n-fold\\) product of a number \\(a\\) with itself (\\(n \\in \\mathbb{N}\\)). The number \\(n\\) is called an exponent. This can be extended to \\(n \\in \\mathbb{R}\\). Theorem 2.2 \\(a^n \\cdot a^m = {a}^{n+m}\\) \\(({a}^{n} ) ^m = {a}^{n \\cdot m}\\) \\(\\frac{a^n}{a^m} = {a}^{n-m}\\) \\(\\frac{a^n}{a^n} = {a}^{0} = 1\\) Furthermore: \\(a^n \\cdot b^n = (a \\cdot b)^n; a^n/b^n = (a/b)^n \\ and \\ {a}^{-n} = 1/a^n\\). Definition 2.15 (Power function) A power function has the form \\(y = ax^b\\), \\(x \\in \\mathbb{R}\\), \\(a &gt; 0\\). The parameter \\(b\\) is called exponent. Note that the variable \\(x\\) acts as the base of the power function here. Definition 2.16 (Exponential function) An exponential function has the form \\(y = ab^x\\) , \\(x \\in \\mathbb {R}\\). The parameter \\(b\\) is called the basis of the function. Exponential functions capture growth effects (e.g.¬†populations, money). The Euler constant \\(e = 2.718...\\) is often used as the basis. (more later) Note: The exponent is now the function variable. Now if we want to invert an exponential function, e.g.¬†to find out how many weeks it takes to reach a certain number of infected people, we use the logarithm function. Definition 2.17 (logarithm function) If \\(x = b^y\\) , with \\(b &gt; 0\\) and \\(b \\neq 1\\), then \\(y\\) is the logarithm of \\(x\\) to the base \\(b\\), written as \\(y = \\log_b x\\), \\(x \\in \\mathbb{R}_+\\) The logarithm to the base \\(e (10)\\) is called the natural logarithm (decade logarithm), written as \\(y = \\ln \\ x\\) \\((y = \\log \\ x)\\). The logarithm of \\(x\\) to the base \\(b\\) answers the question: ‚ÄúHow many times do you multiply \\(b\\) by itself to get \\(x\\)?‚Äù Theorem 2.2 (rules for logarithms) \\(\\log_b(xz) = \\log_b\\ x + \\log_b\\ z\\) \\(\\log_b(x/z) = \\log_b \\ x ‚àí \\log_b \\ z\\) \\(\\log_b(x ^a) = a \\ \\log_b \\ x\\) Remark: From the last property it follows that \\(\\log_b \\ x = \\ln \\ x / \\ln\\ b\\) . Because: If you set \\(y = \\frac{\\ln\\ x}{\\ln\\ b}\\) , then: \\(\\ln \\ x = y \\ \\ln\\ b = \\ln(b^y )\\). So \\(b^y = x\\) and therefore \\(y = \\log_b x\\). On the pocket calculator you can determine any logarithm using the natural logarithm. The world population is growing. This process can be modeled with the help of an exponential function (albeit very simplified). The following formula helps to connect the future population \\(P(t)\\) after \\(t\\) periods with the initial inventory \\(P(0)\\) and growth rate \\(r\\) per period: \\(P(t)=P(0)(1+r)^t\\) where \\(r\\) can be positive or negative. A negative \\(r\\) would mean that the population is shrinking. In the year \\(2000\\), the world population was about \\(5.2 \\ billion\\) with \\(r&gt;0\\), so it shows positive growth. Depending on which estimate is used, \\(r \\approx 1.5\\) percent per year applies. Suppose the population is growing exponentially and the growth rate is \\(r \\approx 1.5\\) percent per year. How high should the population be in the year \\(2025\\) assuming \\(5.2 \\ billion\\) in the year \\(2000\\)? Submit How long will it take for the world population to reach \\(8\\) billion? Submit 2.5.1 Convexity and concavity When we examined Alex‚Äôs utility function, we found that utility increases as consumption levels increase, but the slope decreases as consumption increases. It is assumed that all consumers exhibit such behavior and it is said that the typical utility function is concave. Definition 2.18 (Concave function) The function \\(f : D \\rightarrow \\mathbb{R}\\) is concave if for all \\(x_1,x_2 \\in D\\) and \\(\\lambda \\in (0,1)\\) is applicable: \\(f (\\lambda x_1 + (1 ‚àí \\lambda )x_2) \\geq \\lambda f (x_1) + (1 ‚àí \\lambda)f (x_2)\\). The function is strictly concave if the inequality is strict. Notation: \\(\\bar{x} = \\lambda x_1 + (1 ‚àí \\lambda)x_2\\), \\(\\bar{f} = \\lambda f(x_1) + (1 ‚àí \\lambda)f(x_2)\\). Geometrically, (strict) concavity means that the function value of each point \\(\\bar{x} \\in \\left[ x_1, x_2 \\right]\\) lies (strictly) above the line connecting \\(x_1\\) and \\(x_2\\) connects. Examples of concave functions: Linear functions \\(ax + b\\), for \\(a,b \\in \\mathbb{R}\\) Power functions \\(x ^a\\) on \\(\\mathbb{R}_{++}\\), with \\(a \\in [0,1]\\) Logarithm function \\(\\log(x)\\) on \\(\\mathbb {R}_{++}\\) Example 1.3 (Utility function) If Alex consumes a fixed amount of donuts (e.g.¬†\\(30\\)), his utility function only depends on the amount of coffee and is: \\(U(y )=\\sqrt{30} + \\sqrt{y}\\) Take \\(y_1=2\\), \\(y_2=4\\) and \\(\\lambda=0.5\\), for example. Then \\(\\bar y=3\\). \\(U(y_1=2) = \\sqrt{30} + \\sqrt{2}=6.891439\\), \\(U(y_2=4) = \\sqrt{30} + \\sqrt{4}=7, 477226\\) and \\(U(\\bar y) = \\sqrt{30} + \\sqrt{3}=7.209276\\). Since a utility function is always concave, the following applies: \\(U(\\bar y)=7.209276\\geq 0.5\\cdot U(y_1=2) + 0.5\\cdot U(y_2=4) = 7.184332\\). Definition 2.19 (Convex Function) The function \\(f : D ‚Üí \\mathbb{R}\\) is convex if for all \\(x_1,x_2 \\in D\\) and \\(\\lambda \\in (0,1)\\) holds : \\(f (\\lambda x_1 + (1 ‚àí \\lambda)x_2) ‚â§ \\lambda f (x_1) + (1 ‚àí \\lambda)f (x_2)\\). The function is strictly (strictly) convex if the inequality is strict. Notation: \\(x = \\lambda x_1 + (1 ‚àí \\lambda)x_2, f = \\lambda f (x_1) + (1 ‚àí \\lambda)f (x_2)\\). Geometrically, (strict) convexity means that the functional value of each point \\(\\bar{x} \\in [x_1,x_2]\\) lies (strictly) below the line connecting \\(x_1\\) and \\(x_2\\). Examples of convex functions: Linear functions \\(ax + b\\), \\(a,b \\in \\mathbb{R}\\) Exponential functions \\({e}^{ax}\\) or \\(ab^{x}\\) with \\(a \\in \\mathbb{R}\\) and \\(b&gt;1\\) Power functions \\({x}^{a} \\ on \\ \\mathbb{R}_{++}\\) with \\(a &lt; 0\\) and \\(a \\geq 1\\) Powers of the absolute value \\(\\lvert x \\rvert ^{a}\\) on \\(\\mathbb {R}\\) for \\(a \\geq 1\\) Example 2.17 (Corona infections) Infection numbers in the example with the corona pandemic, where each infected person infects two more people per week and there are initially around \\(1000\\) infected people, can be modeled using the function \\(f(x) = 1000\\cdot 2^x\\). This is a convex function because it is an exponential function of the form \\(ab^{x}\\) with \\(2=b&gt;1\\) and \\(a=1000\\). "],["sequences-limits-and-series.html", "Chapter 3 Sequences, limits and series 3.1 Sequences 3.2 Convergence of sequences 3.3 Properties of sequences 3.4 Series", " Chapter 3 Sequences, limits and series 3.1 Sequences Definition 3.1 (Sequence) A sequence is a function \\(f : \\mathbb N \\rightarrow \\mathbb {R}\\). In other words, it is a function whose domain is the natural numbers and whose domain is the real numbers. Notation: \\(f(n),n= 1,2,3,...\\) The following notation is also often used: \\(({a}_{n}) _{i \\in \\mathbb{N} }\\), where \\(a_n=f(n)\\) The elements of the domain are called indices (singular: index). Properties of interest are: convergence, whether a sequence is bounded or not, monotony. The concept of convergence is fundamental for various applications and concepts, e.g. in financial mathematics; in analysis (continuity, differential quotient). Example 3.1 (Number sequences in the business context) New customers In a company, the monthly customer additions in the first quarter of 2022 are \\(a_1=120,560, \\ a_2=133,847\\) and \\(a_3=123,432\\). It is a finite sequence of numbers, with real numbers assigned to the months of January (1), February (2) and March (3). Employees The number of employees increases monthly by \\(2\\) %. Starting from March 2022 (\\(a_0=128,432\\)), we then have the following sequence members (unrounded): \\(a_1=128,432.00 \\cdot 1.02 =131,000.64\\) (April) \\(a_2=131,000.64 \\cdot 1.02 =133,620.65\\) (May) \\(a_3=133,620.65 \\cdot 1.02 =136,293.07\\) (June) In this example we have the special feature that you can calculate the individual members of the sequence. The functional rule for the nth element of the sequence applies: \\(a_n=128,432 \\times 1.02^n\\) If we put \\(n=3\\) (for the month of June), then we have \\(128,432 \\cdot 1.02^3\\), i.e.¬†\\(136,293.07\\). Such a sequence, which satisfies a functional rule, is also called a geometric sequence (see below). Note that a functional relationship cannot be specified for every sequence. Auch reine Zahlenfolgen werden meist mittels einer Funktionsvorschrift angegeben. Example 3.2 (Sequences of numbers) Observations: The terms in the sequences \\((1/n)_{n\\in \\mathbb N}\\) and \\((-1/n)_{n\\in \\mathbb N}\\) approach zero; they have a limit. Although no element in the sequence takes on the value zero, the limit value is zero. The other two sequences do not approach any finite value. Exercise 3.1 (sequence members) Find the first ten terms of each of the given sequences: \\(f (n) = 5 + 1/n\\) \\(f (n) = 5n/({2}^{n})\\) \\(f (n) = ({n}^{2} + 2n)/n\\) \\(f (n) = 5 ‚àí 1/n\\) \\(f (n) = n/(n + 1)\\) \\(f(n) = 3+(-1)^n\\) \\(f (n) = 3 + [(‚àí1)^n(1/n)]\\) Hint: Insert \\(n=1;2;3;4;...10\\) to determine the first 10 terms. Answer Frage: a b c d e f g Submit 3.2 Convergence of sequences Convergence of a sequence means that the sequence terms \\(a_n = f (n)\\) come ‚Äúarbitrarily close‚Äù to a unique finite value, its limit value (also: \\(\\lim\\)), if \\(n\\) is ‚Äúlarge enough‚Äù. More formally: convergence means that the distance \\(|a_n ‚àí a|\\) between the following terms \\(a_n, n = 1,2, ...\\) and the limit \\(a \\in \\mathbb{R}\\) becomes arbitrarily small with increasing \\(n\\), i.e.: \\(|a_n ‚àí a| &lt; \\varepsilon\\), for arbitrarily small \\(\\varepsilon &gt; 0\\), if \\(n\\) tends to infinity (\\(n\\rightarrow \\infty\\)). A sequence with a limit converges. A sequence that does not converge diverges. Notation: If the sequence \\(a_n, n = 1,2, ...\\) converges to the limit \\(a\\), then we write: \\(\\lim \\limits_{n \\rightarrow \\infty } a_n=a\\) or \\(a_n \\rightarrow a\\) for \\(n \\rightarrow \\infty\\). 3.2.1 Convergent sequences and their limits Definition 3.2 (limit) The sequence \\((a_n) _{n\\in \\mathbb N}\\) has the limit \\(a \\in \\mathbb {R}\\), if for each any \\(\\varepsilon &gt; 0\\) an index \\(N\\) exists such that: \\(|a_n ‚àí a| &lt; \\varepsilon\\), for all \\(n &gt; N\\). A sequence with a limit is called convergent, and the limit is written as \\(\\lim\\limits_{n \\rightarrow \\infty } a_n=a\\). or: \\(a_n \\rightarrow a\\) for \\(n \\rightarrow \\infty\\). Example 3.3 (Checking convergence) We examine the sequence \\((a_n) _{n\\in \\mathbb N}\\) with \\(a_n = 1/n\\). First, choose \\(\\varepsilon = 0.01\\). Then, for each \\(n &gt; 100\\) holds \\(|a_n ‚àí 0| &lt; 1/100 = 1/100 = 0.01 = \\varepsilon\\). So the distance of the following terms \\({a}_{101}, {a}_{102}\\) from \\(0\\) is smaller than \\(\\varepsilon = 0.01\\). Further, check the above property for \\(\\varepsilon= 0.002\\) and \\(n &gt; 500\\). In general, for any \\(\\varepsilon &gt; 0\\): from \\(n &gt; 1/\\varepsilon\\) follows \\(|a_n ‚àí 0| = 1/n &lt; \\varepsilon\\). Hence \\((1/n) _{n\\in \\mathbb N}\\) converges to \\(0\\). Example 3.4 (Some convergent sequences and their limits) \\(\\lim \\limits_{n \\rightarrow \\infty } \\frac{1}{n} =0\\) \\(\\lim \\limits_{n \\rightarrow \\infty } \\frac{n}{n+1} =1\\) \\(\\lim\\limits_{n \\rightarrow \\infty } c^n =0\\), for \\(c &lt; 1\\) \\(\\lim \\limits_{n \\rightarrow \\infty } e^{-n} =0\\) \\(\\lim \\limits_{n \\rightarrow \\infty } e^{-1/n} =1\\) 3.2.2 Bounded sequences Definition 3.3 (Bounded sequence) A sequence is bounded if there is a number \\(K &gt; 0\\) such that an index \\(N\\) exists with \\(a_n &lt; K\\) for all \\(n &gt; N\\) (bounded from above) and \\(a_n &gt; ‚àíK\\) for all \\(n &gt; N\\) (bounded from below). Otherwise the sequence is unbounded. A sequence is bounded if and only if there is a number \\(K &gt; 0\\) such that an index \\(N\\) exists with \\(|a_n| &lt; K\\), for all \\(n &gt; N\\). Graph Examples: \\(a_n = 2n, \\ n = 1,2,3, ...\\) is unbounded because it is not bounded from above; Graph \\(a_n = ‚àín^2 , \\ n = 1,2,3, ...\\) is unbounded because it is not bounded from below; Graph \\(a_n = (‚àí2)^n , \\ n = 1,2,3, ...\\) is not limited from below or above; Graph \\(a_n = 1/n, \\ n = 1,2,3, ...\\) is bounded; Graph \\(a_n = (‚àí1)^n , \\ n = 1,2,3, ...\\) is bounded but does not converge. Graph There is the following relationship between the bounded sequence and their convergence properties. Theorem 3.1 (Boundedness of convergent sequences) Every convergent sequence is bounded. Proof Consider a convergent sequence \\((a_n)\\) with limit \\(a&lt;\\infty\\). With the triangle inequality it follows that \\(|a_n|=|a_n-a+a|\\leq |a_n‚àía|+|a|\\) Due to the convergence of \\((a_n)\\) there is in particular a natural number \\(N\\), so that \\(|a_n‚àía|\\leq 1\\) for all \\(n\\geq N\\). We thus get the estimate: \\(|a_n|\\leq 1+|a|\\) for all \\(n\\geq N\\). 3.2.3 Divergent sequences Definition 3.4 (Divergent sequences) A sequence with no limit diverges. A distinction is made between the following forms of divergence: Definite divergence: \\(\\lim _{n\\rightarrow \\infty} a_n = \\infty\\) or \\(\\lim _{n\\rightarrow \\infty} a_n = -\\infty\\). Examples: \\((n) _{n\\in \\mathbb N}\\), \\((n^k) _{n\\in \\mathbb N}\\), for \\(k &gt; 0\\), \\(( e^n) _{n\\in \\mathbb N}\\), \\((\\ln(n)) _{n\\in \\mathbb N}\\) Graph Indefinite divergence: the sequence is not convergent, nor does it grow (fall) above (below) any limit. Examples: \\((\\sin(n)) _{n\\in \\mathbb N}\\), \\((-1^n) _{n\\in \\mathbb N}\\) Graph The sequence \\((-1^n) _{n\\in \\mathbb N}\\) diverges because for \\(\\varepsilon &gt; 0\\) small enough, no candidate for a limit can be found: 3.3 Properties of sequences We have already seen that some sequences, like \\((1/n)_{n\\in \\mathbb N}\\), are convergent and some, like \\((-1)^n_{n\\in \\mathbb N}\\), are divergent. Now we consider more complex sequences, which are defined as the sum or product of two sequences. Theorem 3.2 (Convergence of Sequences I) Let \\((a_n)_{n\\in \\mathbb N}\\) and \\((b_n)_{n\\in \\mathbb N}\\) be two convergent sequences with limit values \\(\\lim _{n \\rightarrow \\infty } a_n =a\\) and \\(\\lim _{n \\rightarrow \\infty } b_n =b\\). Then: the sum \\(a_n + b_n\\) converges, with limit \\(\\lim _{n \\rightarrow \\infty } (a_n + b_n)= a+b\\); the product \\(a_n \\cdot b_n\\) converges, with limit \\(\\lim _{n \\rightarrow \\infty } (a_n \\cdot b_n)= a\\cdot b\\); if \\(b \\neq 0\\), then \\(a_n/b_n\\) converges, with limit \\(\\lim _{n \\rightarrow \\infty } (a_n / b_n)= a/b\\). Theorem 3.3 (Convergence of sequences II) Let \\((a_n)_{n\\in \\mathbb N}\\) be a convergent sequence with limit \\(\\lim\\limits_{n \\rightarrow \\infty } a_n=a\\) and let \\((b_n)_{ n\\in \\mathbb N}\\) be a definite divergent with \\(\\lim\\limits_{n \\rightarrow \\infty } b_n= + \\infty\\). Then: \\(\\lim\\limits_{n \\rightarrow \\infty } (a_n+b_n)= + \\infty\\) \\(\\lim\\limits_{n \\rightarrow \\infty} (a_n\\cdot b_n) =\\begin{pmatrix} + \\infty , \\ if \\ a&gt;0 \\\\ - \\infty ,\\ \\ if \\ a&lt; 0 \\\\ \\end{pmatrix}\\) \\(\\lim \\limits_{n \\rightarrow \\infty } (a_n/b_n)= 0\\) Remark: If \\(\\lim\\limits_{n \\rightarrow \\infty } a_n= 0\\) , then the limit of the product, \\(\\lim\\limits_{n \\rightarrow \\infty } (a_n\\cdot b_n)\\), can converge or diverge A consequence of (iii) is: \\(\\lim\\limits_{n \\rightarrow \\infty } 1/b_n= 0\\). Theorem 3.4 (Convergence of Sequences III) Let \\(\\displaystyle (b_{n})_{n\\in \\mathbb {N} }\\displaystyle (c_{n})_{n\\in \\mathbb {N} }\\) be two sequences and let \\({\\displaystyle a\\in \\mathbb {R} }\\). The sequence \\({\\displaystyle (a_{n})_{n\\in \\mathbb {N} }}\\) is defined by \\[{\\displaystyle a_{n}={\\begin{cases}b_{\\frac {n+1}{2}}&amp;{\\text{for }}n{\\text{ odd}}\\\\c_{\\frac {n}{2}}&amp;{\\text{for }}n{\\text{ even}}\\end{cases}}}\\] converges to \\({\\displaystyle a}\\) if and only if the sequences \\({\\displaystyle (b_{n})_{n\\in \\mathbb {N} }}\\) and \\({\\displaystyle (c_{n})_{n\\in \\mathbb {N} }}\\) converge to \\({\\displaystyle a}\\). Submit Hints for finding limits of sequences: If there is a fraction \\(\\frac{a_n}{b_n}\\) of the form \\(\\frac\\infty\\infty\\) or \\(\\frac00\\): find the highest power of \\(n\\) in the denominator and factor them out in the numerator and denominator. Then shorten it and see where sequences with a known limit have come up. If \\(a_n - b_n\\) is in the form \\(\\infty - \\infty\\), use the transformation \\[a-b=\\frac{(a-b)(a+b)}{a+b} = \\frac {a^2-b^2}{a+b}.\\] Then use the tip above. If \\(a_n\\) contains \\((-1)^n\\), consider the subsequences for \\(n\\) even and odd separately and apply the theorem 3.4. Example 3.5 (Limit value determination I) Find the limit value: \\[\\lim _{n\\rightarrow\\infty}\\frac{2n^2-4n+5}{6-5n^2+7n}.\\] Limit value calculation We start by looking at the denominator and finding the highest power of \\(n\\) (here it is \\(n^2\\)). Then we exclude \\(n^2\\) from the numerator and denominator. (I.e. each summand is divided by \\(n^2\\)): \\[\\lim _{n\\rightarrow\\infty}\\frac{2n^2-4n+5}{6-5n^2+7n} = \\lim _{n\\rightarrow\\infty}\\frac{n^2\\cdot\\ left(\\frac{2n^2}{n^2}-\\frac{4n}{n^2}+\\frac5{n^2}\\right)}{n^2\\cdot\\left(\\frac6{n ^2}-\\frac{5n^2}{n^2}+\\frac{7n}{n^2}\\right)}.\\] Now we reduce the individual fractions in the numerator and denominator as much as we can. \\(n^2/n^2\\) in the large fraction can also be reduced: \\[= \\lim_{n\\rightarrow\\infty}\\frac{n^2\\cdot\\left(2-\\frac{4}{n}+\\frac5{n^2}\\right)}{n^2\\ cdot\\left(\\frac6{n^2}-5+\\frac{7}{n}\\right)} = \\lim_{n\\rightarrow\\infty}\\frac{2-\\frac{4}{n}+ \\frac5{n^2}}{\\frac6{n^2}-5+\\frac{7}{n}}.\\] In the next step, we apply \\(\\lim _{n\\rightarrow\\infty}\\) to each summand in the numerator and denominator individually: \\[=\\frac{\\lim _{n\\rightarrow\\infty}\\left(2-\\frac{4}{n}+\\frac5{n^2}\\right)}{\\lim _{n\\rightarrow\\infty} \\left(\\frac6{n^2}-5+\\frac{7}{n}\\right)} = \\frac{\\lim _{n\\rightarrow\\infty}2-\\lim _{n\\rightarrow\\infty}\\ frac{4}{n}+\\lim _{n\\rightarrow\\infty}\\frac5{n^2}}{\\lim _{n\\rightarrow\\infty}\\frac6{n^2}-\\lim _{n\\rightarrow\\ infty}5+\\lim_{n\\rightarrow\\infty}\\frac{7}{n}}.\\] As we have seen, all sequences where a number is divided by \\(n, n^2,n^3,\\ldots\\) converge to zero as \\(n\\) increases. Furthermore, the limit of a number is the number itself. Therefore: \\[\\frac{\\overbrace{\\lim _{n\\rightarrow\\infty}2}^{\\rightarrow 2}-\\overbrace{\\lim _{n\\rightarrow\\infty}\\frac{4}{n}}^{\\ rightarrow0}+\\overbrace{\\lim _{n\\rightarrow\\infty}\\frac5{n^2}}^{\\rightarrow 0}}{\\underbrace{\\lim _{n\\rightarrow\\infty}\\frac6{n^2} }_{\\rightarrow 0}-\\underbrace{\\lim _{n\\rightarrow\\infty}5}_{\\rightarrow 5}+\\underbrace{\\lim _{n\\rightarrow\\infty}\\frac{7}{n}} _{\\rightarrow0}} = \\frac{2-0+0}{0-5+0} = -\\frac25.\\] So the limit is: \\[\\lim_{n\\rightarrow\\infty}\\frac{2n^2-4n+5}{6-5n^2+7n}=-\\frac25.\\] Example 3.6 (Limit value determination II) Find the limit value: \\[\\lim _{n\\rightarrow\\infty}(-1)^{n}\\cdot\\frac{4n^3}{5n^4-n^2}.\\] Limit value calculation Since the sequence contains the term \\((-1)^n\\), which takes the value either \\(1\\) or \\(-1\\) depending on whether \\(n\\) is even or odd, we must Here we look at two subsequences: for \\(n\\) even and odd. If the two subsequences have the same limit, then this limit will apply to the entire sequence according to theorem 3.4. For \\(n\\) even \\((n=2k)\\) the corresponding subsequence is: \\[(-1)^{2k}\\cdot\\frac{4n^3}{5n^4-n^2} = \\frac{4n^3}{5n^4-n^2}.\\] We calculate the limit as follows: \\[\\begin{align}\\lim _{n\\rightarrow\\infty}\\frac{4n^3}{5n^4-n^2} &amp;= \\lim _{n\\rightarrow\\infty}\\frac{n^4\\ cdot\\frac{4n^3}{n^4}}{n^4\\cdot\\left(\\frac{5n^4}{n^4}-\\frac{n^2}{n^4}\\right )}\\\\ &amp;=\\lim_{n\\rightarrow\\infty}\\frac{n^4\\cdot\\frac{4}{n}}{n^4\\cdot\\left(5-\\frac{1}{n^2}\\ right)}=\\lim_{n\\rightarrow\\infty}\\frac{\\overbrace{\\frac{4}{n}}^{\\rightarrow0}}{\\underbrace{5}_{\\rightarrow 5}-\\underbrace{ \\frac{1}{n^2}}_{\\rightarrow 0}} = \\frac0{5-0} = 0. \\end{align}\\] For \\(n\\) odd \\((n=2k+1)\\) the corresponding subsequence is: \\[(-1)^{2k+1}\\cdot\\frac{4n^3}{5n^4-n^2} = -\\frac{4n^3}{5n^4-n^2}.\\ ] We calculate the limit as follows: \\[\\begin{align}\\lim _{n\\rightarrow\\infty}-\\frac{4n^3}{5n^4-n^2} &amp;= \\lim _{n\\rightarrow\\infty}-\\frac{n^ 4\\cdot\\frac{4n^3}{n^4}}{n^4\\cdot\\left(\\frac{5n^4}{n^4}-\\frac{n^2}{n^4} \\right)}\\\\ &amp;=\\lim_{n\\rightarrow\\infty}-\\frac{\\overbrace{\\frac{4}{n}}^{\\rightarrow0}}{\\underbrace{5}_{\\rightarrow 5}-\\underbrace{\\ frac{1}{n^2}}_{\\rightarrow 0}} = -\\frac0{5-0} = 0. \\end{align}\\] The two subsequences therefore have the same limit \\(0\\). Consequently, the entire sequence converges to \\(0\\) if \\(n\\rightarrow \\infty\\). Example 3.7 (Limit value determination III) Find the limit value: \\[\\lim_{n\\rightarrow\\infty}{\\sqrt{4n^2+3n}-{2n}}.\\] Limit value calculation Here we use the conversion \\(a-b = \\frac{(a-b)(a+b)}{(a+b)}\\) and the binomial formula: \\((a-b)(a+b)=a^2- b^2.\\) Here we have to multiply by \\((\\overbrace{\\sqrt{4n^2+3n}}^{a}+\\overbrace{{2n}}^{b})\\) so that \\[\\begin{align}(\\color{red}{\\sqrt{4n^2+3n}}-\\color{blue}{{2n}})\\cdot (\\color{red}{\\sqrt{4n^ 2+3n}}+\\color{blue}{{2n}})&amp; = (\\color{red}{\\sqrt{4n^2+3n}})^2-(\\color{blue}{{2n} })^2 \\\\ &amp;= \\color{red}{{4n^2+3n}}-\\color{blue}{{4n^2}} \\\\ &amp;= 3n \\end{align}\\] results. We calculate: \\[\\begin{align}\\lim _{n\\rightarrow\\infty}{\\sqrt{4n^2+3n}-{2n}} &amp;= \\lim _{n\\rightarrow\\infty}\\frac{\\left(\\sqrt {4n^2+3n}-{2n}\\right)\\left(\\sqrt{4n^2+3n}+{2n}\\right)}{\\sqrt{4n^2+3n}+{2n}}\\ \\ &amp;=\\lim_{n\\rightarrow\\infty}\\frac{3n}{\\sqrt{4n^2+3n}+{2n}} = \\lim_{n\\rightarrow\\infty}\\frac{3n}{\\sqrt{ n^2(4+\\frac3n)}+{2n}} \\\\ &amp;= \\lim _{n\\rightarrow\\infty}\\frac{3n}{n\\cdot\\sqrt{4+\\frac3n}+{2n}} = \\lim _{n\\rightarrow\\infty}\\frac{3n}{n \\cdot\\left(\\sqrt{4+\\frac3n}+{2}\\right)}\\\\ &amp;=\\lim_{n\\rightarrow\\infty}\\frac{3}{\\sqrt{4+\\underbrace{\\frac3n}_{\\rightarrow0}}+{2}} = \\frac{3}{\\sqrt{4 +0}+2} = \\frac 34. \\end{align}\\] In the second line of the equation we used: \\(\\sqrt{n^2(4+\\frac3n)} = \\sqrt{n^2}\\cdot\\sqrt{4+\\frac3n} = n\\cdot \\sqrt{ 4+\\frac3n}.\\) So the limit value is: \\[\\lim_{n\\rightarrow\\infty}{\\sqrt{4n^2+3n}-{2n}}=\\frac 34.\\] Exercise 3.2 (Limits I) Determine the limit of: \\(\\frac{n}{(n+1)^2}\\) , \\(n \\in \\mathbb{N}\\); Answer \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac{n}{(n+1)^2} = \\lim\\limits_{n \\rightarrow \\infty} \\frac{n}{n^2+2n +1}\\stackrel{:n}{=} \\lim\\limits_{n \\rightarrow \\infty} \\frac{1}{n+2+\\frac1n}\\) Since \\(\\lim\\limits_{n \\rightarrow \\infty} n+2+\\frac1n = \\infty\\) according to theorem 3.2 (i), because of theorem 3.2 (iii): \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac{1}{n+2+\\frac1n} =0\\) \\(\\frac{n}{(2n+1)}\\) , \\(n \\in \\mathbb{N}\\); Answer \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac{n}{(2n+1)} \\stackrel{:n}{=} \\lim\\limits_{n \\rightarrow \\infty} \\frac{1} {2+\\frac1n}\\) Since \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac1n =0\\) according to theorem 3.2 (i) and (iii): \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac{1}{2+\\frac1n}=\\frac 12\\) \\(({-1})^{n+1} \\cdot \\frac{n}{2n+1}\\) , \\(n \\in \\mathbb{N}\\); Answer \\(\\lim\\limits_{n \\rightarrow \\infty} ({-1})^{n+1}\\cdot\\frac{n}{2n+1}\\stackrel{:n}{=} \\lim\\limits_ {n \\rightarrow \\infty} ({-1})^{n+1}\\frac{1}{2+\\frac1n}\\). For \\(n\\) even (\\(n=2k\\)) the corresponding subsequence \\(({-1})^{2k+1}\\cdot\\frac{2k}{2\\cdot 2k+1} = ({-1})^{2k+1} \\frac{1}{2+\\frac1{2k}}\\) becomes \\(-\\frac{1}{2+\\frac1{2k}}\\) and converges to \\(-\\frac12\\) according to theorem 3.2 (ii). For \\(n\\) odd (\\(n=2k+1\\)) the corresponding subsequence \\(({-1})^{2(k+1)}\\cdot\\frac{2k+1}{2\\cdot (2k+1)+1} = ({-1})^{2(k+1)} \\frac{1}{2+\\frac1{2k+1}} = \\frac{1}{2+\\frac1{2k+1}}\\) and converges due to Theorem 3.2 (ii) to \\(\\frac12\\). Therefore the sequence \\(({-1})^{n+1}\\cdot\\frac{n}{2n+1}\\) does not converge. \\(({-1})^{n+1} \\cdot \\frac{1}{n}\\) , \\(n \\in \\mathbb{N}\\); Answer For \\(n\\) even (\\(n=2k\\)) the corresponding subsequence \\(({-1})^{2k+1}\\frac{1}{2k} = -\\frac{ 1}{{2k+1}}\\) according to theorem 3.2 (ii) to \\(0\\). For \\(n\\) odd (\\(n=2k+1\\)) the corresponding subsequence \\(({-1})^{2(k+1)}\\frac{1}{{2k) converges +1}} = \\frac{1}{{2k+1}}\\) according to theorem 3.2 (ii) also converges to \\(0\\). Therefore \\(\\lim\\limits_{n \\rightarrow \\infty} ({-1})^{n+1}\\cdot\\frac{1}{n} =0\\) according to theorem 3.4. \\(8 ‚àí 2n\\), \\(n \\in \\mathbb{N}\\). Answer \\(\\lim\\limits_{n \\rightarrow \\infty} 8 ‚àí 2n =-\\infty\\) (Theorem 3.3 (i) and (ii)). \\(\\sqrt{n^2-2n} - n\\), \\(n \\in \\mathbb{N}\\). Answer \\(\\lim\\limits_{n \\rightarrow \\infty} \\sqrt{n^2-2n} - n =\\lim\\limits_{n \\rightarrow \\infty} \\frac{(\\sqrt{n^2-2n} - n)(\\sqrt{n^2-2n} + n)}{\\sqrt{n^2-2n} + n} = \\lim\\limits_{n \\rightarrow \\infty} \\frac{n^2-2n- n^2}{n\\left(\\sqrt{1-\\frac2{n}} + 1\\right)}\\) \\(= \\lim\\limits_{n \\rightarrow \\infty} \\frac{-2n}{n\\left(\\sqrt{1-\\frac1{n^2}} + 1\\right)}=\\frac{-2 }{\\left(\\sqrt{1-0} + 1\\right)}=-1\\) (Theorem 3.2 (iii)). Exercise 3.3 (Limits II) For each assignment of \\((a_n)_{n\\in \\mathbb N}\\) and \\((b_n)_{n\\in \\mathbb N}\\), where \\(\\lim\\limits_{n \\rightarrow \\infty } (a_n)= 0\\) and \\(\\lim\\limits_{n \\rightarrow \\infty } (b_n)= + \\infty\\) holds, determine \\(\\lim\\limits_{n \\rightarrow \\infty } (a_n \\cdot b_n)\\). \\(a_n = 1/n\\), \\(b_n = n\\), \\(n \\in \\mathbb{N}\\); Answer \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac1{n}\\cdot n= \\lim\\limits_{n \\rightarrow \\infty} 1 = 1\\). \\(a_n = 1/n\\), \\(b_n= \\sqrt{n}\\), \\(n \\in \\mathbb{N}\\); Answer \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac1{n}\\cdot \\sqrt n= \\lim\\limits_{n \\rightarrow \\infty} \\frac1{\\sqrt n} = 0\\) (Theorem 3.3 (iii)). \\(a_n = 1/ \\sqrt{n}\\), \\(b_n = n\\), \\(n \\in \\mathbb{N}\\). Answer \\(\\lim\\limits_{n \\rightarrow \\infty} \\frac1{\\sqrt{n}}\\cdot n= \\lim\\limits_{n \\rightarrow \\infty} \\sqrt{n} = \\infty\\). The following property is very useful in determining whether a sequence converges or not. Definition 3.5 (Monotone sequences) A sequence\\((a_n) _{ n \\in \\mathbb{N} }\\) is monotonically increasing if \\(a_1 ‚â§ a_2 ‚â§ a_3 ‚â§ ...\\) , and it is monotonically decreasing if \\(a_1 ‚â• a_2 ‚â• a_3 ‚â• ...\\) . In case of strict inequalities (\\(&lt;\\) or \\(&gt;\\)), the sequence is strictly monotonically increasing or decreasing. Theorem 3.5 (Convergence of a monotone sequence) A monotone sequence converges if and only if it is bounded. proof ‚Äú\\(\\Leftarrow\\)‚Äù (from monotonic and bounded follows convergent) Let \\((a_n)_n\\) be a bounded, monotonically increasing sequence. Because of of boundedness there are \\(N\\in \\mathbb N \\text{ and }a\\in \\mathbb R\\) with \\(a_n \\leq a\\) for all \\(n&gt;N\\). We now choose \\(a\\) minimal with this property. For every \\(\\varepsilon &gt; 0\\) there is an \\(M\\) with \\(a ‚àí \\varepsilon &lt; a_M\\) (otherwise \\(a\\) would not be minimal). Because the sequence \\((a_n)_n\\) is monotonically increasing, \\(a_M ‚â§ a_m\\) holds for all \\(m ‚â• M\\). It is therefore for \\(m &gt; M\\) \\[a ‚àí \\varepsilon &lt; a_M ‚â§ a_m ‚â§ a &lt; a + \\varepsilon,\\] if \\(m\\) is large enough, almost all elements \\(a_m\\) are in the interval \\((a ‚àí \\varepsilon, a + \\varepsilon)\\). Or formulated differently: \\(|a_m-a|&lt;\\varepsilon\\) for \\(m&gt;M\\geq N\\). One argues in the same way if the sequence is monotonically decreasing. ‚Äú\\(\\Rightarrow\\)‚Äù (from convergent follows restricted) See theorem 3.1. Example 3.8 (Showing convergence) Show that \\(a_n = 1/{2^n}\\) , \\({ n \\in \\mathbb{N} }\\), converges. Answer The sequence \\(a_n = \\frac1{2^n}={\\left(\\frac 12\\right)}^n\\) is bounded for \\(n&gt;1\\) through \\(\\frac 12\\) from above and through \\(0\\) is bounded from below (see properties of the power function). So the sequence is bounden by \\(K=\\frac 12\\) for \\(n&gt;1\\). In addition, \\(a_{n+1}=\\frac 1{2^{(n+1)}}=\\frac 1{2^{n}\\cdot 2} =a_n\\cdot \\frac 12\\lt a_n\\) i.e.¬†strictly monotonically decreasing. According to theorem 3.5 the sequence converges. Exercise 3.4 (Show convergence) Show that the sequence \\(a_n = 1 /{(1 + r)}^n\\) (i) converges if \\(r ‚â• 0\\), and (ii) diverges if \\(‚àí1 &lt; r &lt; 0\\). Answer for \\(n&gt;1\\) the sequence is bounded by \\(K=\\frac 1{1+r}\\). In addition, \\(a_{n+1}=\\frac 1{(1+r)^{(n+1)}}=\\frac 1{(1+r)^{n}\\cdot (1+r) } =a_n\\cdot \\frac 1{1+r}\\lt a_n\\) for \\(\\frac 1{1+r}\\lt 1\\) i.e.¬†strictly decreasing. According to Theorem 3.5, the sequence for \\(r&gt;0\\) converges. The sequence has no upper limit: for arbitrarily large \\(K\\) there is an index \\(N\\) such that \\(a_n&gt;K\\) for all \\(n&gt;N\\). Since \\(‚àí1 &lt; r &lt; 0\\) we have \\(\\frac 1{1 + r}&gt;1\\) and \\(\\frac 1{(1 + r)}^n = \\left({\\frac 1{ 1+r}}\\right)^{n}\\) strictly increasing. In addition, \\(\\left({\\frac 1{1+r}}\\right)^{n}&gt;K\\) applies for \\(n&gt;\\log_{\\frac1{1+r}}K = N\\). Exercise 3.4 (show divergence) Show that the value of an investment of \\(0.01 \\ ‚Ç¨\\) in year \\(0\\) diverges over time (assuming a positive interest rate \\(r\\)). Answer The value of this asset is represented by the sequence: \\(a_n = 0.01\\cdot(1+r)^n\\). The sequence has no upper limit: for \\(K\\) of any size, there is an index \\(N\\) such that \\(a_n&gt;K\\) for all \\(n&gt;N\\). \\(0.01(1+r)^{n}&gt;K\\) applies for \\(n&gt;\\log_{1+r}(100K) = N\\). 3.4 Series Definition 3.6 (Series and their limits) Let \\((a_n)_{n\\in \\mathbb{N} }\\) be a sequence. The sequence obtained by summing up the terms of the sequence \\[s_n= \\sum_{t=1}^{n} {a}_{t}, {n\\in \\mathbb{N} }, \\] is called (infinite) series The limit of a series \\(\\sum_{t=1}^{ \\infty } {a}_{t}\\) is: \\[\\sum _{t=1}^{ \\infty } {a}_{t} = \\lim _{n\\rightarrow \\infty }\\sum _{t=1}^{ n } {a}_{t}= \\lim_{n\\rightarrow\\infty} s_n.\\] Hint: \\(a_t = (a_1+a_2+...a_n)\\) and \\(s_1=a_1, s_2=a_1+a_2\\) etc. (cumulative sum) Application: Series are useful, for example, for calculating the present value of certain cash flows (annuity calculation). Example 3.9 (Savings) If you pay \\(82.19 \\ Euro\\) into a savings account that earns \\(4\\%\\) interest, you get after 5 years: \\[82.19 \\cdot (1.04)^5 = 100 \\ euros.\\] In general: if you pay the amount \\(\\frac{100}{(1+r)^n}\\) into a savings account, you will receive \\(\\frac{100}{( 1+r)^n} \\cdot (1+r)^n=100 \\ Euro\\). How much do I have to invest in the savings account today so that I can withdraw \\(100 \\ Euro\\) for the next three years at the end of each year? Answer: \\(\\frac{100}{(1+r)} + \\frac{100}{(1+r)^2}+ \\frac{100}{(1+r)^3} =100 \\cdot \\sum_{t=1}^{3} \\frac{1}{(1+r)^t}\\) . How much can I withdraw (\\(A \\ Euro\\)) for the next three years at the end of each year, if I invest \\(1000\\) at the interest \\(r\\)? Answer: \\(1000=\\frac{A}{(1+r)} + \\frac{A}{(1+r)^2}+ \\frac{A}{(1+r)^3} =A \\cdot \\sum_{t=1}^{3} \\frac{1}{(1+r)^t}\\) . How much do I have to invest in the savings account today so that I can withdraw \\(100 \\ Euro\\) every year? Partial answer: \\(100 \\cdot \\sum_{t=1}^{\\infty } \\frac{1}{(1+r)^t} =\\ ???\\). For some sums and series there are closed formulas. Example 3.10 (convergent series) The following applies: \\(s_n= \\sum_{t=1}^{n} \\frac{1}{t^2+t}= \\frac{n}{n+1}\\). For the proof we use the method of complete induction: (i) First show that the claim holds for \\(n = 1\\). (ii) Assuming that the claim holds for \\(n\\), show that it also holds for \\(n + 1\\) (induction step). Regarding (i): one easily verifies that \\(s_1=\\frac{1}{2}\\) and that \\(\\frac{n}{n+1}= \\frac{1}{2}\\) . Regarding (ii): Assume that the assertion holds for \\(n\\) (i.e., \\(s_{\\color{red}n}=\\frac {\\color{red}{n}}{\\color{red }n+1}\\)); then for \\(n + 1\\): \\[ {s}_{\\color{red}{n+1}}=s_n+ \\frac{1}{(n+1)^2+(n+1)}= \\frac{n}{n+1 }+ \\frac{1}{(n+1)((n+1)+1)}\\] \\[ =\\frac{n(n+2)+1}{(n+1)(n+2)}= \\frac{(n+1)^2}{(n+1)(n+2) }= \\frac{n+1}{n+2} = \\frac{\\color{red}{(n+1)}}{\\color{red}{(n+1)}+1}\\] . Since series are special sequences, all statements about the convergence and divergence of sequences on series can be transferred accordingly. The following theorem is useful for determining whether a series converges or diverges. Theorem 3.6 (convergence of series) Let \\((a_n)_{n\\in \\mathbb{N} }\\), \\({n\\in \\mathbb{N} }\\), be a series with \\[\\lim\\limits_{n \\rightarrow +\\infty} \\ \\lvert \\frac{a_{n+1}} {a_n} \\rvert =a. \\] Then: (i) if \\(a &lt; 1\\), then the series \\(s_n\\), \\({n\\in \\mathbb{N} }\\); (ii) if \\(a &gt; 1\\), then the series \\(s_n\\), \\({n\\in \\mathbb{N} }\\); (iii) if \\(a = 1\\), then the series \\(s_n\\), \\({n\\in \\mathbb{N} }\\) can converge or diverge. \\(\\sum_{t=1}^{ \\infty } a_t\\) denotes not only the series, but also its limiting value. 3.4.1 Special Series 3.4.1.1 Geometric series Definition 3.7 (geometric series) The geometric series is given by \\(g_n=\\sum_{t=0}^{ n } x^t\\) , for \\(x \\in \\mathbb{R}\\). It is \\(\\lim\\limits_{n \\rightarrow \\infty} \\lvert \\frac{x^{n+1}}{x^n} \\rvert = \\lim\\limits_{x \\rightarrow \\infty} \\lvert x \\rvert = \\lvert x \\rvert\\). Using the theorem above, one immediately determines that the series converges in the case \\(|x| &lt; 1\\) and diverges in the case \\(|x| &gt; 1\\). If \\(x = 1\\), then the geometric series diverges, because \\(\\sum_{t=1}^{n} x=n\\), for all \\(n \\in \\mathbb{N}\\) . If \\(x = ‚àí1\\), then the geometric series diverges, because the values of the series alternate between \\(0\\) and \\(1\\) for \\(n \\in \\mathbb{N}\\). Theorem 3.7 (convergence of a geometric series) Let \\(x \\neq 1\\). Then: \\[\\sum_{t=0}^{n} x^t= \\frac{1-x^{n+1}}{1-x}, n \\in \\mathbb{N}.\\] Proof by induction For \\(n = 0\\) the following applies: \\[\\sum_{t=0}^{0} x^t= 1= \\frac{1-x^{0+1}}{1-x}.\\] Induction step \\(n \\rightarrow n + 1\\): \\[\\sum_{t=0}^{n+1} x^t = \\sum_{t=0}^{n} x^t + x^{n+1} = \\frac{1-x^{ n+1}}{1-x} + x^{n+1}\\] \\[= \\frac{1-x^{n+1}+x^{n+1}-x^{n+2}}{1-x} = \\frac{1-x^{n+2} }{1-x}.\\] Corollary 3.1 (Special geometric series) Let \\(|x| &lt; 1\\). Then: \\(\\sum_{t=0}^{ \\infty } x^t= \\frac{1}{1-x}\\) . Example 3.11 (Savings) (Example 3.9 cont.) The above result answers the question asked at the beginning: How much can I withdraw (\\(A\\)) for the next three years if I invest \\(1000\\) today at the interest \\(r\\)? \\[\\begin{align*}1000 &amp;= A\\cdot \\sum_{t=1}^3\\left(\\frac1{1+r}\\right)^t = A\\cdot \\left({\\color{red}{\\sum_{t=0}^3\\left(\\frac1{1+r}\\right)^t}}-1\\right)\\\\ &amp;=A\\cdot \\left({\\color{red}{\\frac{1-\\left(\\frac1{1+r}\\right)^4}{1-\\frac 1{1+r}}}}-1\\right). (Theorem ~3.7) \\end{align*}\\] For different interest rates \\(r\\), the withdraw amount is: How much money (\\(K_0\\)) do I have to put in a savings account today so that I can withdraw \\(100 \\ Euro\\) every year? Answer: \\[\\begin{align*} 100\\cdot \\sum_{t=1}^{ \\infty } \\frac{1}{(1+r)^t}&amp;=100 \\cdot [ \\frac{1}{1-(1/(1+ r))}- \\frac{1}{(1+r)^0}] \\\\ &amp; =100 \\cdot [ \\frac{1}{(1+r-1)/(1+r)}-1]=100 \\cdot [ \\frac{1+r}{r}-1]= \\frac{100}{r}.\\\\ &amp;(Corollary~3.1)\\end{align*}\\] For different interest rates \\(r\\), the required investment amount is: 3.4.1.2 Harmonic series\\(^\\ast\\) Definition 3.8 (Harmonic series) The harmonic series is given by \\(h_n=\\sum_{t=1}^{n} \\frac{1}{t}\\) . Although the underlying sequence \\((1/t) \\ _ {t \\in \\mathbb{N} }\\) converges, the series diverges. Example 3.12 (Collecting Coupons) Source: https://en.wikipedia.org/wiki/Coupon_collector%27s_problem In probability theory, the ‚Äòcoupon collector‚Äôs problem‚Äô describes ‚Äúcollect all coupons and win‚Äù contests. It asks the following question: If each box of a brand of cereals contains a coupon, and there are \\(n\\) different types of coupons, what is the probability that more than \\(t\\) boxes need to be bought to collect all \\(n\\) coupons? An alternative statement is: Given \\(n\\) coupons, how many coupons do you expect you need to draw with replacement before having drawn each coupon at least once? The mathematical analysis of the problem reveals that the expected number of trials needed grows with \\(n\\). For example, when \\(n=50\\) it takes about \\(225\\) trials. Calculation: \\[50(1 + 1/2 + 1/3 + ... + 1/50) = 224.9603\\approx 225\\] is the expected number of trials to collect all \\(50\\) coupons. Calculating the expectation Let time \\(T\\) be the number of draws needed to collect all \\(n\\) coupons, and let \\(t_i\\) be the time to collect the \\(i\\)-th coupon after \\(i-1\\) coupons have been collected. Then \\(T=t_1 + \\cdots + t_n\\). Observe that the probability of collecting a new coupon is \\(p_i = \\frac{n - (i - 1)}{n} = \\frac{n - i + 1}{n}\\) Therefore, \\(t_i\\) has geometric distribution with expectation \\(\\frac{1}{p_i} = \\frac{n}{n - i + 1}\\). By the linearity of expectations we have: \\[\\begin{align} \\operatorname{E}(T) &amp; {}= \\operatorname{E}(t_1 + t_2 + \\cdots + t_n) \\\\ &amp; {}= \\operatorname{E}(t_1) + \\operatorname{E}(t_2) + \\cdots + \\operatorname{E}(t_n) \\\\ &amp; {}= \\frac{1}{p_1} + \\frac{1}{p_2} + \\cdots + \\frac{1}{p_n} \\\\ &amp; {}= \\frac{n}{n} + \\frac{n}{n-1} + \\cdots + \\frac{n}{1} \\\\ &amp; {}= n \\cdot \\left(\\frac{1}{1} + \\frac{1}{2} + \\cdots + \\frac{1}{n}\\right) \\\\ &amp; {}= n \\cdot h_n. \\end{align}\\] The above can be modified slightly to handle the case when we‚Äôve already collected some of the coupons. Let \\(k\\) be the number of coupons already collected, then: \\[\\begin{align} \\operatorname{E}(T_k) &amp; {}= \\operatorname{E}(t_{k+1} + t_{k+2} + \\cdots + t_n) \\\\ &amp; {}= n \\cdot \\left(\\frac{1}{1} + \\frac{1}{2} + \\cdots + \\frac{1}{n-k}\\right) \\\\ &amp; {}= n \\cdot h_{n-k} \\end{align}\\] By Cmglee - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=30224158 Theorem 3.8 (Divergence of Harmonic Series) The harmonic series, given by \\(\\sum_{t=1}^{n} \\frac{1}{t}\\) , \\(n \\in \\mathbb{N}\\), diverges. The following applies: \\[\\lim\\limits_{n \\rightarrow \\infty } \\left| \\frac{1/(n+1)}{1/n} \\right| = \\lim\\limits_{n \\rightarrow \\infty } \\frac{n}{n+1} = 1,\\] so that the above theorem 3.6 cannot be used to determine convergence. Proof Alternatively, the harmonic series can be written as \\(\\left(\\sum_{k=1}^{2^{n}} \\frac{1}{k}\\right)_{n \\in \\mathbb{N}}\\) write down. The sequence \\((\\frac1k)_{k\\in \\mathbb N}\\) is increasing. If \\(n\\geq m\\), then \\(\\frac 1n\\leq \\frac 1m\\). Accordingly, we can skilfully estimate the summands downwards and then summarize them: \\[\\begin{aligned} \\sum_{k=1}^{2^{n}} \\frac{1}{k} &amp;=1+\\color{green}{\\frac{1}{2}}+\\color{purple}{\\left(\\frac{1}{3}+\\frac{1}{4}\\right)}+\\color{blue}{\\left(\\frac{1}{5}+\\frac{1}{6}+\\frac{1}{7}+\\frac{1}{8}\\right)}+\\\\\\\\ &amp;+\\ldots+\\color{orange}{\\left(\\frac{1}{2^{n-1}+1}+\\ldots+\\frac{1}{2^{n}-1}+\\frac{1}{2^{n}}\\right)} \\\\\\\\ &amp; \\ \\downarrow \\text {bound the summands from above: } \\color{purple}{\\frac{1}{3} \\geq \\frac{1}{4}} \\text { und } \\color{blue}{\\frac{1}{5} \\geq \\frac{1}{6} \\geq \\frac{1}{7} \\geq \\frac{1}{8}} \\text { und } \\ldots \\\\ &amp; \\geq 1+\\color{green}{\\frac{1}{2}}+\\color{purple}{\\left(\\frac{1}{4}+\\frac{1}{4}\\right)}+\\color{blue}{\\left(\\frac{1}{8}+\\frac{1}{8}+\\frac{1}{8}+\\frac{1}{8}\\right)}+\\ldots+\\color{orange}{\\left(\\frac{1}{2^{n}}+\\ldots+\\frac{1}{2^{n}}+\\frac{1}{2^{n}}\\right)} \\\\\\\\ &amp; \\downarrow \\ \\text{combine the summands} \\\\ &amp;=1+\\color{green}{\\frac{1}{2}}+\\color{purple}{2 \\cdot \\frac{1}{4}}+\\color{blue}{4 \\cdot \\frac{1}{8}}+\\ldots+\\color{orange}{2^{n-1} \\cdot \\frac{1}{2^{n}}} \\\\\\\\ &amp;=1+\\underbrace{\\color{green}{\\frac{1}{2}}+\\color{purple}{\\frac{1}{2}}+\\color{blue}{\\frac{1}{2}}+\\ldots+\\color{orange}{\\frac{1}{2}}}_{n \\text { summands}} \\\\ &amp;=1+\\frac{n}{2} \\end{aligned}\\] This means: \\(\\quad \\lim _{n \\rightarrow \\infty} \\sum_{k=1}^{2^{n}} \\frac{1}{k} \\geq \\lim _{n \\rightarrow \\infty} 1 +\\frac{n}{2}=\\infty\\). This shows us that the sequence \\(\\left(\\sum_{k=1}^{2^{n}} \\frac{1}{k}\\right)_{n \\in \\mathbb{N}}\\) tends towards infinity and thus diverges. "],["continuity-of-functions.html", "Chapter 4 Continuity of functions 4.1 Pointwise continuity 4.2 Continuous functions and their properties", " Chapter 4 Continuity of functions Continuity of functions is an important concept used in a variety of fields, including economics. Intuitively, a function is continuous if its graph has no ‚Äúbreaks‚Äù or ‚Äújumps‚Äù. Example 4.1 (production function) A production function links inputs and outputs of a production process; formally: the output \\(y = f (x)\\) is generated using the input \\(x\\) and the production function \\(f\\). The production function of a car manufacturer is \\(y = x/1050\\), where \\(y\\) denotes the number of cars (output) and \\(x\\) denotes the number of screws (input). The domain of the function is \\(\\left\\{ 1050n:n \\in \\mathbb{N} \\right\\}\\) = \\(\\left\\{ 1,050, 2,100, 3,150, ... \\right\\}\\). In practice it is easier to work with the production function \\(y = x/1050\\), with \\(x \\in \\mathbb{R_+}\\), e.g.¬†to solve decision problems. Exercise 4.1 (Bonus) The sellers of the guitar factory where Sophia is currently doing her internship receive monthly: a base salary of \\(800‚Ç¨\\); plus a commission of \\(1\\%\\) per \\(‚Ç¨\\) on the sales volume; plus a bonus of \\(500‚Ç¨\\) if turnover exceeds \\(20,000‚Ç¨\\). Let \\(S\\) be the sales volume for a month; the salary of a seller is: \\(P = \\begin{cases} 800+0.01\\cdot S, &amp; if \\ S&lt;20000 \\\\ 1300+0.01\\cdot S &amp;if \\ S \\geq 20000 \\end{cases}\\) One day before the end of the month, three salespeople have achieved the following sales volumes: \\(‚Ç¨26000\\), \\(‚Ç¨18500\\), \\(‚Ç¨6000\\). Who will work the hardest on the final day? Answer Employee 2, because then he will probably reach the threshold for the bonus payment (‚Ç¨20000). What could possibly be a better motivational incentive for guitar salespeople? Two possible answers (other alternatives are conceivable): Option 1 A multi-level bonus Option 2 A continuous salary function with a steeper slope from \\(‚Ç¨20000\\) sales. 1 2 3 4 Submit 4.1 Pointwise continuity We first consider the continuity of a function \\(f (x)\\) at a point. Definition 4.1 (Pointwise continuity) The function \\(f:D \\rightarrow \\mathbb{R}\\), with \\(D \\subseteq \\mathbb{R}\\), is continuous in \\(a \\in D\\), if for every sequence \\(( x_n)_{n \\in \\mathbb{N} }\\), which converges to \\(a\\), it holds that \\(f (x_n)\\) converges to \\(f (a)\\). Formally: \\(\\lim\\limits_{n \\rightarrow \\infty} x_n=a \\ \\Rightarrow \\ \\lim\\limits_{n \\rightarrow \\infty} f(x_n)=f(a)\\) . Since this applies to every sequence, we can neglect the reference to a specific sequence and write: \\(\\lim \\limits_{x \\rightarrow a} f(x)=f(a)\\). The following examples show how pointwise continuity can be understood. Example 4.2 (Pointwise continuity I) We show that \\(f (x) = x^2\\) , \\(x \\in \\mathbb{R}\\), is continuous for any \\(a \\in \\mathbb{R}\\). Let \\((x_n)_{n \\in \\mathbb{N} }\\) be a sequence with \\(\\lim\\limits_{n \\rightarrow \\infty} x_n=a\\). If we choose any \\(Œ¥ &gt; 0\\), then \\(|x_n ‚àí a| &lt; \\delta\\) applies to all \\(n\\) that are large enough (e.g.¬†\\(n &gt; N_\\delta\\)). Then, we have: \\(\\lvert f(x)-f(a) \\rvert = \\lvert x_n^2-a^2 \\rvert\\) \\(= \\lvert (x_n-a) (x_n-a+2a)\\rvert\\) \\(= \\lvert x_n-a \\rvert \\lvert x_n-a+2a \\rvert\\) \\(\\leq \\lvert x_n-a \\rvert ( \\lvert x_n-a \\rvert+ \\lvert 2a \\rvert )\\) \\(&lt; \\delta ( \\delta+2 \\lvert a \\rvert )\\) Since \\(\\delta &gt; 0\\) can be chosen arbitrarily small, the result is that the distance \\(|f (x_n) ‚àí f (a)|\\) becomes arbitrarily small if only \\(n\\) is large enough chooses. Example 1.1 (Discontinuity of a function at 0) The function \\(f(x) = \\begin{cases} +1, &amp;if \\ x \\leq 0\\\\ -1, &amp;if\\ x&gt;0 \\end{cases}\\), is discontinuous at \\(0\\). We choose the sequence for \\(x\\) \\(x_n = 1/n \\cdot (‚àí1)^n\\) , \\(n \\in \\mathbb{N}\\) which converges to zero. The following graphic shows \\(x_n\\) and \\(f (x_n) = (‚àí1)^n\\) , \\(n = 1, ... , 20\\). So it turns out that \\(\\lim_ {x \\rightarrow \\infty } x_n = 0\\), whereas \\(f (x_n)\\) has no limit, from which the discontinuity of \\(f\\) at the point \\(0\\) follows. The same can be seen from the following graph: Although \\(x_1,x_2, ...\\) tend towards \\(0\\), the values f\\((x_1),f (x_2), ...\\) jump between \\(‚àí1\\) and \\(1\\) back and forth. Even if the function \\(f(x) = \\begin{pmatrix} +1, if \\ x \\leq 0\\\\ -1, if\\ x&gt;0 \\end{pmatrix}\\), from the previous example is discontinuous in \\(0\\), it satisfies a weaker form of continuity in \\(0\\). Another perspective on the point-wise continuity of a function is provided by the following direction-dependent consideration of the function‚Äôs behavior. Definition 4.2 (Left and right continuity) A function \\(f:D \\rightarrow \\mathbb{R}\\) is left-continuous in \\(a \\in D\\), if for every sequence \\((x_n)_{n\\in \\mathbb N }\\), which converges from below to \\(a\\), \\(f (x_n)\\) converges to \\(f (a)\\), i.e. \\(\\lim _{x \\uparrow a} f(x)= \\lim _{x \\rightarrow a^-} f(x) = f(a)\\). Similarly \\(f:D \\rightarrow \\mathbb{R}\\) is right continuous in \\(a \\in D\\) if \\(f (x_n)\\) converges to \\(f (a)\\) for every sequence \\((x_n)_{n\\in \\mathbb N}\\) converging to \\(a\\) from above, i.e. \\(\\lim _{x \\downarrow a} f(x)= \\lim _{x \\rightarrow a^+} f(x) = f(a)\\). By considering limit values, one can check the pointwise left and right continuity. The following theorem also gives us an approach on how to use the concepts of left and right continuity for determining whether or not a function is continuous at a given point. Theorem 4.1 (pointwise continuity) A function \\(f:D \\rightarrow \\mathbb{R}\\) is continuous in \\(a \\in D\\) if and only if \\(\\lim _{x \\uparrow a} f(x)= \\lim _{x \\downarrow a} f(x) = f(a)\\). Example 4.3 (check continuity) Let \\(f:[0,10] \\rightarrow \\mathbb{R}\\) be defined as \\(f(x) = \\begin{cases} \\lvert x-2 \\rvert -2, &amp;\\text{if} \\ 0 \\leq x&lt;2 \\ \\text{or} \\ 2 &lt; x \\leq 6 \\\\ \\frac{2}{x-6 } -2, &amp;\\text{if} \\ 6&lt; x &lt;8 \\\\ (x-9)^3-1, &amp;\\text{if} \\ 8 \\leq x \\leq 10 \\\\ 1, &amp;\\text{if} \\ x=2 \\end{cases}\\). The function \\(f\\) is discontinuous in three points: \\(f (6) = 2\\), but \\(\\lim_{x\\downarrow 6} f (x) = \\infty\\); \\(f (8) = ‚àí2\\) applies, but \\(\\lim_{x\\uparrow 8} f (x) = ‚àí1\\). It is \\(f (2) = 1\\), but \\(\\lim_{x\\uparrow 2} f (x) = \\lim_{x\\downarrow 2} f (x) = ‚àí2 \\neq f (2)\\) . 4.2 Continuous functions and their properties Continuity on a domain of a function: So far we have considered continuity at a point \\((a \\in D)\\). Now we extend this deÔ¨Ånition to a range. Definition 4.3 (Continuous function) A function \\(f : D \\rightarrow R, D \\subseteq \\mathbb R\\) is called continuous on \\(D\\) if it is continuous at every point \\(a \\in D\\). The following theorems give us the properties of continuous functions. Theorem 4.2 (Continuous functions) Let \\(f\\) and \\(g\\) be continuous functions, and let \\(c \\in \\mathbb {R}\\). Then the following functions are also continuous: \\(c f (x)\\), \\(f (x) + c\\), \\(f (x) \\pm g(x)\\), \\(f (x) \\cdot g(x)\\), \\(f (x)/g(x)\\), for \\(g(x) \\ \\neq 0\\), \\(f^{ (‚àí1)} (x)\\), if it exists. Theorem 4.3 (Composition of continuous functions) Let \\(f : D \\rightarrow \\mathbb {R}\\) and \\(g : E \\rightarrow \\mathbb {R}\\) be functions with \\(f (D) \\subset E\\) if \\(f\\) and \\(g\\) are continuous, then the function is also \\(g \\circ f:D \\rightarrow \\mathbb{R} , \\ g(f(x))\\), continuous. Submit "],["differential-calculus.html", "Chapter 5 Differential calculus 5.1 Definition of the tangent line 5.2 Definition of the derivative 5.3 Differentiability 5.4 Derivation rules 5.5 The rule of L‚ÄôH√¥pital 5.6 Higher order derivatives 5.7 Taylor‚Äôs theorem", " Chapter 5 Differential calculus The derivation of a function describes the change in one variable in response to the change in another variable. Examples in economics: How does a company change its production level as a result of increased costs? How does a change in the money supply affect inflation? How can I structure my consumption in such a way that my utility is at its maximum? Implicitly this question is covered by the functional link \\(y = f (x)\\). Explicitly this is expressed as the influence of a change in \\(x\\), written as \\(\\Delta x\\), on the change in \\(y\\), written as \\(\\Delta y\\). In economics, this type of analysis is also called limit analysis. For example, profit maximization: ‚ÄúA profit-maximizing firm increases its output until marginal revenue (\\(\\Delta R\\)) equals or exceeds marginal cost (\\(\\Delta C\\)).‚Äù 5.1 Definition of the tangent line A colloquial description of the tangent line is as follows: ‚ÄúA tangent line is a straight line that touches a function at only one point.‚Äù In the graph, the line \\(l_P\\) only touches the function at the point \\(P\\) without intersecting the function at any other point. For a smooth function the slope of the tangent is identical to the slope of the function at the point of contact. The gradient of the tangent in \\(P\\) corresponds to the derivative of \\(y = f (x)\\) at the point \\(P\\). The above statement covers well our general understanding of the tangent, but does not serve as a definition. The tangent may intersect the function at a point farther away; therefore we have to restrict ourselves to suitable neighborhoods of the point \\(P\\). In some cases, the tangent can even intersect the function, as here in the example \\(y = x^3\\) at \\(x = 0\\). 5.1.1 Secant and tangent lines We therefore turn to a formal derivation of the derivative concept. First, we define other concepts that play a role in defining a tangent. Let \\(P = (x_1, f (x_1))\\) and \\(Q = (x_2, f (x_2))\\) be two points in the graph of the function \\(f\\) . The secant of \\(P\\) and \\(Q\\) is the straight line connecting \\(P\\) and \\(Q\\). The slope of the secants, called the difference quotient, is \\({m}_{PQ}= \\frac{f(x_2)-f(x_1)}{x_2-x_1}=: \\frac{\\triangle y}{ \\triangle x}\\) , where \\(\\Delta y = f (x_2) ‚àí f (x_1)\\) and \\(\\Delta x = x_2 ‚àí x_1\\). 5.1.2 From the secant to the tangent line Now fix \\(P = (x_0,f (x_0))\\) and consider a sequence of values \\(({x_n})_{n \\in \\mathbb{N}}\\), which against \\(x_0\\) converges. This is equivalent to the formulation that \\(\\Delta x_n = x_n ‚àí x_0\\) converges to \\(0\\). If the slopes of the secants exist for every possible such sequence and these slopes converge to a limit \\(m^*\\), then the tangent is the straight line with slope \\(m^*\\) that touches \\(P\\). Definition 5.1 (Tangent line) Let \\(f\\) be defined on an open interval around \\(x_0\\). If \\(m^* = \\lim _{ \\triangle x \\rightarrow 0} \\frac{f(x_0+ \\triangle x) -f(x_0) }{ \\triangle x}\\) exists, then the straight line through \\((x_0,f (x_0))\\) with slope \\(m^*\\) is the tangent of \\(f\\) at the point \\(x_0.\\) Example 5.1 (secant and tangent) Let \\(f (x) = x^2\\) , \\(P = (2, 4)\\) and \\(Q=(4, 16)\\). One easily checks that \\(\\Delta x = 2\\) and \\(\\Delta y = 12\\), so that the slope of the secants is \\(\\Delta y/\\Delta x = 12/2 = 6\\). If one chooses \\(Q&#39; = (5,25)\\), the secant slope is \\(\\Delta y/\\Delta x = 21/3 = 7\\). Now choose the sequence \\(\\Delta x_n = 1/n\\), \\(n \\geq 1\\). Then: \\(\\Delta x_n \\rightarrow 0\\), if \\(n \\rightarrow \\infty\\). For any point \\(x\\) we determine the slope of the tangent: \\[\\begin{align*}\\frac{f(x+ \\triangle x_n)-f(x)}{ \\triangle x_n} &amp;= \\frac{(x+1/n)^2-x^2}{1/n} \\\\ &amp; = \\frac{x^2+2x/n+1/n^2-x^2}{1/n}\\\\ &amp;= 2x + \\frac{1}{n}, \\end{align*}\\] and \\(\\lim_{ \\triangle x \\rightarrow 0} \\frac{f(x+ \\triangle x_n)-f(x)}{ \\triangle x_n} = \\lim_{n\\rightarrow\\infty}(2x+1/n) = 2x\\) (= the derivative of \\(f(x)=x^2\\) ). 5.2 Definition of the derivative Definition 5.2 (Derivative) The derivative (the differential quotient) of a function \\(f\\) at the point \\(x\\), written as \\(f&#39; (x)\\), is the slope of the tangent at that point: \\(f&#39;(x)= \\lim_{ \\triangle x \\rightarrow 0 } \\frac{f(x+ \\triangle x) - f(x)}{ \\triangle x}\\) . The so-called Leibniz notation of the derivative is \\(f&#39;(x)= \\frac{df(x)}{dx}\\), where the differential operator \\(d\\) expresses an infinitesimally small change. Definition 5.3 (Differential) Let \\(f\\) be a function with derivative \\(f&#39;\\). The differential of \\(f\\) at \\(x\\) is \\(df (x) = f &#39; (x) dx\\). The differential expresses that \\(f\\) changes at the point \\(x\\) approximately by \\(f&#39; (x) dx\\), where - to put it bluntly - \\(dx\\) is an infinitesimal change of \\(x\\) denotes and \\(f&#39;\\) specifies the direction of change of \\(f\\). Example 5.2 (Total cost and marginal cost) A firm‚Äôs total cost function \\(y \\mapsto C( y )\\) expresses costs as a function of the number \\(y\\) units produced. The ratio \\(\\frac{ \\triangle C}{ \\triangle y} = \\frac{C(y+ \\triangle y) - C( y )}{ \\triangle y}\\) reflects the average additional cost per unit if additional \\(\\Delta y\\) units are produced. The limit of this ratio when \\(\\Delta y \\rightarrow 0\\), is the instantaneous rate of change; in economics, this rate represents the marginal cost (or marginal cost): \\(\\lim_{ \\triangle y \\rightarrow 0 \\ } \\frac{ \\triangle C}{ \\triangle y} = \\lim_{ \\triangle y \\rightarrow 0 \\ } \\frac{C(y+ \\triangle y) - C( y ) }{ \\triangle y} = C&#39;( y )\\) Example of a linear cost function: In practice, the assumption of a linear cost function, i.e.¬†constant marginal costs, is often unrealistic (see earlier example of cost functions). Instead, higher production often leads to higher marginal costs (at least in the short run). This is expressed by a quadratic cost function, for example: 5.3 Differentiability Definition 5.4 (Differentiability) The function \\(f\\) is differentiable at the point \\(x\\) if it is defined in an open neighborhood of \\(x\\) and if \\[ \\lim_{ \\triangle x \\rightarrow 0 \\ } \\frac{ f(x+ \\triangle x)-f(x)}{ \\triangle x } \\] exists and is finite. A function is said to be differentiable if it is differentiable anywhere in its domain. If \\(f\\) is differentiable in \\(x\\), then the left derivative and the right derivative exist and take the same value: \\(\\lim_{ \\triangle x \\uparrow 0 \\ } \\frac{ f(x+ \\triangle x)-f(x)}{ \\triangle x } = \\lim_{ \\triangle x \\downarrow 0 \\ } \\frac{ f(x+ \\triangle x)-f(x)}{ \\triangle x }\\). Example 5.3 (Differentiability) We consider the function \\(f(x)=\\begin{cases} x, &amp;if~ x&lt;1 \\\\ 2-x, &amp;if \\ x \\geq 1 \\end{cases}\\). Although the function is continuous at the point \\(x = 1\\), it is not differentiable at this point. Because: At the point \\(x = 1\\) applies \\(\\lim_{ \\triangle x \\uparrow 0 } \\frac{ f(1+ \\triangle x)-f(1)}{ \\triangle x } = \\lim_{ \\triangle x \\uparrow 0 } \\frac{ 1+ \\triangle x-1 }{ \\triangle x } =1\\) and \\(\\lim_{ \\triangle x \\downarrow 0 } \\frac{ f(1+ \\triangle x)-f(1)}{ \\triangle x } = \\lim_{ \\triangle x \\downarrow 0 } \\frac{ (2 -(1+ \\triangle x))-(2-1) }{ \\triangle x } = -1\\). Details We consider the connection between differentiability and continuity. Theorem 5.1 (Differentiability and Continuity) If a function \\(f\\) is differentiable at \\(x\\), then it is also continuous at \\(x\\). The converse statement is generally not true, as the previous example shows. One can equivalently say: Continuity is a necessary but not a sufficient condition for differentiability. We extend the notion of differentiability to closed intervals. Definition 5.5 (Differentiability on an interval) A function \\(f\\) , defined on the interval \\([a,b]\\), is differentiable on \\([a,b]\\) if: the right derivative for \\(f (a)\\) exists; the left derivative for \\(f (b)\\) exists; \\(f\\) is differentiable on the open interval \\((a,b)\\). 5.4 Derivation rules With the help of the following rules we can determine derivations concretely (always assuming differentiability). Theorem 5.2 (derivation rules) In the following, let \\(c\\), \\(m\\), \\(n\\) and \\(b\\) be constants. \\[\\begin{equation*} \\begin{array}[t]{lll} \\hline \\text{(function) type} &amp; \\text{function} &amp; \\text{derivation}\\\\\\hline \\text{constant function} &amp; f(x)=c &amp; f^\\prime(x)=0\\\\ \\text{linear function} &amp; f(x)=mx + b &amp; f^\\prime(x)=m\\\\ \\text{power function} &amp; f(x)=x^n &amp; f^\\prime(x)=n\\, x^{n-1}\\\\ \\text{scaling} &amp; g(x)=c\\, f(x) &amp; g^\\prime(x)=c\\, f^\\prime(x)\\\\ \\text{summation rule} &amp; f(x)=g_1(x) + g_2(x) &amp; f^\\prime(x) = g_1^\\prime(x) + g_2^\\prime(x)\\\\ &amp; f(x)=\\sum_{i=1}^n g_i(x) &amp; f^\\prime(x) = \\sum_{i=1}^n g_i^\\prime(x)\\\\ \\text{product rule} &amp; f(x)=g(x)\\, h(x) &amp; f^\\prime(x) = g^\\prime(x) h(x) + g(x) h^\\prime(x)\\\\ \\text{chain rule} &amp; f(x)=g(h(x))&amp; f^\\prime(x)=g^\\prime(h(x))\\, h^\\prime(x)\\\\ \\hline \\end{array} \\end{equation*}\\] \\[\\begin{equation*} \\begin{array}[t]{lll} \\hline \\text{(function) type}\\!\\!\\!&amp; \\text{function} &amp; \\text{derivation}\\\\\\hline \\text{ratio rule} &amp; \\displaystyle f(x)=\\frac{g(x)}{h(x)}, h(x)\\not=0 &amp; \\displaystyle f^\\prime(x) = \\frac{g^\\prime(x) h(x) - g(x) h^\\prime(x)} {(h(x))^2}\\\\ \\text{inverse} &amp; y=f(x)\\text{, where }&amp; \\displaystyle (f^{(-1)})^\\prime(y) = \\frac{1}{f^\\prime(x)} = \\frac{1}{f^\\prime(f^{(-1)}(y))}\\\\ &amp; f^{(-1)}(y)=x \\text{ exists } &amp; \\\\ &amp;\\text{and } f^\\prime(x)\\not=0 &amp; \\\\ \\text{logarithm} &amp; \\ln (x) &amp; \\displaystyle\\ln^\\prime(x)=\\frac{1}{x}\\\\ &amp; \\log_a (x) &amp; \\displaystyle\\log_a^\\prime(x)=\\frac{1}{x\\cdot \\ln (a)}\\\\ \\text{sine function} &amp; \\sin(x) &amp; \\sin^\\prime(x)=\\cos(x)\\\\ \\text{cosine function} &amp; \\cos(x) &amp; \\cos^\\prime(x)=-\\sin(x)\\\\ \\text{exponential function} &amp; e^{x} &amp; (e^{x})^\\prime=e^{x}\\\\ &amp; a^{x} &amp; (a^{x})^\\prime=a^{x}\\ln (a)\\\\\\hline \\end{array} \\end{equation*}\\] Proof In general, derivations can be made via the definition of the differential quotient (definition 5.2) and already proven rules are determined. Constant function \\(f(x)=c\\): The derivative is determined through \\[\\begin{equation*} f^\\prime(x) = \\lim_{\\Delta x\\rightarrow 0} \\frac{f(x+\\Delta x)-f(x)}{\\Delta x} = \\lim_{\\Delta x\\rightarrow 0} \\frac{c-c}{\\Delta x}=0. \\end{equation*}\\] For power functions \\(f(x)=x^n\\) we use the binomial formula \\[\\begin{equation*} (x+y)^n = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} y^k \\end{equation*}\\] and received \\[\\begin{align*} \\frac{(x+\\Delta x)^n - x^n}{\\Delta x} % &amp;= \\frac{\\sum _{k=1}^n \\binom{n}{k} x^{n-k} (\\Delta x)^k} {\\Delta x} % = \\sum_{k=1}^n \\binom{n}{k} x^{n-k} (\\Delta x)^{k-1} \\\\% &amp;= \\binom{n}{1} x^{n-1} + % \\underbrace{\\sum_{k=2}^n \\binom{n}{k} x^{n-k} (\\Delta x)^{k-1}}_{\\rightarrow 0 \\text{ for } \\Delta x\\rightarrow0}= n\\, x^{n-1} \\end{align*}\\] Product rule: For the product \\(f(x)=g(x) h(x)\\) we get where we used that: \\[\\begin{align*} \\lim_{\\Delta x\\rightarrow 0} \\frac{(g(x+\\Delta x) - g(x)) h(x+\\Delta x)} {\\Delta x}&amp;% = \\lim_{\\Delta x\\rightarrow 0} \\frac{(g(x+\\Delta x) - g(x))} {\\Delta x} \\, \\lim_{\\Delta x\\rightarrow 0} h(x+\\Delta x) \\end{align*}\\] Chain rule (\\(f(x)=g(h(x))\\)): Write first \\[\\begin{equation*} \\frac{g(h(x+\\Delta x)) - g(h(x))} {\\Delta x} % = \\frac{g(h(x+\\Delta x)) - g(h(x))} {h(x+\\Delta x)-h(x)} % \\cdot \\frac{h(x+\\Delta x)-h(x)} {\\Delta x} % \\end{equation*}\\] For the first term applies \\(\\lim_{\\Delta x\\rightarrow 0} h(x+\\Delta x)-h(x)=0\\), so that \\[\\begin{equation*} \\displaystyle \\frac{g(h(x+\\Delta x))-g(h(x))} {h(x+\\Delta x)-h(x)} \\rightarrow g^\\prime(h(x)). \\end{equation*}\\] The second term converges to \\(h^\\prime(x)\\). Quotient rule (\\(\\displaystyle f(x)=\\frac{g(x)}{h(x)}\\)): \\[\\begin{align*} \\left(\\frac{g(x)}{h(x)}\\right)^\\prime &amp;= \\left(g(x)) \\frac{1}{h(x)}\\right)^\\prime \\stackrel{\\text{product rule}}= g^\\prime(x) \\frac{1}{h(x)} + g(x) \\left(\\frac{1}{h(x)}\\right)^\\prime \\\\% &amp;= \\frac{g^\\prime(x) h(x)}{h(x)^2} + g(x) % \\underbrace{ \\left(h^{-1}(x)\\right)^\\prime.% } % _{\\stackrel{\\text{chain % rule, power %function}}=-1\\cdot % h^{-2}(x) \\cdot %h^\\prime(x)}, \\end{align*}\\] For \\(\\left(h^{-1}(x)\\right)^\\prime\\) we get with the Chain rule and the power rule: \\[\\begin{equation*} \\left(h^{-1}(x)\\right)^\\prime = -1\\cdot h^{-2}(x)\\cdot h^\\prime(x) = -\\frac{h^\\prime(x)}{h(x)^2}. \\end{equation*}\\] For the inverse we use \\(y=f(x)\\) and get with \\(\\Delta y=f(x+\\Delta x)-f(x)\\): \\[\\begin{align*} &amp;\\frac{f^{(-1)}(y+\\Delta y) - f^{(-1)}(y)} {\\Delta y} = \\frac{f^{(-1)}(f(x)+f(x+\\Delta x)-f(x)) - f^{(-1)}(f(x))} {f(x+\\Delta x) - f(x)}\\\\ &amp;= \\frac{f^{(-1)}(f(x+\\Delta x)) - f^{(-1)}(f(x))} {f(x+\\Delta x)-f(x)} = \\frac{\\Delta x}{f(x+\\Delta x)-f(x)} \\rightarrow \\frac{1}{f^\\prime(x)} \\end{align*}\\] For the derivative of the logarithm, first note that that \\(\\ln (a^x)=x\\cdot \\ln(a)\\), \\(\\ln(a/b)=\\ln (a)-\\ln (b)\\) and that \\(\\displaystyle \\lim_{n\\rightarrow \\infty} \\left(1+\\frac{x}{n}\\right)^n=\\text{e}^x\\). Then: \\[\\begin{equation*} \\ln^\\prime(x)% = \\frac{\\ln(x+\\Delta x)-\\ln (x)} {\\Delta x} % = \\frac{1}{\\Delta x} \\ln \\left(\\frac{x+\\Delta x}{x}\\right)% = \\ln\\left(\\left(\\frac{x+\\Delta x}{x}\\right)^{1/\\Delta x}\\right). \\end{equation*}\\] Set \\(\\displaystyle n=\\frac{x}{\\Delta x}\\) and note that \\(n\\rightarrow\\infty\\) if \\(\\Delta x\\rightarrow 0\\). With \\(n\\rightarrow\\infty\\): \\[\\begin{equation*} \\ln\\left(1+\\frac{1}{n}\\right)^{n/x}% = \\frac{1}{x} \\ln \\left(1+\\frac{1}{n}\\right)^n % \\rightarrow \\frac{1}{x} \\ln(\\text{e}) = \\frac{1}{x}, \\end{equation*}\\] Finally, for the exponential function we use, that \\[\\begin{equation*} \\left(\\ln(\\text{e}^x)\\right)^\\prime = x^\\prime=1, \\end{equation*}\\] and therefore, by applying the chain rule: \\(\\left(\\ln\\text{e}^x\\right)^\\prime=\\frac{1}{\\text{e}^x} (\\text{e}^x)^\\prime =1,\\) from which \\(\\left(\\text{e}^x\\right)^\\prime=\\text{e}^x\\) follows. Example 4.1 (Production function and marginal productivity) Consider the production function \\(TP(L) = L^a\\) , \\(a &gt; 0\\), which maps the input \\(L\\) (work) to the output \\(TP (L)\\). The marginal productivity is \\(MP (L) = dTP (L)/ \\ dL = aL^{a‚àí1}\\) ; if \\(a &gt; 1\\), then \\(MP (L)\\) is increasing in \\(L\\), \\(a = 1\\), then \\(TP (L) = L\\) and \\(MP (L) = 1\\), \\(a &lt; 1\\), then \\(MP (L)\\) falls in \\(L\\). Example 5.4 (Marginal revenue with the product rule) The revenue (sales) is determined from the price of a good multiplied by the quantity sold, i.e.¬†\\(TR(q) = pq\\). A competing firm will assume the price to be constant (market price): \\(\\bar{p}\\); the marginal revenue is therefore \\(MR(q) = dTR(q)/dq = \\bar{p}\\). From the point of view of a monopolist, quantity and price are determined by the demand function \\(q = D(p)\\) or by its inverse \\(p = D ^{(‚àí1)}(q) =: p(q)\\). The total revenue of the monopolist is \\(TR(q) = p(q) q\\) and the marginal revenue is \\(MR(q)=TR&#39;(q)= \\frac{dTR(q)}{dq} = \\frac{dp}{dq}q + p(q) \\frac{dq}{dq} = p&#39; (q)q+p(q)\\) Typically, \\(p&#39; (q) &lt; 0\\). Example 5.5 (Average and marginal cost with quotient rule) The average function of a function \\(f (x)\\), \\(x ‚â• 0\\), is given by \\(A(x)= \\frac{f(x)}{x}\\) . The quotient rule gives \\(A&#39;(x)= \\frac{f&#39;(x)x-1f(x)}{x^2} = \\frac{1}{x} \\left[ f&#39;(x)-A(x) \\right]\\) . with \\(f&#39;\\) being the marginal cost. Therefore: If \\(f&#39; (x) &lt; A(x)\\), then \\(A&#39;(x) &lt; 0\\); if \\(f&#39; (x) = A(x)\\), then \\(A&#39; (x) = 0\\) (Minimum); if \\(f&#39; (x) &gt; A(x)\\), then \\(A&#39; (x) &gt; 0\\). 5.5 The rule of L‚ÄôH√¥pital If \\(f (x) ‚Üí 0\\) and \\(g(x) ‚Üí 0\\) for \\(x ‚Üí a\\), then existence and determination of the limit \\(\\lim _{x \\rightarrow a} \\frac{f(x)}{g(x)}\\) not obvious at first. Examples: \\(\\lim _{x \\rightarrow 1} \\frac{x^2-1}{x-1} = 2\\), \\(\\lim _{x \\rightarrow 0} \\frac{ \\sin x}{x} = 1\\), \\(\\lim _{x \\rightarrow 0} \\frac{ 1 - \\cos x}{x} = 0\\) The first limit is easy to determine because \\(\\frac{x^2-1}{x-1} = \\frac{(x+1)(x-1)}{x-1} = x+1\\). The other two limits are not obvious. In this situation, L‚ÄôH√¥pital‚Äôs rule is often very helpful. Theorem 5.3 (The rule of L'H√¥pital) Let \\(f\\) and \\(g\\) in \\(x = a\\) be differentiable functions with \\(g&#39; (a) \\neq 0\\) and \\(\\lim _{x \\rightarrow a} f(x) = 0\\) and \\(\\lim _{x \\rightarrow a} g(x) = 0\\) or \\(\\lim _{x \\rightarrow a} f(x) = \\infty\\) and \\(\\lim _{x \\rightarrow a} g(x) = \\infty\\). If \\(\\lim _{x \\rightarrow a} \\frac{f&#39;(x)}{g&#39;(x)}\\) exists or if the limit is \\(\\pm\\infty\\), then it holds \\(\\lim _{x \\rightarrow a} \\frac{f(x)}{g(x)} = \\lim _{x \\rightarrow a} \\frac{f&#39;(x)}{g&#39;(x) }\\) . Exercise 5.1 (Limits with L'H√¥pital's rule) Check the following limits using L‚ÄôH√¥pital‚Äôs rule: \\(\\lim _{x \\rightarrow 1} \\frac{x^2-1}{x-1} = 2\\), \\(\\lim _{x \\rightarrow 0} \\frac{ \\sin x}{x} = 1\\), \\(\\lim _{x \\rightarrow 0} \\frac{ 1 - \\cos x}{x} = 0\\) Note: \\(\\sin&#39; (x) = \\cos(x)\\) and \\(\\cos&#39; (x) = ‚àí \\sin(x)\\). Answer \\(\\lim _{x \\rightarrow 1} \\frac{x^2-1}{x-1} = \\lim _{x \\rightarrow 1} \\frac{(x^2-1)&#39;}{(x-1)&#39;} = \\lim _{x \\rightarrow 1} \\frac{2x}{1} =2\\), \\(\\lim _{x \\rightarrow 0} \\frac{ \\sin x}{x} = \\lim _{x \\rightarrow 0} \\frac{(\\sin \\ x)&#39;}{(x)&#39;} = \\lim _{x \\rightarrow 0} \\frac{\\cos \\ x}{1} =1\\), \\(\\lim _{x \\rightarrow 0} \\frac{ 1 - \\cos x}{x} = \\ \\lim _{x \\rightarrow 0} \\frac{(1-\\cos \\ x)&#39;}{(x)&#39;} = \\lim _{x \\rightarrow 0} \\frac{-(- \\sin \\ x)}{1} = 0\\) 5.6 Higher order derivatives Repeated differentiation yields higher-order derivatives \\(f&#39;\\) , \\(f&#39;&#39;\\) , \\(f&#39;&#39;&#39;\\), etc. (if they exist). \\(f&#39;\\) is the first derivative, \\(f&#39;&#39;\\) is the second derivative, etc. We also write \\(f&#39;&#39;(x)= \\frac{d^2f(x)}{dx^2}\\) , etc.. The notation \\(f^{ (n)}\\) is also used for the \\(n\\)th derivative. Example 5.6 (Some higher-order derivatives) The first four derivatives of \\(f (x) = x^ 4\\) are \\(f&#39; (x) = 4x^3 , \\ f&#39;&#39;(x) = 12x^2 , \\ f&#39;&#39;&#39;(x) = 24x, f^{(4)}(x) = 24\\). All higher derivatives are \\(0\\), i.e.¬†\\(f ^{(n)} (x) = 0\\), for \\(n \\geq 5\\). If the first two derivatives exist, then a function is said to be twice differentiable. The second derivative can be used to determine whether a function is convex or concave. Theorem 5.4 (Derivatives of convex and concave functions) Let \\(D \\subset \\mathbb {R}\\) be an open interval and let \\(f: D \\rightarrow \\mathbb {R}\\) be twice differentiable. \\(f\\) is convex if and only if \\(f&#39;&#39;(x) \\geq 0\\) (concave: \\(f&#39;&#39;(x)\\leq 0\\)) for all \\(x \\in \\mathbb{D}\\). 5.7 Taylor‚Äôs theorem In practice, the following problem often arises: The value of a differentiable function \\(f\\) is difficult to calculate at \\(x\\); but the function value and all derivatives at a neighboring point \\(x_0\\) are known. Example 5.7 (Function value determination for ln(2)) The function value \\(\\ln(2)\\) is difficult to determine without a calculator. However, the following values of \\(f (x) = \\ln \\ x\\) at the position \\(x_0 = 1\\) are known: \\(f (1) = 0\\); \\(f&#39; (1) = 1\\); \\(f&#39;&#39;(x) = ‚àí1\\); \\(f&#39;&#39;&#39;(1) = 2\\); \\(f ^{(4)}(1) = ‚àí6\\); etc. From \\(f (x_0)\\), \\(f&#39; (x_0)\\), \\(f&#39;&#39;(x_0)\\), ‚Ä¶, the function value \\(f (x)\\) can be determined approximately. Example 5.8 (Approximation of a profit function) Consider the exponential form of the inverse demand function (a more realistic model for demand functions!): \\[p(q) = 100\\cdot e^{-0.01\\cdot q} = 100\\cdot\\exp(-0.01 q).\\] The profit function for a monopolist can be computed as: \\[\\pi(q) = p(q)\\cdot q -C(q),\\] where \\(C(q)\\) is the cost function. Assume the cost function adapts the linear representation \\(C(q)=10-0.01q\\). Then the profit is: \\[\\pi(q) = p(q)\\cdot q -C(q) = \\exp(-0.01 q) \\cdot q - 10 - 0.01\\cdot q.\\] Note: we can not solve for \\(q\\) if we set the profit to zero to find the break-even point (the red point on the graph)! (Try that :)) The question is: How can we find the Break-Even point. Theorem 5.5 (Taylor's theorem) Let \\(f\\) be an \\(n\\)-fold differentiable function. The Taylor formula (also Taylor expansion) of \\(f (x)\\) in the area around \\(x_0\\) is given by \\[\\begin{align*} f(x)&amp;=f(x_0)+\\sum_{k=1}^{n} \\left(\\frac{f^{(k)}(x_0)}{k!} (x-x_0)^k\\right) + R_n(x). \\end{align*}\\] where \\[\\begin{align*} f(x_0)+\\sum_{k=1}^{n} \\left(\\frac{f^{(k)}(x_0)}{k!} (x-x_0)^k\\right)&amp;=f(x_0)+ f^\\prime(x_0)(x-x_0) + \\frac{f^{\\prime\\prime}(x_0)}{2}(x-x_0)^2 \\\\ &amp;+ \\frac{f^{\\prime\\prime\\prime}(x_0)}{6}(x-x_0)^3+\\ldots + \\frac{f^{(n)}(x_0)}{n!} (x-x_0)^n \\end{align*}\\] is the Taylor polynomial and \\[ R_n(x)= \\frac{f^{(n+1)}( \\xi) }{(n+1)!} (x-x_0)^{n+1} \\] with \\(\\xi \\in [x_0,x]\\) is the remainder. If \\(R_n(x) \\rightarrow 0\\) for \\(n \\rightarrow \\infty\\), then the function value \\(f (x)\\) can be approximated by the Taylor polynomial. In particular, \\[f (x_0) + f&#39; (x_0)(x ‚àí x_0)\\] is a first-order Taylor expansion and it is a linear approximation of \\(f (x)\\). Example 5.9 (Function value approximation for ln(2)) We determine \\(f (x) = \\ln(x)\\) using the Taylor approximation with \\(x_0 = 1\\) from Example 5.7. The following applies: \\(f&#39;(x)= \\frac{1}{x}\\), \\(f&#39;&#39;(x)= - \\frac{1}{x^2}\\), \\(f&#39;&#39;&#39;(x)= - \\frac{2}{x^3}\\), \\(f^{(n)}(x)= \\frac{(-1)^{n+1}(n-1)!}{x^n}\\) Approximation by nth order Taylor polynomial: \\(f(x) \\approx (x-1)- \\frac{(x-1)^2}{2} + ... + (-1)^{n+1} \\ \\frac{(x- 1)^n}{n}\\) Convergence of the remainder for \\(1 &lt; x ‚â§ 2\\): from \\(1 &lt; Œæ &lt; x ‚â§ 2\\), i.e.¬†\\(0 &lt; (x ‚àí 1)/ Œæ ‚â§ 1/ 1 = 1\\), follows: \\(R_n(x)= \\frac{(-1)^{n+2} \\ n!}{ \\xi ^{n+1}(n+1)!}(x-1)^{n+1 }\\) \\(= (-1)^n\\frac{(x-1)^{n+1} }{ \\xi ^{n+1}(n+1)} \\rightarrow 0\\) for \\(n \\rightarrow \\infty\\). We determine \\(\\ln(2)\\) approximately using the Taylor polynomial \\(10\\)th order: \\(\\ln 2 ‚âà 1 ‚àí 1/2 + 1/3 ‚àí 1/4 + 1/5 ‚àí 1/6 + 1/7 ‚àí 1/8 + 1/9 ‚àí 1/10 = 0.6456\\). The error is in \\((\\frac{1}{2^{11} \\cdot 11}, 1/11)= \\left[ 0.000044; 0.0909091] \\right]\\). Exercise 5.2 (Interest rate sensitivity with Taylor approximation) For a portfolio of interest rate instruments, let \\(P(r)\\) be the market price depending on the interest rate \\(r&gt;0\\) (with a flat yield curve). Furthermore, \\[\\operatorname{DUR}(r):=-P&#39;(r)\\] denotes the absolute duration, which describes the change in the market price of the portfolio in the event of an absolute change in interest rates in the form of a sensitivity. For the current market interest rate \\(r=0.05\\), the market price of the portfolio is \\(2,400,000\\) and \\(\\operatorname{DUR}(0.05)=3,200,000\\) applies. Using Taylor‚Äôs first-order approximation, approximate the market price of the portfolio as interest rates rise to $0.07 and fall to $0.03. Answer "],["optimization.html", "Chapter 6 Optimization 6.1 Necessary conditions for maxima and minima 6.2 Second-order conditions 6.3 Optimization on an interval", " Chapter 6 Optimization Economic models are often based on the idea that a decision-maker makes an optimal decision based on possible alternatives. We formalize optimal decisions as maximizing or minimizing a function. For example: A company wants to minimize production costs or maximize profit; A consumer wants to maximize his utility; A (political) decision-maker wants to maximize social welfare. Optimization is central to economics, business administration, management, strategy, ‚Ä¶ In this chapter we cover the optimization of functions of one variable; Functions of several variables follow later. 6.1 Necessary conditions for maxima and minima Optimizing a function \\(f (x), x \\in D\\), means finding the value \\(x\\) at which an extreme value (also extremum) occurs; this can be a maximum or a minimum. In the case \\(D=\\mathbb{R}\\) there is an optimization problem without constraints. Definition 6.1 (Maximum, Minimum) The function \\(f\\) has a global maximum at the position \\(x ^‚àó\\) if: \\(f (x^‚àó ) \\geq f (x)\\) for all \\(x\\). Illustration A local maximum is at the position \\(\\hat{x}\\) if there is a \\(\\epsilon &gt;0\\) with \\(f ( \\hat {x}) \\geq f (x)\\) for \\(\\hat {x} ‚àí \\epsilon \\leq x \\leq \\hat {x} + \\epsilon\\). Illustration Similarly, \\(f\\) has a global minimum at \\(x^ ‚àó\\) if: \\(f (x^ ‚àó ) \\leq f (x)\\) for all \\(x\\). Illustration A local minimum is at \\(\\hat {x}\\) if there is a \\(\\epsilon &gt;0\\) with \\(f ( \\hat {x}) \\leq f (x)\\) for \\(\\hat {x} ‚àí \\epsilon \\leq x \\leq \\hat {x} + \\epsilon\\). Illustration The following theorem gives us the necessary condition for a local maximum and a local minimum. Theorem 6.1 (first-order condition) If the differentiable function \\(f\\) has an extreme value at \\(x^*\\), then: \\(f^\\prime (x^ ‚àó ) = 0\\). This equation is also called first-order condition (FOC). It is a necessary condition. In other words: If \\(f&#39; (x) \\neq 0\\), then \\(f\\) has no extremum in \\(x\\). The first-order condition is not a sufficient condition, i.e.¬†the converse does not hold! In other words: The statement ‚ÄúIf \\(f&#39; (x^‚àó ) = 0\\), then \\(f\\) has an extremum at \\(x^ ‚àó\\)‚Äù is wrong. Example 6.1 (FOC is not a sufficient condition) Consider the function \\[f (x) = 16x ‚àí 4x^ 3 + x^ 4.\\] The derivative is: \\[f&#39; (x) = 16 ‚àí 12x^ 2 + 4x^ 3\\] and one easily checks that \\(f&#39; (2) = 0\\). The graph shows that \\(f\\) has no extremum at \\(x = 2\\). A point with \\(f&#39; (x) = 0\\), at which there is no extremum, is called an inflection point. In order to give a label to all points where \\(f&#39;(x)=0\\), we introduce the definition of stationary or critical points. Definition 6.2 (stationary point) Let \\(f\\) be a differentiable function. Every point \\(x\\) with \\(f&#39; (x) = 0\\) is a stationary point/ critical point. A stationary point is either an extremum or an inflection point. An example application concerns profit maximization for a monopolist such as the guitar manufacturer. Example 6.2 (Monopoly with linear demand and linear costs) A monopolist is in the following situation: linear demand \\(x = 100 ‚àí p\\) (\\(x\\) is demand, \\(p\\) is price); linear cost function \\(C(x) = 25x\\). Transforming the demand function into \\(p = 100 ‚àí x\\) gives the following profit function: \\(\\pi(x) = px ‚àí C = 100x ‚àí x^2 ‚àí 25x\\). The profit is maximum at the point \\(x^ ‚àó\\) with \\(\\pi&#39; (x^ ‚àó ) = 100 ‚àí 2x^‚àó ‚àí 25 = 0\\), so \\(x^‚àó = (100 ‚àí 25)/ 2 = 37.5\\). The profit-maximizing price and the corresponding profit are \\(p^‚àó = 100 ‚àí x^‚àó = 62.50\\), \\(\\pi^‚àó = (62.50 ‚àí 25) 37.5 = 1,406.25\\). The graph on the left shows: the total revenue \\(R(x) = px = 100x ‚àí x^2\\) the total cost \\(C(x) = 25x\\) the profit \\(œÄ(x) = (100 ‚àí 25)x ‚àí x^2 = 75x ‚àí x^ 2\\) The right graph shows: the demand \\(p = 100 ‚àí x\\) the marginal revenue \\(R&#39; (x) = 100 ‚àí 2x\\) the marginal cost \\(C&#39; (x) = 25\\) Exercise 6.1 (extreme values) Find the extreme values of \\(f (x) = 2x^ 3 ‚àí 0.5x^ 2 + 2\\) \\(f (x) = 4x^ 2 ‚àí 5x + 10\\) \\(f(x) = 6x/(x^4 + 2)\\) \\(f (x) = 0.5x^ 4 ‚àí 5x^ 3 + 2x^ 2\\) In each case, determine (e.g.¬†graphically: https://www.desmos.com/calculator?lang=en) whether it is a maximum or a minimum. Answer \\(f (x) = 2x^ 3 ‚àí 0,5x^ 2 + 2\\) \\(f&#39;(x)=6x^2-x=0\\) (FOC) \\(x(6x-1)=0\\) \\(\\Leftrightarrow\\) \\({x}_{1}^* =0\\); \\(6x-1=0 \\Rightarrow {x}_{2}^{*}= \\frac{1}{6}\\) \\(f (x) = 4x^ 2 ‚àí 5x + 10\\) \\(f&#39;(x)=8x-5=0\\) (FOC) \\(\\Leftrightarrow x^*= \\frac{5}{8}\\) \\(f (x) = 6x/(x^ 4 + 2)\\) \\(f&#39;(x)= \\frac{6(x^4+2)-6x(4x^3)}{(x^4+2)^2} =0\\) \\(x^4=12/18=2/3\\) \\(x^*_{1,2}= \\pm \\sqrt[4]{ \\frac{2}{3} }\\) \\(= \\pm 0.9036\\) \\(f (x) = 0,5x^ 4 ‚àí 5x^ 3 + 2x^ 2\\) \\(f&#39;(x)=0,5 \\cdot 4x^3-5 \\cdot 3x^2+ 2 \\cdot 2x=0\\) \\(\\Leftrightarrow x(x^2-15x+4)=0\\) \\(x_1^*=0\\) \\(x_{2}^*= \\frac{15- \\sqrt{193} }{4} = 0.2769\\) \\(x_{3}^*= \\frac{15+ \\sqrt{193} }{4} = 7.2231\\) A firm is the sole producer of a product with a cost function: \\[\\displaystyle f(x)=100+20x+2x^2\\]. If the company increases the price, fewer units will be sold; the price \\(p(x)\\) expressed as a function of the number of units \\(x\\) is: Submit 6.2 Second-order conditions Second order derivatives can determine whether a stationary point is a maximum or a minimum. The three possible cases for stationary points are shown on the graphs below. Graph (a) shows that in the case of a maximum, the slope of the function is positive to the left of the maximum (i.e.¬†for \\(x &lt; x^ ‚àó\\) ) and that it is negative to the right of the maximum (\\(x &gt; x^ ‚àó\\) ). This is captured by the negative slope of \\(f&#39;\\) at \\(x^ ‚àó\\) (Graph (d)). For a minimum the behavior is just the opposite (graphs (b) and (e)). In the case of an inflection point (graphs (c) and (f)) this behavior cannot occur. Hence \\(f&#39;&#39;(x^‚àó ) = 0\\). The function changes from concave to convex (or vice versa). Theorem 6.2 (Sufficient condition for maximum (minimum)) Let \\(f\\) be twice differentiable. If \\(f&#39; (x^ ‚àó ) = 0\\) and \\(f&#39;&#39;(x ‚àó ) &lt; 0\\), then \\(f\\) has a local maximum at \\(x^ ‚àó\\) . If \\(f&#39; (x^ ‚àó ) = 0\\) and \\(&#39;&#39;f(x^ ‚àó ) &gt; 0\\), then \\(f\\) has a local minimum at \\(x^ ‚àó\\) . The theorem gives sufficient conditions for determining whether a stationary point is a minimum or a maximum. Exercise 6.2 (maximum or minimum) For the following function, use the second-order conditions to determine whether an extremum is a local maximum or a local minimum. \\(f (x) = 2x^ 3 ‚àí 0.5x^ 2 + 2\\) Answer \\(f&#39;(x)=6x^2-x=0\\) \\(x(6x-1)=0 \\rightarrow x_1^*=0 \\text{ und }x_2^*=1/6\\) \\(f&#39;&#39;(x)=(6x^2)&#39;=12x-1\\) \\(x_1^*=0 : f&#39;&#39;(x_1^*)=12 \\cdot 0-1=-1&lt;0\\rightarrow\\) lokales Maximum \\(x_2^*=1/6:f&#39;&#39;(x_2^*)=12 \\cdot(1/6)-1=1&gt;0\\rightarrow\\) lokales Minimum Example 6.3 (Monopoly with linear demand and linear costs) In Example 6.2, we obtained: \\(\\pi&#39; (x^ ‚àó ) = 100 ‚àí 2x^‚àó ‚àí 25 = 0\\), and \\(x^‚àó = (100 ‚àí 25)/ 2 = 37.5\\). Now, we verify, that the profit has its maximum at \\(x^‚àó\\) using the second derivative: \\[\\pi&#39;&#39; (x^ ‚àó ) = ‚àí 2 &lt;0,\\] It means, that at \\(x^‚àó=37.5\\) the profit function reaches its maximum. Example 6.4 (Approximate maximization of profit functions with Taylor Approximation) In Example 5.8 we considered a monopolist with the following profit function: \\[\\pi(q) = 100\\cdot \\exp(-0.01 q) \\cdot q - 1000 - q.\\] The derivative of this profit function is: \\[\\pi^\\prime(q) = (-1)\\cdot\\exp(-0.01q)\\cdot q + 100\\cdot\\exp(-0.01q) - 1.\\] Note: we can not solve for \\(q\\) if we set the derivative to zero! (Try that :)) The question is: How can we find the optimal production \\(q^*\\)? \\(\\leadsto\\) visually: the maximum has to be around \\(q=100\\). But can we get a better approximation? We approximate the derivative \\(\\pi^\\prime(q)\\) using its first-order Taylor expansion around \\(q_0=100\\). The function value at \\(q_0=100\\) is: \\[\\pi^\\prime(100) = (-1)\\cdot \\exp(-0.01\\cdot 100)\\cdot 100 + 100\\cdot\\exp(-0.01\\cdot 100) - 1 = -1,\\] The derivative of the function (here \\(\\pi^{\\prime\\prime}(q)\\)) is: \\[\\begin{align*}\\pi^{\\prime\\prime}(q) &amp;= 0.01\\exp(-0.01q)\\cdot q - \\exp(-0.01q)+ 100(-0.01)\\exp(-0.01q) \\\\ &amp;= 0.01\\exp(-0.01q)\\cdot q - 2\\exp(-0.01q).\\end{align*}\\] So \\[\\begin{align*}\\pi^{\\prime\\prime}(q_0=100)&amp;=0.01\\exp(-0.01\\cdot 100)\\cdot 100 -2\\exp(-0.01\\cdot 100) \\\\ &amp;= -\\exp(-1)=-\\frac1e.\\end{align*}\\] The first order Taylor approximation for the derivative of the profit function: \\[\\begin{align*}\\pi^\\prime(q) &amp;\\approx \\pi^\\prime(q_0) + \\pi^{\\prime\\prime}(q_0)(q-q_0) \\\\ &amp;=-1 - \\frac 1e\\cdot(q-100) \\end{align*}\\] Setting the expression above to zero, we get: \\[-1 - \\frac 1e\\cdot(q-100)=0\\rightarrow q^*_{approx}=-e+100=97.2817.\\] That is, the profit is approximately in its maximum for \\(q^*_{approx}=97.2817.\\) Now, we can also verify whether the second derivative is smaller than zero (sufficient condition for the maximum): \\[\\begin{align*}\\pi^{\\prime\\prime}(q^*_{approx})&amp;=0.01\\exp(-0.01\\cdot 97.2817)\\cdot 97.2817 -2\\exp(-0.01\\cdot 97.2817) \\\\ &amp;=-0.3883&lt;0.\\end{align*}\\] 6.3 Optimization on an interval In practice, most optimization problems have to be solved under constraints, for example: a firm can only produce non-negative quantities of goods; a company has production capacity limitations; a consumer has a limited budget. Example 6.5 (Optimization on an interval) We decide \\[\\begin{equation*} \\max_x f(x)=3-2x\\quad\\text{ under the condition } 0\\leq x\\leq 1. \\end{equation*}\\] The case without constraint has no extremes (\\(f^\\prime(x)=-2\\), for all \\(x\\)), so the maximum must be on one of the interval corners. Since the derivative is negative, i.e.¬†the function is decreasing, the solution is the left boundary \\(x^\\ast=0\\). The general formulation of an optimization problem under Constraints (given as an interval) is as follows: \\[\\begin{equation} \\max_x f(x)\\quad\\text{ under the condition }\\quad a\\leq x\\leq b.\\tag{6.1} \\end{equation}\\] Alternatively, this can be expressed as \\[\\begin{equation*} \\max_{x\\in [a,b]} f(x). \\end{equation*}\\] Three cases can be identified as possible solutions to the maximization problem occur: \\(x^\\ast=a\\): In this case, \\(f^\\prime(x^\\ast)\\leq 0\\) (left graph) \\(a&lt;x^\\ast&lt;b\\): In this case \\(f^\\prime(x)=0\\) (middle graph) \\(x^\\ast=b\\): In this case \\(f^\\prime(x^\\ast)\\geq 0\\) (right graph) In cases (i) and (iii), the constraint is mandatory; in (ii) the constraint is non-mandatory. The solution in (ii) is called internal solution. The following sentence summarizes the three situations. Theorem 6.3 (Maximization under constraints) A solution \\(x^\\ast\\) to the problem \\[\\begin{equation*} \\max_x f(x)\\quad\\text{ under the condition } a\\leq x\\leq b \\end{equation*}\\] meets one or both of the following conditions: \\[\\begin{align*} \\phantom{test test} % f^\\prime(x^\\ast)\\leq 0&amp;\\quad\\text{ and }\\quad (x^\\ast-a) f^\\prime(x^\\ast)=0\\\\ f^\\prime(x^\\ast)\\geq 0&amp;\\quad\\text{ and }\\quad (b-x^\\ast) f^\\prime(x^\\ast)=0. \\end{align*}\\] If both conditions are met and additionally \\(f^\\prime(a)\\not=0\\), \\(f^\\prime(b)\\not=0\\), then \\(x^\\ast\\) is an inner solution, i.e.¬†\\(a&lt;x^\\ast&lt;b\\). Theorem 6.4 (Minimization under constraints) A solution \\(x^\\ast\\) to the problem \\[\\begin{equation*} \\min_x f(x)\\quad\\text{ under the condition } a\\leq x\\leq b, \\end{equation*}\\] meets one or both of the following conditions: \\[\\begin{align*} \\phantom{test test} % f^\\prime(x^\\ast)\\geq 0&amp;\\quad\\text{ and }\\quad (x^\\ast-a) f^\\prime(x^\\ast)=0\\\\ f^\\prime(x^\\ast)\\leq 0&amp;\\quad\\text{ and }\\quad (b-x^\\ast) f^\\prime(x^\\ast)=0. \\end{align*}\\] If both conditions are met and additionally \\(f^\\prime(a)\\not=0\\), \\(f^\\prime(b)\\not=0\\), then \\(x^\\ast\\) is an inner solution, i.e.¬†\\(a&lt;x^\\ast&lt;b\\). To practically determine the maximum/minimum, carry out the following steps: find the derivative of \\(f(x)\\); see which of the two conditions from the theorems @ref(thm: thmmaxneb) and 6.4 (depending on whether you should maximize or minimize) apply and solve for \\(x\\). Finally, check whether the resulting values for \\(x\\) are from the target interval and compare the function values if you received several \\(x\\) values. The smallest (largest) function value then determines the minimum (maximum). Alternatively, you can determine all local maxima and minima for the objective function; The associated \\(x\\) values, which are also on the target interval, are considered candidates for Min (Max) considered. Then compare the function values that represent local min (max) with the boundary values \\(f(a),f(b)\\). The smallest (largest) function value then determines the minimum (maximum). Exercise 6.3 (Minimum and maximum under constraints) Solve the following problems: \\(\\max_x 3 + 2x\\) under the condition \\(0 ‚â§ x ‚â§ 10\\) \\(\\max_x 1 + 10x^ 2\\) under the condition \\(5 ‚â§ x ‚â§ 20\\) \\(\\min_x 5 ‚àí x^ 2\\) under the condition \\(0 ‚â§ x ‚â§ 10\\) Draw the solutions graphically. How do the solutions differ from the respective case without constraints? Answer \\(\\max_{0 \\leq x \\leq 10 }3+2x\\) \\(f&#39; (x^ ‚àó ) ‚â§ 0\\) and \\((x^ ‚àó ‚àí a)f&#39; (x^ ‚àó ) = 0\\) does not hold \\(f&#39; (x^ ‚àó ) ‚â• 0\\) and \\((b ‚àí x^ ‚àó )f&#39; (x^ ‚àó ) = 0\\) holds, therefore \\(f&#39;(x)=(3+2x)&#39;=2&gt;0\\) always applies \\((10-x) \\cdot 2=0 \\Leftrightarrow 20-2x=0 \\Rightarrow x^*=10\\) \\(\\max_{5 \\leq x \\leq 20 }1+10x^2\\) \\(f&#39; (x^ ‚àó ) ‚â§ 0\\) and \\((x^ ‚àó ‚àí a)f&#39; (x^ ‚àó ) = 0\\) does not hold \\(f&#39; (x^ ‚àó ) ‚â• 0\\) and \\((b ‚àí x^ ‚àó )f&#39; (x^ ‚àó ) = 0\\) holds, therefore \\(f&#39;(x)=(1+10x^2)&#39;=20x&gt;0 \\ for \\ 5 \\leq x \\leq 20\\) \\((20-x) \\cdot 20x=0 \\Rightarrow 20-x=0 \\Rightarrow x_1^*=20\\) \\(20x=0 \\Rightarrow x_2^* =0 \\neq for \\ 5 \\leq x \\leq 20\\)! \\(\\min_{0 \\leq x \\leq 10 }5-x^2\\) \\(f&#39; (x^ ‚àó ) ‚â• 0\\) and \\((x^ ‚àó ‚àí a)f&#39; (x^ ‚àó ) = 0\\) does not hold \\(f&#39; (x^ ‚àó ) ‚â§ 0\\) and \\((b ‚àí x^ ‚àó )f&#39; (x^ ‚àó ) = 0\\) holds, therefore \\(f&#39;(x)=(5-x^2)&#39;= -2x&lt;0\\) for \\(0 ‚â§ x ‚â§ 10\\) \\((10-x)(-2x)=0 \\rightarrow x_1^*=0 \\Rightarrow f(0)=5-0^2=5\\) \\(x_2^*=10 \\Rightarrow f(10)=5-10^2=-95\\) \\(x=0\\) \\(x=-1\\) \\(x=1\\) Submit "],["integral-calculus.html", "Chapter 7 Integral calculus 7.1 The indefinite integral 7.2 The definite integral", " Chapter 7 Integral calculus In the following, we will deal with the question of whether and how the underlying function \\(f (x)\\) can be derived from a given derivative function \\(f&#39; (x)\\). This process - the determination of the (indefinite) integral - is the inverse of differentiating. One application of the integral calculus is the determination of the area below a function graph. Further applications in economics result, for example, from the consideration of marginal costs and total costs. Example 7.1 (marginal cost function) A firm produces a good with the following marginal cost function \\(C&#39;\\) : \\(C&#39; (x) = 0.3x^ 2 ‚àí 4x + 21\\). How can the company determine the total cost function \\(C\\) from this? So we are looking for a function \\(C\\) such that its derivative is \\(C&#39;\\). One easily verifies that the function \\(C(x) = 0.1x^ 3 ‚àí 2x^ 2 + 21x\\) meets this requirement. Note that any other function of the form \\(C(x) = 0.1x^ 3 ‚àí 2x^ 2 + 21x + c\\), \\(c\\) constant, (e.g.¬†\\(c\\) = fixed costs) fulfills the condition. 7.1 The indefinite integral For the function \\(f (x) = x^ 2\\) we already know that \\(f&#39; (x) = 2x\\) applies. Conversely, if it is known that \\(f&#39; (x) = 2x\\), it is clear that \\(f (x) = x^ 2\\) is a function with this derivative. Any other function of the form \\(f (x) = x^ 2 + c\\) with \\(c\\) constant, but has the same derivative! Starting from a derivation, the function itself cannot be determined unambiguously, but only up to an (unknown) constant. The reverse process of differentiation is called integration or integrating. In the example, the cost function (apart from the fixed costs) is obtained from the marginal cost function \\(C&#39;\\) by integration. Definition 7.1 (Indefinite integral) Let \\(f\\) be a continuous function in the interval \\([a,b]\\). A differentiable function \\(F\\) in \\([a,b]\\) is called antiderivative of \\(f\\) if: \\(F&#39; (x) = f (x)\\) or \\(dF / dx = f (x)\\). Example 7.2 (Some antiderivatives) Antiderivatives of \\(f (x) = x\\) are about \\(F(x)= \\frac{1}{2}x^2\\) and \\(F(x)= \\frac{1}{2 }x^2 +7\\). Antiderivative of \\(f (x) = 1/x\\) , \\(x &gt; 0\\), \\(F(x) = \\ln x + c\\) (\\(c\\): constant), because \\(F&#39; (x) = 1/x.\\) Definition 7.2 (Indefinite integral) The set of all antiderivatives of f is called indefinite integral and denoted by \\(\\int f (x) dx\\). The function \\(f (x)\\) is called Integrand. Example 7.2 (Some integrals) \\(\\int 4x^ 3 dx = x^ 4 + c\\) \\(\\int 7t^ 6 dt = t^ 7 + c\\) \\(\\int e^ z dz = e^ z + c\\). The following rules help to find indefinite integrals. Theorem 7.1 (Basic integrals) Let: \\(g\\) be a continuous function; \\(n\\), \\(c\\), \\(a\\), \\(b\\) real constants. \\[\\begin{equation*} \\def\\arraystretch{1.9} \\begin{array}[t]{l|llll} \\hline &amp; \\text{function } f(x) &amp; \\int f(x)\\, \\text{d} x &amp; remark\\\\\\hline\\hline 1&amp; x^n &amp; \\displaystyle \\frac{x^{n+1}}{n+1} + c &amp; n\\not=-1\\\\\\hline 2&amp; (ax + b)^n &amp; \\displaystyle \\frac{1}{a} \\cdot \\frac{(ax + b)^{n+1}} {n+1} + c\\\\\\hline 3&amp; \\displaystyle \\frac{1}{x} &amp; \\ln |x| + c\\\\\\hline 4&amp; \\displaystyle\\frac{1} {ax +b} &amp; \\displaystyle \\frac{1}{a} \\ln |ax+b| + c &amp; a\\not=0\\\\\\hline \\end{array} \\end{equation*}\\] \\[\\begin{equation*} \\def\\arraystretch{1.9} \\begin{array}[t]{l|llll} \\hline% &amp; \\text{function } f(x) &amp; \\int f(x)\\, \\text{d} x &amp; remark\\\\\\hline\\hline 5&amp; \\displaystyle\\frac{g^\\prime(x)}{g(x)} &amp; \\ln |g(x)| + c\\\\\\hline 6&amp; \\text{e}^x &amp; \\text{e}^x + c\\\\\\hline 7&amp; \\text{e}^{ax+b} &amp; \\frac{1}{a} \\text{e}^{ax+b} + c &amp; a\\not=0\\\\\\hline 8&amp; g^\\prime(x) \\text{e}^{g(x)} &amp; \\text{e}^{g(x)} + c\\\\\\hline 9&amp; g(x)\\cdot g^\\prime(x)&amp; \\tfrac{1}{2}(g(x))^2 + c\\\\\\hline \\end{array} \\end{equation*}\\] Example 7.3 (Application of the rules) \\(\\int dx = \\int 1 \\cdot dx = \\int x^0 \\cdot dx = x + c\\) (Rule 1 with \\(n = 0\\)) \\(\\int \\sqrt{y} \\ dy= \\int {y}^{1/2} dy= \\color{blue}{\\frac{2}{3}} {y}^{\\color{red }{3/2}}+c\\) (Rule 1 with \\(n=\\frac 12\\) therefore \\(n+1=\\color{red}{\\frac{3}{2}}\\) and \\(\\frac 1{n+1} = \\color{blue}{\\frac{2}{3}}\\)) \\(\\int (\\color{red}{3}z-2)^2 \\ dz = \\frac{1}{\\color{red}{3}} \\frac{(3z-2)^\\color{ blue}{3}}{\\color{blue}{3}}+c = \\frac 19 (3z-2)^3+c\\) (Rule 2 with \\(a=\\color{red}{3}\\ ) and \\(n=2\\) therefore \\(n+1=\\color{blue}{3}\\)) \\(\\int \\frac 1{\\color{blue}{2}x-5}\\ dx = \\frac 1{\\color{blue}{2}}\\ln|\\color{blue}{2}x- 5|+c\\) (Rule 4 with \\(a=\\color{blue}{2}\\)) \\(\\int \\frac {\\color{red}{x}}{\\color{blue}{0.5x^2-1}}\\ dx = \\ln|\\color{blue}{0.5x^2-1 }|+c\\) (Rule 5 with \\(g(x)=\\color{blue}{0.5x^2-1}\\) hence (g‚Äô(x) = ¬†)) \\(\\int e ^{\\color{red}{0.5}t-7} \\ dt = \\color{blue}{2} \\cdot e^{\\color{red}{0.5}t- 7}+c\\) (Rule 7 with \\(a=\\color{red}{0.5}\\) therefore \\(\\frac 1a = \\color{blue}{2}\\)) \\(\\int \\color{red}{4x}\\cdot e ^{\\color{blue}{2x^2}} \\ dt = e^{\\color{blue}{2x^2}}+c\\) (Rule 8 with \\(g(x)={\\color{blue}{2x^2}}\\) therefore \\(g&#39;(x)={\\color{red}{4x}}\\)) \\(\\int 9\\cdot\\color{red}{(3x-2)} \\ dx = \\int 3\\cdot 3\\cdot\\color{red}{(3x-2)} \\ dx =3\\cdot\\ int \\color{blue}{3}\\cdot\\color{red}{(3x-2)} \\ dx = 3\\cdot \\frac 12\\color{red}{(3x-2)}^2\\) (Rule 9 with \\(g(x)=\\color{red}{(3x-2)}\\) and therefore \\(g&#39;(x) = \\color{blue}{3}\\)) Theorem 7.2 (Calculation rules for integrals) Let \\(f\\) and \\(g\\) be continuous functions and \\(k\\) be a constant. Then: \\(\\int k \\cdot f (x) dx = k \\cdot \\int f (x) dx\\) \\(\\int (f (x) + g(x)) dx =\\int f (x) dx + \\int g(x) dx\\) Example 7.4 (Application of the rules and Theorem 7.2) \\(\\int dx = \\int \\underbrace{12x}_{3\\cdot4x}\\cdot e^{2x^2+1} \\cdot dx \\stackrel{Thm.7.2 i}{=} 3\\cdot{\\color{red}{\\int 4x\\cdot e^{2x^2+1} \\cdot dx}} = 3\\cdot\\color{red}{e^{2x^2+1} }+ c\\) (Rule 8 with \\(g(x) = 2x^2+1\\) and \\(g^\\prime(x)=4x\\)). \\(\\int \\big(\\underbrace{\\frac2{3x+4}}_{\\frac{2\\cdot 1}{3x+4}} + e^x\\big)dx\\stackrel{Thm.7.2 i,ii}{=} 2\\cdot\\color{red}{\\int \\frac1{3x+4}dx} + \\color{green}{\\int e^xdx}= 2\\cdot\\color{red}{\\frac13\\ln|3x+4|} + \\color{green}{e^x} + c\\) (Rule 4 with \\(a=3\\)) Apply the above calculation rules for solving the following problems. Exercise 7.1 (Calculation of integrals) Calculate: \\(\\int \\ 6x^2 dx\\) Answer \\(= 6 \\cdot \\int x^2dx= 6 \\cdot \\frac{x^{2+1}}{2+1} +c= 6 \\cdot (x^3/3) + c= 2x^3 +c\\) (Rule 1) (ii) \\(\\int \\frac{-1}{x} dx\\) Answer \\(= -1 \\int \\frac{1}{x} dx = -1 \\cdot ln (x) + c = - ln(x) + c\\) (Rule 3) (iii) \\(\\int (8x^3 ‚àí 4x + 2) dx\\) Answer \\(= \\int 8x^3dx + \\int -4xdx + \\int 2dx = 8 \\cdot \\int x^3dx + (-4) \\cdot \\int xdx + 2 \\cdot \\int 1dx\\) \\(= 8 (x^4/ 4)-4 (x^2/2+2x+c = 2x^4 - 2x^2+2x+c\\) (Rule 1) (iv) \\(\\int x^{3/2} dx\\) Answer \\(= \\frac{x ^{\\frac{3}{2}+1 }}{ \\frac{3}{2}+1 } +c = \\frac{x^ \\frac{5}{2} } { \\frac{5}{2} } +c = \\frac{2}{5} x ^ {\\frac{5}{2}}+c\\) (Rule 2) (v) \\(\\int 6x \\cdot \\ e^{x^2} dx\\) Answer \\(= \\int 3 \\cdot 2x \\cdot e^{x^2} dx = 3 \\cdot \\int 2x \\cdot e^{x^2} dx = 3 \\cdot e^{x^2} +c\\) (Rule 8) (vi) \\(\\int \\frac{3x^2+2}{x^3+2x} dx\\) Answer \\(= ln (x^3+2x)+c\\) (Rule 5) The generally unknown integration constant \\(c\\) can be calculated with the help of additional information, such as the function value at a point. Example 7.5 (Calculation of the integration constant) If, as in the above exercise \\((i)\\), you additionally know the function value in e.g.¬†in \\(0\\), you can use this to calculate the value for the integration constant. That is, from \\(F(0)=10\\) and \\(F(x)= 2x^3 + c\\), one calculates: \\[2\\cdot 0^3 + c = 10\\rightarrow c = 10.\\] So the antiderivative is: \\(F(x) = 2x^3 + 10.\\) Exercise 7.2 (Calculating integration constants) Determine the integral and the integration constant \\(c\\): \\(F(x) = \\int x^{1/2} dx\\), \\(F(0) = 5\\) Answer \\(=\\frac{x^{(1/2+1)}}{1/2+1} +c = \\frac{x^{(3/2)}}{3/2} + c = \\frac{2}{3}x^{(3/2)}+c = F(x).\\) We know: \\(F(0)=5\\), i.e.¬†\\((2/3) \\cdot 0^{(3/2)} +c =5 \\Rightarrow \\ c=5\\) \\(\\rightarrow F(x)=2/3x^{3/2}+5.\\) (ii) \\(F(x) = \\int (2x^3 + 4x) dx\\), \\(F(0) = 0\\) Answer \\(= \\int 2x^3dx + \\int 4x dx = 2 \\cdot \\int x^3dx +4 \\cdot \\int x dx=2 \\cdot x^4/4+4 \\cdot x^2/2 +c=x^4/2+2x^2+c.\\) We know: \\(F(0)=0\\), i.e.¬†\\(0^4/2+2 \\cdot 0^2 +c=0 \\Rightarrow c=0\\) \\(\\rightarrow F(x)=(x^4)/2+2x^2\\) Submit Exercise 7.3 (Total cost and unit cost) A firm produces with the following marginal cost function: \\(C&#39; (x) = 1.5x^2 ‚àí 4x + 4\\). With an output of \\(10\\) units of quantity, the total costs are \\(372\\) monetary units. Find the total cost \\(C(x)\\) and unit cost functions \\(\\frac{C(x)}{x}\\). Answer Total cost function: find the antiderivative of \\(C&#39;(x)\\): \\[\\begin{align}C(x) &amp;= \\int C&#39;(x) dx \\)=\\int (1.5x^2-4x+4) dx \\\\ &amp;=\\int 1.5x^2dx + \\int (-4)xdx+ \\int 4dx \\\\ &amp;= 1.5 \\int x^2dx + (-4) \\int xdx+ 4\\int 1dx \\\\ &amp;= 1.5 \\frac{x^3}{3} + (-4) \\frac{x^2}{2} + 4x +c. \\end{align}\\] \\(c\\) is still being sought. Additionally given: \\(C(10)=372\\), i.e.¬†\\(0.5 \\cdot 10^3 - 2 \\cdot 10^2 + 4 \\cdot 10 + c = 372.\\) Then: \\(c =372-340=32.\\) Total cost function: \\(C(x) = 0.5x^3-2x^2+4x+32\\) Unit cost function: \\(\\frac{C(x)}{x} =0.5x^2-2x+4+ \\frac{32}{x}\\) 7.2 The definite integral Let \\(f\\) be a continuous and positive function. The definite integral, also Riemann integral, is defined as the area on an interval piece between the \\(x\\) axis and the function graph of \\(f\\) . For example, consider the function \\(f (x) = 2x\\) on the interval \\([0,1]\\). One thing is clear: The area below \\(f\\) is \\(1\\) (height x width of the rectangle divided by \\(2\\)). The integral calculus offers the mathematical apparatus to determine the area for non-linear functions. Details Theorem 7.3 (The main theorem of integral calculus) The function \\(f\\) is continuous on the interval \\([a,b]\\) and \\(F\\) is an antiderivative (indefinite integral) of \\(f\\) . Then: \\(\\int_{a}^{b} f(x)dx=F(b)-F(a)\\). For the expression \\(F(b) ‚àí F(a)\\) the notation \\([F(x)]_a ^b\\) is also used. The constant of integration can be ignored because it cancels out: \\((F(b) + c) ‚àí (F(a) + c) = F(b) ‚àí F(a)\\). In practice, one determines the antiderivative, inserts the interval limits \\(a\\) and \\(b\\) and evaluates the difference \\(F(b) ‚àí F(a)\\). Example 7.6 (Definite integrals) The example \\(f (x) = 2x\\) on the interval \\([0,1]\\) results in: \\(\\int_{0}^{1} 2xdx = F(1)-F(0)= \\left[ x^2 \\right]_0^1 = 1^2 - 0^2 = 1\\). A little more general: \\(\\int_{0}^{b} 2xdx = \\left[ x^2 \\right]_0^b = b^2\\) . Example 7.7 (Definite integrals) Let \\(f (x) = x^3 + xe^{x^2}\\). The antiderivative is \\(F(x)= \\frac14x^4 + \\frac 12 \\cdot e^{x^2}\\). The area on \\([0.5,1]\\) is: \\(\\int_{1}^{2} x^3 + xe^{x^2}dx = \\left[ \\frac14x^4 + \\frac 12 \\cdot e^{x^2} \\right] _{1}^2 = \\frac14 \\cdot 2^4 + \\frac 12 \\cdot e^{2^2}- \\frac14 \\cdot 1^4 - \\frac 12 \\cdot e^{1^2} = 29.69.\\) Exercise 7.4 (Calculate definite integrals) Given: \\(\\int_{0}^{1} (4x^4+2x^3+4x+10) dx\\) Answer \\(= \\int_{0}^{1} x^4dx + \\int_{0}^{1} 2x^3dx + \\int_{0}^{1} 4xdx + \\int_{0}^{1} 10dx =\\) \\(\\int_{0}^{1} x^4dx + 2 \\cdot \\int_{0}^{1} x^3dx + 4 \\cdot \\int_{0}^{1} xdx + 10 \\cdot \\int_ {0}^{1} 1 \\ \\cdot dx=\\) \\(\\left[ \\frac{x^5}{5} \\right]_0^1 + 2 \\cdot \\left[ \\frac{x^4}{4} \\right]_0^1 + 4 \\cdot \\left [ \\frac{x^2}{2} \\right]_0^1 + 10 \\cdot \\left[ x \\right]_0^1 =\\) \\(\\frac{1^5}{5} + 2 \\cdot \\frac{1^4}{4} +4 \\cdot \\frac{1^2}{2} + 10 \\cdot 1 - ( \\frac{ 0^5}{5} + 2 \\cdot \\frac{0^4}{4} + 4 \\cdot \\frac{0^2}{2} + 10 \\cdot 0)=\\) \\(\\frac{1}{5}+ \\frac{1}{2}+2+10=12.7\\) (ii) \\(\\int_{0}^{8} {x}^{2/3} dx\\) Answer \\(= \\left[ \\frac{x^{2/3+1}}{ \\frac{2}{3}+1 } \\right]_0^8 = \\left[ \\frac{x^{5/3}}{ \\frac{5}{3} } \\right]_0^8 = \\left[ \\frac{3}{5} \\cdot x^{5/3} \\right]_0^8 =\\) \\(\\frac{3}{5} \\cdot 8^{5/3} - \\frac{3}{5} \\cdot \\sqrt[3]{8^5} =19.2\\) (iii) \\(\\int_{1}^{2} 6x \\cdot e^{x^2} dx\\). Answer \\(= \\left[ 3 \\cdot e^{x^2} + c \\right]_1^2 = 3 \\cdot e^{2^2} - 3 \\cdot e^{1^2} = 3 (e^4-e)= 155.6392\\) Submit 7.2.1 Properties and elementary calculation rules The following properties make calculating with integrals easier. Theorem 7.4 (Properties of definite integrals I) Let \\(f\\) and \\(g\\) be two integrable functions on \\([a,b]\\) and let \\(k\\) be a real constant. Then: \\(\\int_{a}^{b}k \\cdot f(x)dx= k \\cdot \\int_a^b f(x)dx\\), \\(\\int_{a}^{b}(f(x)+g(x))dx= \\int_a^b f(x)dx +\\int_a^b g(x)dx\\). Theorem 7.5 (Properties of definite integrals II) Let \\(f\\) be integrable in \\([a,b]\\) and in \\([b,c]\\). Then: \\(\\int_{a}^{c} (f(x) dx = \\int_a^b f(x)dx + \\int_b^c f(x)dx\\). Theorem 7.6 (Properties of definite integrals III) Let \\(f\\) be integrable. Then: \\(\\int_{a}^{a} (f(x) dx = \\lim_{c \\rightarrow a} \\int_a^c f(x)dx =0\\), \\(\\int_{c}^{a} f(x) dx = - \\int_a^c f(x)dx\\). Example 7.8 (capital growth) In numerous applications, the integral conveniently represents the course of an economic quantity over time. The function \\(K(t)\\) describes the capital of a company over time. It is \\(K(t + \\Delta t) ‚àí K(t)\\) the capital increase or capital outflow in the time period \\([t,t + \\Delta t]\\) and \\(\\frac{K(t+ \\triangle t)-K(t)}{ \\triangle t}\\) is the (average) rate of change for that time period. The instantaneous rate of change in \\(t\\) is \\(\\lim_{ \\triangle t \\rightarrow 0} \\frac{K(t+ \\triangle t)-K(t)}{ \\triangle t} = \\frac{dK(t)}{dt} =I(t)\\). (=investment) Since \\(I(t)\\) is the derivative of \\(K(t)\\), it follows conversely that \\(K(t)\\) is the (indefinite) integral of \\(I(t)\\). , i.e.¬†\\(\\int I(t) dt = K(t)\\). The sum of the net investments between two points in time \\(a\\) and \\(b\\) is given by the instantaneous changes in capital, and the following applies: \\(K(b) ‚àí K(a) = \\int_a^b I(t) dt\\). (capital growth) We calculate the capital growth between periods 1 and 2 for \\(I(t)=2t^2+3t\\): \\[\\begin{align*} \\int_1^2 I(t)dt&amp;= \\int _1^2(2t^2+3t)dt= \\left[ 2 \\cdot (t^3/3)+3 \\cdot (t^2 /2)\\right]_1^2\\\\ &amp;= 2 \\cdot (2^3/3) + 3 \\cdot (2^2/2) - (2 \\cdot (1^3/3) + 3 \\cdot 1^2/2)) \\\\ &amp;= 16/3+12/2-2/3-2/3=14/3+9/2=55/6. \\end{align*}\\] We calculate the capital growth between periods 1 and 4 for \\(I(t)=\\begin{cases}0.5(2t^2+3t),&amp;t\\in[1,2)\\\\ e^t,&amp;t\\in[2,4)\\end{cases}\\) \\[\\begin{align*} \\int_1^4 I(t)dt&amp;\\stackrel{Thm. 7.4 ii}= \\int_1^2 I(t)dt + \\int_2^4 I(t)dt\\\\ &amp;= \\underbrace{\\int_1^20.5(2t^2+3t)dt}_{\\stackrel{Thm. 7.4 i}=0.5\\int_1^2(2t^2+3t)dt = 0.5\\cdot 55/6 = 55/12} + \\int _2^4e^tdt\\\\ &amp;\\\\ &amp;= \\frac{55}{12} + \\left[ e^t\\right]_2^4 = \\frac{55}{12} + (e^4 - e^2) \\\\ &amp;= 51.7924. \\end{align*}\\] "],["systems-of-linear-equations.html", "Chapter 8 Systems of linear equations 8.1 Systems of two linear equations 8.2 Systems of equations with \\(n\\) linear equations", " Chapter 8 Systems of linear equations Many economic models are based on linear equation systems: production planning under linear resource constraints: Production constraint for two quantities \\(x\\) and \\(y\\) on Machine 1 (2 hours for a unit of \\(x\\) and 3 hours for a unit of \\(y\\)): \\(2x+3y = 8\\). Production constraint for two quantities \\(x\\) and \\(y\\) on Machine 2 (4 hours for a unit of \\(x\\) and 0.5 hours for a unit of \\(y\\)): \\(4x+0.5y = 8\\). What is the optimal production? finding market equilibrium given linear demand and supply functions: Inverse demand: \\(p(q)=400-0.3q\\) versus inverse supply: \\(p(q)=40+0.3q\\). What is the equilibrium price? calibrating national income models (finding equilibrium incom \\(Y\\) and consumption \\(C\\)): \\[\\begin{align*} Y &amp;= C+I+G\\\\ C&amp;=C_0 +bY\\\\ I&amp;=I_0+aY \\end{align*}\\] for given initial investment \\(I_0=50\\), consumption \\(C_0=65\\), and government expenditures \\(G=20\\), as well as \\(b=0.7\\), \\(a=0.1\\). What is the equilibrium income and consumption? \\(\\leadsto\\) In this Chapter, we will review the methods for solving systems of linear equations. Definition 8.1 (Systems of linear equations) A linear equation with \\(n\\) variables (‚Äúunknowns‚Äù) has the form: \\[a_1x_1 + a_2x_2 + + a_nx_n = b,\\] whereby \\(a_1, ... , a_n\\) and \\(b\\) known constants (e.g.¬†prices), so-called parameters, are and \\(x_1, ... , x_n\\) denote the variables (e.g.¬†quantities of goods). A system of linear equations (LGS) consists of two or more linear equations. A solution is an assignment of variables such that all equations are true/satisfied at the same time. \\(3x_1 +4x_2+5x_3=6\\) \\(x+3^{\\frac12}z=4\\) \\(x_1x_2x_3=-2\\) \\(x^2+6y=1\\) Submit Example 8.1 (Linear production model) We consider an economy with \\(n + 1\\) goods. Each of the goods \\(1, . . . , n\\) is the result of a production process. A production process is characterized by a set of quantities of goods that are required to produce one unit of the production good. Good \\(0\\) denotes the factor labor that is not produced by a process but is used in every production process. The following input-output table shows the production process for a 3-goods economy (without the labor factor): \\[\\begin{equation*} \\begin{array}{l|lll} out\\downarrow;~ in\\rightarrow&amp; x_1&amp;x_2&amp;x_3\\\\ x_1&amp; 0 &amp; 0.4 &amp; 0.3\\\\ x_2&amp; 0.2 &amp; 0.12 &amp; 0.14\\\\ x_3&amp; 0.5 &amp; 0.2 &amp; 0.05 \\end{array} \\end{equation*}\\] The entry \\(a_{ij}\\) in the \\(i\\)th row and \\(j\\)th column denotes the quantity of goods \\(i\\) that is required to produce a unit of goods \\(j\\): Producing one unit of good \\(2\\) requires \\(0.4\\) units of good \\(1\\), as well as \\(0.12\\) units of good \\(2\\) and \\(0.2\\) units of good \\(3\\). There is an exogenous demand for \\(130\\) units of good \\(1\\), for \\(74\\) units of good \\(2\\), and for \\(95\\) units of good \\(3\\). What production volume meets the demand? The solution is: the economy must produce \\(300\\) units of good \\(1\\), \\(200\\) units of good \\(2\\), and \\(300\\) units of good \\(3\\) in order to meet the exogenous demand. 8.1 Systems of two linear equations We start with smallest LGS - LGS with just two linear equations. Example 8.2 (LGS with two equations and two unknowns) Let‚Äôs consider the following system with two linear equations: \\(2 x + 2y = 4\\) \\(\\rightarrow y=4- x\\) (a straight line with a slope \\(-1\\)), \\(4x +0.5y = 8\\) \\(\\rightarrow y=16 - 8x\\) (a straight line with a slope \\(-8\\)). To solve the LGS, we need at least one pair of values \\((x,y)\\), which satisfies both equations. It can be shown that this holds for \\(x = \\frac{12}7\\) and \\(y = \\frac{16}7\\); this corresponds to the intersection of the two straight lines. To find the intersection point, we equalize the two linear functions: \\[{\\color{blue}{4-x}}={\\color{red}{16-8x}}\\rightarrow 7x=12\\rightarrow x=\\frac{12}7\\rightarrow y=4-\\frac{12}7=\\frac{16}7.\\] For \\(x = 1\\) and \\(y = 3\\) the first equation is fulfilled, but the second is not; this pair of values is therefore not a solution of the system. 8.1.1 Solution by substitution and elimination Theorem 8.1 (Number of solutions in a two-equation LGS) A system with two linear equations has either no solution, exactly one solution or infinitely many solutions. Graphically this means: Two straight lines can‚Ä¶ ‚Ä¶ never intersect; ‚Ä¶intersect exactly once; ‚Ä¶ agree on all points. Given a system with two linear equations: \\(ax + by = c\\) \\(dx + ey = f\\) , where \\(a, b, c, d, e, f\\) are known constants. We consider two different methods to solve this system. 1. Substitution: Solving the first equation for \\(x\\) (if \\(a\\neq 0\\)): \\[ x= \\color{red}{\\frac{c}{a} - \\frac{b}{a} \\cdot y}. \\] Substituting/substituting the expression for \\(x\\) into the second equation to find a solution for \\(y\\) (if \\(ae-bd \\neq 0\\)): \\[ d\\left( \\color{red}{\\frac{c}{a} - \\frac{b}{a} \\cdot y}\\right)+ey=f \\ \\Rightarrow \\ y= \\frac{af-cd}{ae-bd}. \\] Substituting back into the first equation gives: \\[ x= \\frac{ce-bf}{ae-bd}. \\] Example 8.3 (Solving via substitution) Let‚Äôs consider the following LGS: \\[5x + 2y = 3,\\] \\[‚àíx ‚àí 4y = 3.\\] Rearranging the second equation gives: \\(x = ‚àí3 ‚àí 4y\\). Substituting into the first equation gives: \\(5(‚àí3 ‚àí 4y) + 2y = 3\\Leftrightarrow ‚àí15 ‚àí 18y = 3\\Leftrightarrow y = ‚àí1\\), and \\(x = ‚àí3 ‚àí 4y = ‚àí3 + 4 = 1\\). 2. (Gaussian) elimination: One or both equations are multiplied by a constant in order to adjust the coefficients associated with \\(x\\) and \\(y\\): \\[a{\\color{red}{d}}x + b{\\color{red}{d}}y = c{\\color{red}{d}},\\] \\[{\\color{blue}{a}}dx + {\\color{blue}{a}}ey = {\\color{blue}{a}}f.\\] Next, subtract the two equations to eliminate one variable: \\[(ae ‚àí bd)y = af ‚àí cd.\\] Then, one solves the system for the remaining variable (if \\(ae-bd \\neq 0\\)): \\[ y= \\frac{af-cd}{ae-bd}, \\] and computes the value of the eliminated variable: \\[ x= \\frac{ce-bf}{ae-bd}. \\] Example 8.4 (solving via elimination) Consider again the following LGS: \\[5x + 2y = 3,\\] \\[‚àíx ‚àí 4y = 3.\\] Scaling the first equation by 2 gives \\[10x + 4y = 6,\\] \\[‚àíx ‚àí 4y = 3.\\] Next the two equations are added: \\(9x = 9\\) Eliminating \\(y\\) yields \\(x = 1.\\) Substituting this result into the second equation, we get \\(‚àí1 ‚àí 4y = 3\\), so that \\(y = ‚àí1\\) must hold. Submit 8.2 Systems of equations with \\(n\\) linear equations We now generalize the results to \\(n\\) variables. A system consisting of \\(m\\) equations and \\(n\\) unknowns/variables is given as follows: \\[\\begin{align*}a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n &amp;= b_1,\\\\ a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n &amp;= b_2,\\\\ \\ldots\\\\ a_{m1}x_1 + a_{m2}x_2 + ... + a_{mn}x_n &amp;= b_m. \\end{align*}\\] The \\(a_{ij}\\) and \\(b_i\\) are real numbers, where \\(a_{ij}\\) denotes the coefficient of the unknown variable \\(x_j\\) in the \\(i\\)-th equation. A solution of the system is an \\(n\\)-tuple of real numbers \\(x_1, x_2, ... , x_n\\) that satisfies each of the \\(m\\) equations simultaneously. Regarding LGS, we are interested in the following three questions: Is there a solution? How many solutions are there? Is there an efficient algorithm that can calculate the solution(s)? There are three main ways to solve an LGS: substitution; elimination of the variables; matrix method (\\(\\leadsto\\) next chapter). The theorem from the last section can be generalized to the case with \\(n\\) variables: Theorem 8.2 (Solution set of an LGS with m equations and n unknowns) A system with \\(m\\) linear equations and \\(n\\) unknowns either has no solution, exactly one solution, or infinitely many solutions. 8.2.1 Solving systems of equations with \\(m\\) linear equations Solving a system with \\(m\\) linear equations using Substitution: Solve an equation of the system for one variable, e.g.¬†\\(x_n\\), so that \\(x_n\\) can be written as an expression of the other variable. Substitute this expression for \\(x_n\\) in the remaining \\(m ‚àí 1\\) equations. The result is a new system consisting of \\(m ‚àí 1\\) equations with \\(n ‚àí 1\\) unknowns. This process is continued by solving another equation for \\(x_{n‚àí1}\\), etc. This procedure is repeated until a single equation remains that can be easily solved. Example 8.5 (Linear production model) Example 8.1 cont. The following input-output table shows the production process for a 3-goods economy (without the labor factor): \\[\\begin{equation*} \\begin{array}{l|lll} out\\downarrow;~ in\\rightarrow&amp; x_1&amp;x_2&amp;x_3\\\\ x_1&amp; \\color{red}0 &amp; \\color{red}{0.4} &amp; \\color{red}{0.3}\\\\ x_2&amp; \\color{blue}{0.2} &amp; \\color{blue}{0.12} &amp; \\color{blue}{0.14}\\\\ x_3&amp; \\color{green}{0.5} &amp; \\color{green}{0.2} &amp; \\color{green}{0.05} \\end{array} \\end{equation*}\\] It gives the system of equations: (1.) \\(x_1 = \\color{red}{0}\\cdot x_1 + \\color{red}{0.4}x_2 + \\color{red}{0.3}x_3 + 130,\\) (2.) \\(x_2 = \\color{blue}{0.2}x_1 + \\color{blue}{0.12}x_2 + \\color{blue}{0.14}x_3 + 74,\\) (3.) \\(x_3 = \\color{green}{0.5}x_1 + \\color{green}{0.2}x_2 + \\color{green}{0.05}x_3 + 95.\\) Solving by substitution Bringing all the variables to the left side gives the system: (4a.) \\(x_1 ‚àí 0.4x_2 ‚àí 0.3x_3 = 130,\\) (4b.) \\(‚àí0.2x_1 + 0.88x_2 ‚àí 0.14x_3 = 74,\\) (4c.) \\(‚àí0.5x_1 ‚àí 0.2x_2 + 0.95x_3 = 95.\\) Solving equation (4a.) for \\(x_1\\) results in: (5.) \\(x_1 = 0.4x_2 + 0.3x_3 + 130\\). Substitution in (4b.) and (4c.) yields: \\(‚àí0.2(0.4x_2 + 0.3x_3 + 130) + 0.88x_2 ‚àí 0.14x_3 = 74,\\) \\(‚àí0.5(0.4x_2 + 0.3x_3 + 130) ‚àí 0.2x_2 + 0.95x_3 = 95\\). This can be simplified to: (6a.) \\(0.8x_2 ‚àí 0.2x_3 = 100,\\) (6b.) \\(‚àí0.4x_2 + 0.8x_3 = 160.\\) This subsystem is now also solved by substitution; (6a.) yields: (7.) \\(x_2 = 125 + 0.25x_3\\) and insertion into (6b.) yields: \\(‚àí0.4(125 + 0.25x_3) + 0.8x_3 = 160,\\) \\(x_3 = 300\\). Substituting x\\(_3 = 300\\) in (7.) gives \\(x_2 = 200\\). Substituting \\(x_2 = 200\\) and \\(x_3 = 300\\) in (5) yields \\(x_1 = 300\\). It follows that the economy must produce \\(300\\) units of good \\(1\\), \\(200\\) units of good \\(2\\), and \\(300\\) units of good \\(3\\) in order to meet the exogenous demand. Solving a system with \\(m\\) equations using Gaussian elimination: Using the coefficient for \\(x_1\\) in the first equation, the \\(x_1\\) term is eliminated from all equations below/below; To do this, a suitable multiple of the first equation is added to each of the following equations. In the following, the first equation is ignored. From the remaining \\(m ‚àí 1\\) equations, the next variable, \\(x_2\\), is then eliminated. If \\(x_2\\) is not contained in the second equation but is contained in another equation, the two equations are exchanged. The elimination of variables is carried out until only one equation remains. The simplified system can now be solved by substitution. Example 8.6 (Linear production model) Example 8.5 cont. We solve the system of equations (4a)-(4c) using Gauss elimination: (8a) \\(x_1 ‚àí 0.4 x_2 ‚àí 0.3 x_3 = 130\\) (8b) \\(‚àí0.2x_1 + 0.88x_2 ‚àí 0.14x_3 = 74\\) (8c) \\(‚àí0.5x_1 ‚àí 0.2x_2 + 0.95x_3 = 95\\) To eliminate \\(x_1\\), a suitable multiple of the first equation is added to the second and third equation. More precisely: (8a) is multiplied by \\(0,2\\) and added to (8b); this gives: \\(0.8x_2 ‚àí 0.2x_3 = 100\\). Similarly, adding \\(0.5\\) times (8a) to (8c) results in: \\(‚àí0.4x_2 + 0.8x_3 = 160\\). The result is the following simplified system: (9a) \\(x_1 ‚àí 0.4x_2 ‚àí 0.3x_3 = 130\\) (9b) \\(0.8x_2 ‚àí 0.2x_3 = 100\\) (9c) \\(‚àí0.4x_2 + 0.8x_3 = 160\\) Now \\(x_2\\) is eliminated from the second equation: Multiplying (9b) by \\(0.5\\) and adding to (9c) gives: (10a) \\(x_1 ‚àí 0.4x_2 ‚àí 0.3x_3 = 130\\) (10b) \\(0.8x_2 ‚àí 0.2x_3 = 100\\) (10c) \\(0.7x_3 = 210\\) Finally, by back substitution / back substitution we get: \\(x_3 = 300, x_2 = 200\\) and \\(x_1 = 300\\). Why is the elimination method permissible? More precisely: What operations can be performed in an LGS without changing the solution of the equations? The addition of a multiple of one equation to another, as it has been applied several times, e.g.¬†in the transition from (8b) to (9b), is reversible, ‚Ä¶ ‚Ä¶ e.g.¬†(8b) can be restored from (9a)‚Äì(9c) by adding \\(‚àí0.2\\) times (9a) to (9b). Overall, the following three operations, so-called elementary equation operations, can be used to solve an LGS: Addition of a multiple of one equation to another; Multiplication of both sides of an equation with a scalar (\\(\\neq 0\\)); Interchanging two equations. Because of the reversibility of these operations, every solution of the transformed system is also a solution of the original system. This following variant is the Gauss-Jordan Elimination: As soon as all elimination steps of the Gaussian elimination have been carried out, instead of the back substitution, another elimination step is carried out, this time from the bottom up. This then provides the final solution. Example 8.7 (Linear production model) Examples 8.1 und 8.6 cont. Consider again the linear production model, which after elimination has the following form: (11a) \\(x_1 ‚àí 0.4x_2 ‚àí 0.3x_3 = 130\\) (11b) \\(0.8x_2 ‚àí 0.2x_3 = 100\\) (11c) \\(0.7x_3 = 210\\) Instead of back substitution, elimination is performed from below. First, each equation is scaled such that the first non-zero coefficient is even \\(1\\): (e.g.¬†by dividing (11c) by \\(0,7\\)): (12a) \\(x_1 ‚àí 0.4 x_2 ‚àí 0.3x_3 = 130\\) (12b) \\(x_2 ‚àí 0.25x_3 = 125\\) (12c) \\(x_3 = 300\\) Next \\(x_3\\) is eliminated from (12b) by multiplying (12c) by \\(0.25\\) and adding (12c) to (12b); this gives: (13a) \\(x_1 ‚àí 0.4x_2 ‚àí 0.3x_3 = 130\\) (13b) \\(x_2 = 200\\) (13c) \\(x_3 = 300\\) Similarly, \\(x_2\\) and \\(x_3\\) are eliminated from (13a) by multiplying \\(0,3\\) times (13c) and \\(0,4\\) times (13b). (13a) added; finally one gets: (14a) \\(x_1 = 300\\) (14b) \\(x_2 = 200\\) (14c) \\(x_3 = 300\\). Exercise 8.1 (machine runtime) Three different products are made with three different machines. The running times (in hours) of the machines to produce each unit of each product are as follows: \\[\\begin{equation*} \\begin{array}[t]{l|ccc} \\hline % &amp; P_1 &amp; P_2 &amp; P_3\\\\\\hline M_1 &amp; 2 &amp; 2 &amp; 2\\\\ M_2 &amp; 3 &amp; 4 &amp; 1\\\\ M_3 &amp; 6 &amp; 10/3 &amp; 2/3\\\\\\hline \\end{array} \\end{equation*}\\] If all the machines run 8 hours a day, how many units of each product can be made in a day? Solution hint "],["matrices-and-basic-matrix-operations.html", "Chapter 9 Matrices and Basic Matrix Operations 9.1 Matrices 9.2 Basic matrix operations 9.3 Economic Applications 9.4 Transpose of a matrix 9.5 Determinant and inverse of a matrix", " Chapter 9 Matrices and Basic Matrix Operations Matrices represent and manipulate data in a very efficient way. One important applications of matrices is solving large systems of linear equations. We summarize the coefficients \\(a_{ij}\\) of such linear equation system in a matrix, e.g., \\(A\\), write the unknowns as a vector \\(\\bf x\\), and collect the constants on the right hand sides of the equations in a vector \\(\\bf b.\\) A matrix can be thought of as a table, with the added benefit of being able to do matrices. For example, matrices can be used to solve systems of linear equations. 9.1 Matrices Definition 9.1 (Matrix) A \\((m\\times n)\\) matrix \\(A\\) is a rectangular number scheme with \\(m\\) rows and \\(n\\) columns: \\[\\begin{equation*} A=\\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp; \\ldots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; a_{23} &amp; \\ldots&amp; a_{2n} \\\\ \\vdots &amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\ a_{m1} &amp; a_{m2} &amp; a_{m3} &amp; \\ldots&amp; a_{mn} \\end{pmatrix} \\end{equation*}\\] The element \\(a_{ij}\\in \\mathbb R\\) designates the entry of \\(A\\), which is in the \\(i\\)-th row and the \\(j\\)-th column. Matrices are often denoted by capital letters of the alphabet. The dimensions of a matrix (important for matrix operations!) are specified in the following form \\((m\\times n) = (\\text{number of rows}\\times\\text{number of columns})\\). Definition 9.2 (Vectors) A column vector is a matrix of dimension \\(m\\times 1\\), i.e.¬†a matrix consisting of a column with \\(m\\) entries. For example: \\[\\mathbf b = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix}.\\] Similarly, a row vector is a \\(1\\times n\\) matrix. For example: \\[\\mathbf c = ( c_1 \\ c_2 \\ ... \\ c_n).\\] Vectors are usually denoted by lowercase bold letters of the Roman alphabet. All operations for matrices automatically apply to vectors, since these only represent special matrices. Column and row vectors can be converted into one another by transposing them, i.e.¬†swapping the dimensions. Write \\(x^\\top\\) to get a transposed version of \\(x\\). Example 9.1 (machine runtime) In the exercise 8.1, we solved the following system of three equations: \\[\\begin{align*} 2x_1 + 2x_2 +2x_3 &amp;= 8,\\\\ 3x_1 + 4x_2 +x_3 &amp;=8,\\\\ 6x_1 + \\frac{10}3 x_2 + \\frac 23x_3 &amp;=8. \\end{align*}\\] The coefficients (production hours) of the three linear equations are collected in coefficient matrix \\(A\\): \\[A=\\begin{pmatrix} a_{\\color{red}11} &amp; a_{\\color{red}12} &amp; a_{\\color{red}13} &amp; \\ldots &amp; a_{\\color{red}1n} \\\\ a_{\\color{blue}21} &amp; a_{\\color{blue}22} &amp; a_{\\color{blue}23} &amp; \\ldots&amp; a_{\\color{blue}2n} \\\\ \\vdots &amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\ a_{\\color{green}m1} &amp; a_{\\color{green}m2} &amp; a_{\\color{green}m3} &amp; \\ldots&amp; a_{\\color{green}mn} \\end{pmatrix} = \\begin{pmatrix} \\color{red}{2} &amp; \\color{red}{2} &amp; \\color{red}{2} \\\\ \\color{blue}{3} &amp; \\color{blue}4 &amp; \\color{blue}1 \\\\ \\color{green}{6} &amp; \\color{green}{\\frac{10}3} &amp; \\color{green}{\\frac 23} \\end{pmatrix} \\] the hours required for the production on the second machine can be represented as an \\(n\\)-dimensional row vector: \\[\\mathbf a_2 = (a_{21} ~ a_{22} ~\\ldots ~ a_{2n}) = (\\color{blue}3~~ \\color{blue}4 ~~\\color{blue}1)\\] The available daily running times of each machine represent an \\(m\\)-dimensional column vector: \\[\\mathbf b = \\begin{pmatrix} b_1 \\\\ b_2 \\\\b_3 \\end{pmatrix}= \\begin{pmatrix} \\color{red}8 \\\\ \\color{blue}{8} \\\\ \\color{green}8 \\end{pmatrix}.\\] In the example above, we have three unknowns (production quantities), which we summarize in the column vector: \\[\\mathbf x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}.\\] Apart from summarizing linear equation systems, matrices are useful for other complex data representation as the following example shows. Example 9.2 (Transition matrices) A transition matrix represents the transition from one state to another. Examples of ‚Äústates‚Äù: belonging to a social class, income group, geographical location. Regional migration: In a country with three regions \\(1\\), \\(2\\) and \\(3\\), the proportion of the population that stays in one region or moves to another region is described by the following transition matrix: \\[P = \\begin{pmatrix} p_{11} \\ p_{12} \\ p_{13} \\\\ p_{21} \\ p_{22} \\ p_{23} \\\\ p_{31} \\ p_{32} \\ p_{33} \\end{pmatrix},\\] where the element \\(p_{ij}\\) denotes the proportion of the population that moves from region \\(j\\) to region \\(i\\). The elements on the diagonal, \\(p_{ii}\\), \\(i = 1,2,3\\), denote the proportion of people who stay in their region. Let‚Äôs assume the transition matrix has the following entries: \\[P = \\begin{pmatrix} \\color{red}{p_{11}} &amp; \\color{orange}{p_{12}} &amp; p_{13} \\\\ \\color{blue}{p_{21}} &amp; p_{22} &amp; p_{23} \\\\ \\color{green}{p_{31}} &amp; p_{32} &amp; p_{33} \\end{pmatrix}=\\begin{pmatrix} \\color{red}{0.80} \\ \\ \\color{orange}{0.15} \\ \\ 0.05 \\\\ \\color{blue}{0.10} \\ \\ 0.70 \\ \\ 0.05 \\\\ \\color{green}{0.10} \\ \\ 0.15 \\ \\ 0.90 \\end{pmatrix}\\] - This expresses that \\(\\color{red}{80 \\%}\\) of the population from region \\(1\\) stay in region \\(1\\), \\(\\color{blue}{10 \\%}\\) move from region \\(1\\) to region \\(2\\) and more \\(\\color{green}{10 \\% }\\) move from region \\(1\\) to region \\(3\\). - Similarly, the entry \\(p_{12} = 0.15\\) means that \\(\\color{orange}{15 \\%}\\) of the population is moving from region \\(2\\)= to region \\(1\\). Advantage among others: The matrix notation allows a short and clear representation of these relationships. [We‚Äôll come back to this example later‚Ä¶] There are some special types of matrices, which are summarized in the following definition. Definition 9.3 (special matrices) The zero matrix is a matrix whose entries are all zero (\\(a_{ij} = 0\\) for \\(i = 1,...m\\) and \\(j = 1,... n\\)). A square matrix is a matrix with the same number of rows and columns (\\(m = n\\)). A diagonal matrix is a square matrix that has zeros everywhere except on the main diagonal. An upper (lower) triangular matrix is a matrix that has non-zero entries only above (below) the diagonal. A identity matrix is a diagonal matrix whose diagonal elements are all one. The identity matrix with dimension \\(n √ó n\\) is denoted by \\(I_n\\). Example for \\(n = 4\\): \\[I_4 = \\begin{pmatrix} 1 \\ \\ 0 \\ \\ 0 \\ \\ 0 \\\\ 0 \\ \\ 1 \\ \\ 0 \\ \\ 0 \\\\ 0 \\ \\ 0 \\ \\ 1 \\ \\ 0 \\\\ 0 \\ \\ 0 \\ \\ 0 \\ \\ 1 \\end{pmatrix}\\] 9.2 Basic matrix operations It is often necessary to compare, add and multiply two matrices, or even form the ‚Äúreciprocal‚Äù of a matrix. Definition 9.4 (Equality of two matrices) Two matrices \\(A\\) and \\(B\\) are equal if they have the same dimension and all elements are identical, i.e.¬†if \\(a_{ij} = b_{ij}\\), for all \\(i = 1, ... , m\\) and \\(j = 1, ... , n\\). For example, the two \\(2 √ó 2\\) are matrices \\(\\begin{pmatrix}2 &amp; 2x \\\\ 3 &amp; 1\\end{pmatrix}\\) and \\(\\begin{pmatrix} 2 &amp;4 \\\\ x+y &amp; 1 \\end{pmatrix}\\) equal if and only if \\(x = 2\\) and \\(y = 1\\). Definition 9.5 (Addition and subtraction of matrices) The sum of two matrices \\(A\\) and \\(B\\) exists if the matrices have the same dimension; in this case the sum is defined elementwise: \\[\\begin{align*} A+B&amp;= \\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp; \\ldots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; a_{23} &amp; \\ldots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots&amp; \\vdots &amp; &amp; \\vdots\\\\ a_{m1} &amp; a_{m2} &amp; a_{m3} &amp; \\ldots &amp; a_{mn} \\end{pmatrix}+ \\begin{pmatrix} b_{11} &amp; b_{12} &amp; b_{13} &amp; \\ldots &amp; b_{1n} \\\\ b_{21} &amp; b_{22} &amp; b_{23} &amp; \\ldots &amp; b_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots\\\\ b_{m1} &amp; b_{m2} &amp; b_{m3} &amp; \\ldots &amp; b_{mn} \\end{pmatrix}\\\\[10pt] &amp;= \\begin{pmatrix} a_{11}+b_{11} &amp; a_{12}+b_{12} &amp; a_{13}+b_{13} &amp; \\ldots &amp; a_{1n}+b_{1n} \\\\ a_{21}+b_{21} &amp; a_{22}+b_{22} &amp; a_{23}+b_{23} &amp; \\ldots &amp; a_{2n}+b_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots\\\\ a_{m1}+b_{m1} &amp; a_{m2}+b_{m2} &amp; a_{m3}+b_{m3} &amp; \\ldots &amp; a_{mn}+b_{mn} \\end{pmatrix} \\end{align*}\\] The difference \\(A ‚àí B\\) is defined analogously. Example 9.3 (Addition and subtraction of matrices) Consider the situation, where production process in Example 9.1 is changed in following way: production hours on machine 1 are increased by one hour for each of the three products. production hours on machine 2 remain unchanged. production hours on machine 3 decrease by \\(\\frac 13\\) for product 2 and increase by \\(\\frac 13\\) for product 3. Then, the new production process can be described by the sum of matrices \\(A\\) and \\(B\\), where: \\(A = \\begin{pmatrix} 2 &amp; 2 &amp; 2 \\\\ 3 &amp; 4 &amp; 1 \\\\ 6 &amp; \\frac{10}3 &amp; \\frac 23 \\end{pmatrix}\\) and \\(B = \\begin{pmatrix} 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; -\\frac 13 &amp; \\frac 13 \\end{pmatrix}\\) Their sum is defined element wise: \\[\\begin{align*} A+B&amp;= \\begin{pmatrix} 2 &amp; 2 &amp; 2 \\\\ 3 &amp; 4 &amp; 1 \\\\ 6 &amp; \\frac{10}3 &amp; \\frac 23 \\end{pmatrix}+ \\begin{pmatrix} 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; -\\frac 13 &amp; \\frac 13 \\end{pmatrix}\\\\ &amp;= \\begin{pmatrix} 2+1 &amp; 2+1 &amp; 2+1 \\\\ 3+0 &amp; 4+0 &amp; 1+0 \\\\ 6+0 &amp; \\frac{10}3 - \\frac 13 &amp; \\frac 23+\\frac 13 \\end{pmatrix}\\\\ &amp;= \\begin{pmatrix} 3 &amp; 3 &amp; 3 \\\\ 3 &amp; 4 &amp; 1 \\\\ 6 &amp; 3 &amp; 1 \\end{pmatrix} \\end{align*}\\] Multiplication of a matrix by a scalar refers to scaling; each element of the matrix is multiplied by a scalar (= a real number). Definition 9.6 (Multiplication by a scalar) The product of a real number \\(\\lambda\\) with a matrix \\(A\\) is defined as: \\[\\begin{equation*} \\lambda\\cdot A=\\lambda\\cdot \\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp; \\ldots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; a_{23} &amp; \\ldots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots&amp; \\vdots &amp; &amp; \\vdots\\\\ a_{m1} &amp; a_{m2} &amp; a_{m3} &amp; \\ldots &amp; a_{mn}% \\end{pmatrix} = \\begin{pmatrix} \\lambda\\,a_{11} &amp; \\lambda\\, a_{12} &amp; \\lambda\\, a_{13} &amp; \\ldots &amp; \\lambda\\, a_{1n} \\\\ \\lambda\\, a_{21} &amp; \\lambda\\, a_{22} &amp; \\lambda\\, a_{23} &amp; \\ldots &amp; \\lambda\\, a_{2n} \\\\ \\vdots &amp; \\vdots&amp; \\vdots &amp; &amp; \\vdots\\\\ \\lambda\\, a_{m1} &amp; \\lambda\\, a_{m2} &amp; \\lambda\\, a_{m3} &amp; \\ldots &amp; \\lambda\\, a_{mn}% \\end{pmatrix} \\end{equation*}\\] Example 9.4 (Multiplication of matrices with a number) Consider the situation, where production process in Example 9.1 becomes more efficient, and the production hours reduce by 50%. This corresponds to multiplication of \\(A\\) with \\(0.5\\): \\[\\begin{align*} 0.5\\cdot A&amp;= 0.5\\cdot \\begin{pmatrix} 2 &amp; 2 &amp; 2 \\\\ 3 &amp; 4 &amp; 1 \\\\ 6 &amp; \\frac{10}3 &amp; \\frac 23 \\end{pmatrix}\\\\ &amp;= \\begin{pmatrix} 0.5\\cdot 2 &amp; 0.5\\cdot 2 &amp; 0.5\\cdot 2 \\\\ 0.5\\cdot 3 &amp; 0.5\\cdot 4 &amp; 0.5\\cdot 1 \\\\ 0.5\\cdot 6 &amp; 0.5\\cdot \\frac{10}3 &amp; 0.5\\cdot\\frac 23 \\end{pmatrix}\\\\ &amp;= \\begin{pmatrix} 1&amp; 1 &amp; 1 \\\\ 1.5 &amp; 2 &amp; 0.5 \\\\ 3 &amp; \\frac 53 &amp; \\frac 13 \\end{pmatrix} \\end{align*}\\] Before we define the multiplication of matrices with matrices, we consider the product of two vectors (the dot product or scalar product) as a special case. Definition 9.7 (dot product) Let \\(\\bf x^\\top\\) be an \\(n\\)-dimensional row vector (\\(1 \\times n\\)) and \\(\\bf y\\) be an \\(n\\)-dimensional column vector (\\(n \\times 1\\)). Then the dot product or the scalar product \\(\\bf x^\\top y\\) is defined as the sum of the products of the elements of \\(\\bf x\\) and \\(\\bf y\\): \\[\\begin{equation*} \\begin{pmatrix} x_{1} &amp; x_{2} &amp; \\ldots &amp; x_{n} \\end{pmatrix} \\, \\begin{pmatrix} y_{1}\\\\ y_{2}\\\\ \\vdots\\\\ y_{n} \\end{pmatrix} = x_{1} y_{1} + x_{2} y_{2} + \\cdots + x_{n} y_{n} =\\sum _{i=1}^n x_{i} y_{i}. \\end{equation*}\\] The dot product is thus an operation that returns a number from two vectors. This number can be interpreted geometrically. It tells you to what extent the vectors, which are represented as arrows from the coordinate origin to the point with vector elements as coordinates, point in the same direction (see the figure below). If the dot product is \\(\\color{green}{positive}\\), the angle between the arrows is \\(\\color{green}{\\alpha&lt;90¬∞}\\). For a \\(\\color{red}{negative}\\) dot product, the angle becomes \\(\\color{red}{\\beta&gt;90¬∞}\\). If the dot product is zero, the arrows are perpendicular to each other (at a 90¬∞ angle). The angle between the vectors as arrows can also be used as a similarity measure: the smaller the angle, the more similar the data is, represented as points in \\(\\mathbb R^n\\). Figure 9.1: Illustation of the dot product Example 9.5 (dot product) The dot product \\(\\bf x^\\top y\\) of \\(\\bf x = \\begin{pmatrix} 3 &amp; 3 \\end{pmatrix}\\) and \\(\\bf y = \\begin{pmatrix} 1\\\\ 5 \\end{pmatrix}\\) is: \\[\\begin{equation*} \\begin{pmatrix} 3 &amp; 3 \\end{pmatrix} \\, \\begin{pmatrix} 1\\\\ 5 \\end{pmatrix} = 3\\cdot 1 + 3 \\cdot 5= 18. \\end{equation*}\\] The dot product \\(\\bf x^\\top y\\) of \\(\\bf x = \\begin{pmatrix} 3 &amp; -3 \\end{pmatrix}\\) and \\(\\bf y = \\begin{pmatrix} -1\\\\ 5 \\end{pmatrix}\\) is: \\[\\begin{equation*} \\begin{pmatrix} 3 &amp; -3 \\end{pmatrix} \\, \\begin{pmatrix} -1\\\\ 5 \\end{pmatrix} = 3\\cdot (-1) + (-3) \\cdot 5= -18. \\end{equation*}\\] To be able to interpret the dot product in the sense of cosine of the corresponding angle, we have to normalize it, i.e.¬†take the lengths of the vectors into account. To do this, we define the Euclidean norm of a vector. Definition 9.8 (Euclidean norm of a vector) The Euclidean norm (length) of a column vector \\(\\bf x\\) is denoted by \\(\\lvert \\lvert \\bf x \\rvert \\lvert\\) and is defined as: \\[\\lvert \\lvert {\\mathbf {x}} \\rvert \\lvert = \\sqrt{\\mathbf {x^\\top x}} = \\sqrt{ \\sum_{i=1}^{n} x_i^2 }\\] Example 9.6 (Euclidean norm) The Euclidean norm of \\(\\bf z = \\begin{pmatrix} 0\\\\ 4\\\\ -3 \\end{pmatrix}\\) is: \\[\\begin{align*} ||{\\bf{z}}||&amp;={\\bf{z}}^\\top {\\bf{z}}\\\\ &amp;=\\sqrt{\\begin{pmatrix} 0 &amp; 4 &amp; -3 \\end{pmatrix} \\cdot \\begin{pmatrix} 0\\\\ 4\\\\ -3 \\end{pmatrix}}\\\\ &amp;= \\sqrt{(0)^2 + (4)^2 + (-3)^2} =\\sqrt{25} = 5. \\end{align*}\\] Example 9.7 (scalar product) Continuation of 9.5. The scalar product \\(\\bf x^\\top y\\) of \\(\\bf x = \\begin{pmatrix} 3 &amp; 3 \\end{pmatrix}\\) and \\(\\bf y = \\begin{pmatrix} 1\\\\ 5 \\end{pmatrix}\\) is \\(18.\\) The Euclidean norm of \\(x\\): \\[||x|| = \\sqrt{x^\\top x} = \\sqrt{3^2+3^2}=\\sqrt{18}.\\] The Euclidean norm of \\(y\\): \\[||y|| = \\sqrt{y^\\top y} = \\sqrt{1^2+5^2}=\\sqrt{26}.\\] The angle between the vectors: \\[\\begin{align}\\alpha &amp;= \\arccos\\left(\\frac{x^\\top y}{||x||\\cdot||y||}\\right) \\\\ &amp;= \\arccos\\left(\\frac{18}{\\sqrt{18}\\sqrt{26}}\\right)= \\arccos(0.8321) = 0.588rad\\\\ &amp;\\approx33.7¬∞ \\end{align}\\] The remaining case is when the dot product is zero. In this case the vectors are perpendicular to each other. Such vectors form, for example, useful coordinate systems. It also makes sense if the vectors that form the basis of such coordinate systems have the length \\(1\\) (intuitively: one step in each direction). When you bring the length of vectors to \\(1\\), you term it normalize. The following definition makes the terms more precise. Definition 9.9 (Orthogonal and orthonormal vectors) Two vectors are orthogonal if their dot product is zero. This means that the two vectors are perpendicular to each other. Vectors that are pairwise orthogonal and all have length one are said to be orthonormal. Exercise 9.1 (find an orthogonal vector) Consider \\(\\mathbf x = \\begin{pmatrix} 3 &amp; -3 &amp; a \\end{pmatrix}\\) and \\(\\bf y = \\begin{pmatrix} 1\\\\ 1\\\\ -5 \\end{pmatrix}.\\) Find \\(a\\) such that the vectors are orthogonal. Answer The dot product is: \\[3\\cdot 1 + (-3) \\cdot 1 + a\\cdot (-5) =3 -3 -5a = -5a.\\] Since the dot product of orthogonal vectors is zero, we have: \\[-5a=0\\rightarrow a=0.\\] We obtain, \\(\\mathbf x = \\begin{pmatrix} 3 &amp; -3 &amp; 0 \\end{pmatrix}.\\) Exercise 9.2 (find orthonormal vectors) Consider \\(\\mathbf x = \\begin{pmatrix} a &amp; b &amp; a \\end{pmatrix}\\) and \\(\\bf y = \\begin{pmatrix} 0\\\\ 0.6\\\\ -0.8 \\end{pmatrix}.\\) Find \\(a,b&gt;0\\) such that the vectors are orthonormal. Answer The dot product is: \\[a\\cdot 0+ b \\cdot 0.6 + a\\cdot (-0.8) =0.6 b -0.8a \\stackrel{!}{=} 0.\\] So, \\(a=3/4\\cdot b.\\) On the other hand, the norm of \\(\\bf x\\) is: \\[\\sqrt{a^2+b^2+a^2} \\stackrel{!}{=} 1\\rightarrow 2a^2 + b^2 = 1. \\] Plugging in the above \\(a=3/4\\cdot b,\\) we have: \\[2\\cdot 9/16b^2 + b^2 = 1\\rightarrow 17/8b^2 =1\\rightarrow b = \\sqrt{8/17} = 2\\sqrt{2/17}.\\] Hence, \\(a=3/4\\cdot 2\\sqrt{2/17} = 1.5 \\cdot \\sqrt{2/17}.\\) Therefore: \\(\\mathbf x = \\begin{pmatrix} 1.5 \\cdot \\sqrt{2/17} &amp; \\sqrt{8/17} &amp; 1.5 \\cdot \\sqrt{2/17} \\end{pmatrix}\\) The product of two matrices is defined in such a way that some properties of multiplication of real numbers are preserved. Definition 9.10 (product of two matrices) Let \\(A\\) be an \\(m √ó n\\) matrix and \\(B\\) an \\(n √ó q\\) matrix (i.e.¬†the number of columns in \\(A\\) corresponds to the number of rows in \\(B\\) ‚Äì important!). Then the product \\(C = A ¬∑ B\\) is defined as the \\(m √ó q\\) matrix with the elements: \\(c_{ij}= \\sum_{k=1}^{n} a_{ik} \\ b_{kj}\\), \\(i = 1, ... , m\\), \\(\\ j = 1, ... , q\\). In other words: The entry \\(c_{ij}\\) is the scalar product of the \\(i\\)th row vector and the \\(j\\)th column vector: \\[\\begin{equation*} \\begin{pmatrix} a_{i1} &amp; a_{i2} &amp; \\ldots &amp; a_{in} \\end{pmatrix} \\, \\begin{pmatrix} b_{1j}\\\\ b_{2j}\\\\ \\vdots\\\\ b_{nj} \\end{pmatrix} = a_{i1} b_{1j} + a_{i2} b_{j2} + \\cdots + a_{in} b_{nj} =c_{ij}. \\end{equation*}\\] Example 9.8 (matrix multiplication) Let \\(A\\) and \\(B\\) be given as: \\[\\begin{equation*} A=\\begin{pmatrix} 3 &amp; \\phantom{-}1 \\\\ 2 &amp; -2\\\\ 0 &amp; \\phantom{-}2% \\end{pmatrix} ,\\quad\\quad B=\\begin{pmatrix} 1 &amp; 0 &amp; -1\\\\ 2 &amp; 3 &amp; \\phantom{-}0% \\end{pmatrix} \\end{equation*}\\] Then the product of \\(A\\) and \\(B\\) is \\(3\\times 3\\) Matrix: \\[\\begin{align*} AB &amp;= \\begin{pmatrix} 3\\cdot 1+1\\cdot2=5 &amp; 3\\cdot 0+1\\cdot 3=3 &amp; 3\\cdot (-1)+1\\cdot 0=-3\\\\ 2\\cdot1-2\\cdot2=-2 &amp; 2\\cdot 0-2\\cdot 3=-6 &amp; 2\\cdot (-1)-2\\cdot 0=-2\\\\ 0\\cdot 1+2\\cdot 2=4 &amp; 0\\cdot 0+2\\cdot 3=6 &amp; 0\\cdot (-1)+2\\cdot 0=0% \\end{pmatrix}\\\\ &amp;=\\begin{pmatrix} \\phantom{-}5 &amp; \\phantom{-}3 &amp; -3 \\\\ -2 &amp; -6 &amp; -2 \\\\ \\phantom{-}4 &amp; \\phantom{-}6 &amp; \\phantom{-}0% \\end{pmatrix} \\end{align*}\\] In Excel, the product of two matrices is calculated as follows: Input of matrices \\(A\\) and \\(B\\) in Excel; Selecting the cells that will contain the product \\(A\\, B\\) to be entered in; Enter the formula {=MMULT(‚Äúrange of \\(A\\)‚Äù,‚Äúrange from \\(B\\)‚Äù)} With the confirmation { CTRL + SHIFT + ENTER} result will be calculated. The following matrices are given: \\(A = \\begin{pmatrix} 3 \\ \\ -5 \\ \\ \\ \\ \\ \\ 4 \\\\ 2 \\ \\ \\ -2 \\ \\ -2 \\end{pmatrix}\\) \\(B = \\begin{pmatrix} -2 \\ \\ -3 \\\\ 5 \\ \\ \\ -2 \\\\ 4 \\ \\ \\ \\ 4 \\ \\end{pmatrix}\\). Compute their product! ‚Äò\\(\\begin{pmatrix} -15 \\ \\ -15 \\\\ 2 \\ \\ \\ \\ \\ \\ 2 \\end{pmatrix}\\)‚Äô ‚Äò\\(\\begin{pmatrix} -10 \\ \\ -10 \\\\ 3 \\ \\ \\ \\ \\ \\ 3 \\end{pmatrix}\\)‚Äô Submit Matrices are often used to solve (large) linear systems of equations. Example 9.9 (Systems of linear equations) We consider an LGS consisting of \\(m\\) linear ones Equations and \\(n\\) variables: \\[\\begin{equation*} \\begin{array}{ccccccccc} a_{11} x_1 &amp;+&amp; a_{12} x_2 &amp;+&amp; \\cdots &amp;+&amp; a_{1n} x_n &amp;=&amp; b_1\\\\ a_{21} x_1 &amp;+&amp; a_{22} x_2 &amp;+&amp; \\cdots &amp;+&amp; a_{2n} x_n &amp;=&amp; b_2\\\\ \\vdots &amp; &amp; \\vdots &amp; &amp; \\ddots &amp; &amp; \\vdots &amp; &amp; \\vdots\\\\ a_{m1} x_1 &amp;+&amp; a_{m2} x_2 &amp;+&amp; \\cdots &amp;+&amp; a_{mn} x_n &amp;=&amp; b_m \\end{array} \\end{equation*}\\] The LGS can be written as a matrix product: \\[\\begin{equation*} Ax=b \\end{equation*}\\] where \\(A=\\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\ldots &amp; a_{1n}\\\\ a_{21} &amp; a_{22} &amp; \\ldots &amp; a_{2n}\\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots\\\\ a_{m1} &amp; a_{m2} &amp; \\ldots &amp; a_{mn} \\end{pmatrix}\\), \\(x=\\begin{pmatrix} x_{1} \\\\ x_{2}\\\\ \\vdots\\\\ x_n \\end{pmatrix}\\), \\(b=\\begin{pmatrix} b_{1} \\\\ b_{2}\\\\ \\vdots\\\\ b_m \\end{pmatrix}\\). The following theorem contains some properties of matrix multiplication. Theorem 9.1 (Properties of matrix multiplication) Let \\(A\\) be an \\(m \\times n\\) matrix and let \\(B\\) and \\(C\\) be matrices such that the following operations are well defined: Multiplication by the identity matrix: \\(A I_n = A\\) and \\(I_m A = A\\). associative law: \\((A + B) + C = A + (B + C)\\) \\((AB)C = A(BC)\\) Commutative Law of Addition: \\(A + B = B + A\\) distributive law: \\(A(B + C) = AB + AC\\) \\((A + B)C = AC + BC\\) Important: There is no commutative law for multiplication! As a rule \\(AB \\neq BA\\) holds, even if both products are well defined. Exercise 9.3 (Matrix multiplication I) Check that \\(AB\\not= BA\\) for the matrices \\(\\displaystyle A= \\begin{pmatrix} 2 &amp; 1 \\\\ 1 &amp; 1 \\end{pmatrix}\\) and \\(\\displaystyle B= \\begin{pmatrix} 1 &amp; -1 \\\\ 0 &amp;\\phantom{-}2 \\end{pmatrix}\\). Matrices that have the property \\(AB= BA\\) are called idempotent matrices. Definition 9.11 (idempotence) A square matrix \\(A\\) is called idempotent if: \\(A\\, A=A\\). Exercise 9.4 (Idempotent Matrices) Show that the following matrices are idempotent: \\[\\begin{pmatrix} -1 &amp; 2\\\\ -1 &amp; 2 \\end{pmatrix}\\] and \\[\\displaystyle \\begin{pmatrix} \\phantom{-}3 &amp; \\phantom{-}6\\\\ -1 &amp; -2 \\end{pmatrix}\\] Exercise 9.5 (Matrix multiplication II) be \\(A = \\begin{pmatrix} 2 \\ 1 \\\\ 1\\ 1 \\\\ 1 \\ 1 \\end{pmatrix}\\) and \\(B = \\begin{pmatrix} 1 \\ -1 \\ \\ 1 \\\\ 0 \\ \\ \\ \\ \\ 2 \\ \\ \\ 1\\end{pmatrix}\\) Both products are well defined, but it is easy to see that \\(AB \\neq BA\\). Answer 9.3 Economic Applications 9.3.1 Monthly consumer spending The column vector \\(x\\) represents the quantities of \\(n\\) goods that a consumer buys monthly: \\(x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ ... \\\\ x_n \\end{pmatrix}\\) The associated prices (in Euro) per unit of each consumer good are entered in the row vector \\(p^\\top\\): \\(p^\\top=(p_1 \\ \\ p_2 \\ \\ ... \\ \\ p_n)\\) The monthly consumer spending corresponds to the scalar product \\(E = p^\\top x\\): \\(E= p^\\top x= (p_{1} \\ \\ p_{2} \\ \\ ... \\ p_{n}) \\begin{pmatrix} x_{1} \\\\ x_{2} \\\\ . \\\\ . \\\\ x_{n} \\end{pmatrix} = \\sum_{i=1}^{n} p_ix_i\\) 9.3.2 Regional migration The transition matrix from section 1 above describes the migratory behavior of the population in three regions. Currently, i.e.¬†at the time \\(t = 0\\), the population is distributed over the three regions as follows (numbers in million), \\({\\bf x_0} = \\begin{pmatrix} 5 \\\\ 10 \\\\ 6 \\end{pmatrix}\\) With the transition matrix \\(P\\) \\(P = \\begin{pmatrix} 0.80 \\ \\ 0.15 \\ \\ 0.05 \\\\ 0.10 \\ \\ 0.70 \\ \\ 0.05\\\\ 0.10 \\ \\ 0.15 \\ \\ 0 ,90 \\\\ \\end{pmatrix}\\) we can find the population distribution at the beginning of the next period (\\(t = 1\\)): \\({\\bf x_1} = P{\\bf x_0}\\). The solution \\({\\bf x_1} = P {\\bf x_0}\\) with the concrete numbers is \\[\\begin{align*} P{\\bf x_0} &amp;= \\begin{pmatrix} 0.80 \\ \\ 0.15 \\ \\ 0.05 \\\\ 0.10 \\ \\ 0.70 \\ \\ 0.05\\\\ 0.10 \\ \\ 0.15 \\ \\ 0 ,90 \\\\ \\end{pmatrix} \\begin{pmatrix} 5 \\\\ 10 \\\\ 6 \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} 0.80 \\cdot 5\\ + \\ 0.15 \\cdot 10 \\ + \\ 0.05 \\cdot 6\\\\ 0.10 \\cdot 5 \\ + \\ 0.70 \\cdot 10 \\ + \\ 0.05 \\cdot 6\\\\ 0.10 \\cdot 5\\ + \\ 0.15 \\cdot 10 \\ + \\ 0.90 \\cdot 6 \\\\ \\end{pmatrix} =\\begin{pmatrix} 5.8 \\\\7.8\\\\ 7.4\\end{pmatrix} \\end{align*}\\] According to this, after a period more people live in regions 1 and 3, whereas the population in region 2 has shrunk. Similarly, it can be calculated how the population is distributed over the three regions after two periods: \\[{\\bf x_2} = P{\\bf x_1} = P(P{\\bf x_0} ) = P^ 2 {\\bf x_0}. \\] In general, after \\(n\\) periods \\[{\\bf x_n} = P{\\bf x_{n-1}} = P^ n {\\bf x_0}. \\] Exercise 9.6 (Regional migration) Determine \\(\\bf x_2\\), the population in the three regions at the end of the second period. Answer Exercise 9.7 (customer order) The customer orders of a manufacturer are: ‚Äì Customer 1 orders 3 units of product 1, ‚Äì Customer 2 orders 2 units of product 1, ‚Äì Customer 3 orders 0 units of product 1, ‚Äì Customer 4 orders 7 units of product 1, ‚Äì Customer 1 orders 9 units of product 2, ‚Äì Customer 2 orders 1 units of product 2, ‚Äì Customer 3 orders 2 units of product 2, ‚Äì Customer 4 orders 3 units of product 2, ‚Äì Customer 1 orders 5 units of product 3, ‚Äì Customer 2 orders 3 units of product 3, ‚Äì Customer 3 orders 6 units of product 3, ‚Äì Customer 4 orders 4 units of product 3. Write the orders in matrix notation and determine the revenue per customer for the following prices: ‚Äì a unit of product 1 costs p1 = 2 euros, ‚Äì a unit of product 2 costs p2 = 4 euros, ‚Äì a unit of product 3 costs p3 = 10 euros Answer 9.4 Transpose of a matrix We have already seen that you can use transposition to turn a column vector into a row vector and vice versa. You can also transpose matrices and thus swap their dimensions. Definition 9.12 (transpose of a matrix) Let \\(A\\) be a \\(m\\times n\\) matrix. The Transpose of a matrix \\(A^\\top\\), also written as \\(A^\\prime\\), is a \\(n\\times m\\) matrix, which is created by adding the rows (columns) from \\(A\\) to the Columns (rows) of \\(A^\\top\\) makes: \\[\\begin{equation*} A^\\top = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\ldots &amp; a_{1n}\\\\ a_{21} &amp; a_{22} &amp; \\ldots &amp; a_{2n}\\\\ \\vdots &amp; \\vdots &amp;&amp; \\vdots\\\\ a_{m1} &amp; a_{m2} &amp; \\ldots &amp; a_{mn} \\end{pmatrix}^\\top = \\begin{pmatrix} a_{11} &amp; a_{21} &amp; \\ldots &amp; a_{m1}\\\\ a_{12} &amp; a_{22} &amp; \\ldots &amp; a_{m2}\\\\ \\vdots &amp; \\vdots &amp; \\ldots &amp; \\vdots\\\\ a_{1n} &amp; a_{2n} &amp; \\ldots &amp; a_{mn} \\end{pmatrix} \\end{equation*}\\] Example 9.10 (Transposing a matrix) \\[\\begin{equation*} \\begin{pmatrix} 3 &amp; 1 \\\\ 2 &amp; -2 \\\\ 0 &amp; 2% \\end{pmatrix}^\\top = \\begin{pmatrix} 3 &amp; 2 &amp; 0 \\\\ 1 &amp; -2 &amp; 2% \\end{pmatrix} \\end{equation*}\\] Are a square matrix and its transposed matrix identical, i.e.¬†if \\(A^\\top=A\\) then it is called symmetric Matrix. Transposing a vector results in out of a row vector becomes a column vector and vice versa. Theorem 9.2 (Properties of the transpose) Transposing a transposed matrix produces the original matrix: \\((A^{\\top})^{\\top}=A\\). The transpose of a sum of matrices is equal to Sum of the transposed matrices: \\[\\begin{equation*} (A+B+C)^{\\top}=A^{\\top}+B^{\\top}+C^{\\top}. \\end{equation*}\\] The transpose of a well-defined matrix product \\(AB\\) is the dimension \\(m\\times m\\), where \\(A\\) is the dimension \\(m\\times n\\) and \\(B\\) has the dimension \\(n\\times m\\) is given through: \\[\\begin{equation*} (AB)^{\\top}=B^{\\top}A^{\\top}. \\end{equation*}\\] For three matrices with corresponding dimensions \\(A, B\\) and \\(C\\) is: \\((ABC)^{\\top}=C^{\\top}B^{\\top}A^{\\top}\\). 9.5 Determinant and inverse of a matrix We define the inverse of a square matrix. Definition 9.13 (Inverse of a square matrix) Let \\(A\\) be a square \\(n\\times n\\) matrix. The \\(n\\times n\\) matrix \\(B\\) is the inverse matrix of \\(A\\) if: \\[\\begin{equation*} AB=BA=I_n. \\end{equation*}\\] If such a matrix \\(B\\) exists, then \\(A\\) is said to be invertible or non-singular and one writes \\(A^{-1}\\) for the inverse matrix. If a matrix \\(A\\) is not invertible, then it is said to be singular. If we can find the inverse of the matrix describing a linear system of equations (LSE), it will help us it. Example 9.11 (Inverse of a matrix in LSE) We consider an LSE in matrix form: \\[\\begin{equation*} A{\\bf x}={\\bf b}, \\end{equation*}\\] whereby \\(A\\) is a \\(n\\times n\\) square coefficient matrix, \\(\\bf x\\) a \\(n\\times 1\\) vector with unknowns and \\(\\bf b\\) a \\(n\\times 1\\) vector consisting of constants. This system can be solved for \\(\\bf x\\) if the matrix \\(A\\) is invertible. In this case both sides of the equation are filled with \\(A^{-1}\\) multiplied: \\[\\begin{equation*} A^{-1}A{\\bf x}=A^{-1}{\\bf b}, \\end{equation*}\\] from what \\[\\begin{equation*} {\\bf x}=A^{-1}{\\bf b} \\end{equation*}\\] follows as the solution of the system. We derive the inverse of a \\(2\\times 2\\) matrix. We consider an invertible \\(2\\times 2\\) matrix¬† \\[\\begin{equation*} \\displaystyle A= \\begin{pmatrix} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22}% \\end{pmatrix} \\end{equation*}\\] with the associated inverse matrix: \\[\\begin{equation*} A^{-1}= \\begin{pmatrix} \\alpha _{11} &amp; \\alpha _{12} \\\\ \\alpha _{21} &amp; \\alpha _{22}% \\end{pmatrix}. \\end{equation*}\\] We shall now derive the relationship between the elements of \\(A\\) and the elements of \\(A^{-1}\\). By definition, \\(AA^{-1}=I_{2}\\), i.e. \\[\\begin{equation*} \\begin{pmatrix} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22}% \\end{pmatrix} \\begin{pmatrix} \\alpha _{11} &amp; \\alpha _{12} \\\\ \\alpha _{21} &amp; \\alpha _{22} \\end{pmatrix} =\\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix}. \\end{equation*}\\] This gives a system with four equations and four unknowns: \\(\\alpha _{11}\\), \\(\\alpha _{12}\\), \\(\\alpha _{21}\\) and \\(\\alpha _{22}\\). Solving the system of equations gives: \\[\\begin{align*} \\alpha _{11} &amp;=\\frac{a_{22}}{a_{22}a_{11}-a_{21}a_{12}} \\\\ \\alpha _{21} &amp;=\\frac{-a_{21}}{a_{22}a_{11}-a_{21}a_{12}} \\\\ \\alpha _{12} &amp;=\\frac{-a_{12}}{a_{22}a_{11}-a_{21}a_{12}} \\\\ \\alpha _{22} &amp;=\\frac{a_{11}}{a_{22}a_{11}-a_{21}a_{12}} \\end{align*}\\] Accordingly, the inverse of \\(A\\) is given through \\[\\begin{equation*} A^{-1}=\\frac{1}{a_{22}a_{11}-a_{21}a_{12}} \\begin{pmatrix} a_{22} &amp; -a_{12} \\\\ -a_{21} &amp; a_{11} \\end{pmatrix}. \\end{equation*}\\] The denominator of the prefactor, \\(a_{22}a_{11}-a_{21}a_{12}\\), is called the determinant. The Inverse exists if and only if the determinant is different from zero. Theorem 9.3 (Calculation rules for the inverse) Let \\(A\\) be a square matrix. Then: \\((A^{-1})^{-1}=A\\), \\((A^\\top)^{-1}=(A^{-1})^\\top\\), \\((AB)^{-1}=B^{-1}A^{-1}\\) \\((\\lambda \\cdot A)^{-1}=\\frac{1}{\\lambda}\\cdot A^{-1}\\) for all \\(\\lambda&gt;0\\). One can perform matrix inversion in Excel. Namely, the inverse of a matrix can be found in Excel as follows: Entering the matrix \\(A\\) in Excel; Selection of the cells in which the result \\(A^{-1}\\) is entered shall be; Enter the command =MINVERSE(‚Äúrange of \\(A\\)‚Äù) With a German-language Excel, the command is MINV. Confirm with CTRL + SHIFT + ENTER to get the result calculate. Example 9.12 (Matrix inverse in Excel) Given: \\(A = \\begin{pmatrix} -3 \\ \\ \\ \\ \\ 4 \\\\ 4 \\ \\ \\ -3 \\end{pmatrix}\\) \\(\\begin{pmatrix} 0.281 \\ \\ \\ \\ \\ 0.349 \\\\ 0.349 \\ \\ \\ 0.281 ¬†\\end{pmatrix} \\) \\(\\begin{pmatrix} 0.364 \\ \\ \\ \\ \\ 0.418 \\\\ 0.418 \\ \\ \\ 0.364 ¬†\\end{pmatrix}\\) \\(\\begin{pmatrix} 0.429 \\ \\ \\ \\ \\ 0.571 \\\\ 0.571 \\ \\ \\ 0.429 ¬†\\end{pmatrix}\\) Submit Example 9.13 (Coffee and tea market) Consider the market for tea with supply \\(S_t\\) and demand \\(D_t\\) given as follows: \\[\\begin{align*} D_{t} &amp;=100-5p_{t}+3p_{k}, \\\\ S_{t} &amp;=-10+2p_{t}, \\end{align*}\\] where \\(p_t\\) is the price of tea and \\(p_k\\) is the price of coffee designated. Analogously, the market for coffee can be described as follows: \\[\\begin{align*} D_{k} &amp;=120-8p_k + 2p_t,\\\\ S_{k} &amp;=-20+5p_{k}. \\end{align*}\\] The equilibrium prices for tea and coffee, \\(p_{t}\\) and \\(p_{k}\\) arise precisely where supply and demand to match. Using the matrix notation, the equilibrium can be write as: \\[\\begin{equation*} A\\, {\\bf p} = {\\bf b}, \\end{equation*}\\] with \\[\\begin{equation*} A=\\begin{pmatrix} 7 &amp; -3 \\\\ -2 &amp; 13% \\end{pmatrix} ,\\quad {\\bf p}= \\begin{pmatrix} p_{t} \\\\ p_{k}% \\end{pmatrix} , \\quad {\\bf b}= \\begin{pmatrix} 110 \\\\ 140% \\end{pmatrix}. \\end{equation*}\\] So the solution is: \\[\\begin{equation*} {\\bf p}=A^{-1}{\\bf b}. \\end{equation*}\\] With \\[\\begin{equation*} A^{-1}= \\begin{pmatrix} 13/85 &amp; 3/85 \\\\ 2/85 &amp; 7/85% \\end{pmatrix} \\end{equation*}\\] therefore applies: \\[\\begin{equation*} {\\bf p}=\\begin{pmatrix} p_{t} \\\\ p_{k}% \\end{pmatrix} =\\begin{pmatrix} 13/85 &amp; 3/85 \\\\ 2/85 &amp; 7/85% \\end{pmatrix} \\, \\begin{pmatrix} 110 \\\\ 140% \\end{pmatrix} =\\begin{pmatrix} 21.76 \\\\ 14.12% \\end{pmatrix}. \\end{equation*}\\] Example 9.14 (Input-Output Matrix) A firm produces two outputs, \\(y_{1}\\) and \\(y_{2}\\), with two inputs, \\(z_{1}\\) and \\(z_{2}\\). Let \\(a_{ij}\\) denote the amount of \\(z_i\\) required to produce one unit of output \\(y_j\\). The coefficients \\(a_{ij}\\), \\(i,j=1,2\\), define the input-requirement matrix \\[\\begin{equation*} A=\\begin{pmatrix} 2 &amp; 1 \\\\ 3 &amp; 2% \\end{pmatrix}. \\end{equation*}\\] Given the input levels \\(z_{1}=50\\) and \\(z_{2}=80\\), what outputs \\(y_{1}\\) and \\(y_{2}\\) are produced? We have \\(z=Ay\\) \\(\\Longrightarrow y=A^{-1}z\\), and therefore \\(\\displaystyle\\begin{pmatrix} y_{1} \\\\ y_{2} \\end{pmatrix} =\\begin{pmatrix} 2 &amp; 1 \\\\ 3 &amp; 2 \\end{pmatrix}^{-1}\\, \\begin{pmatrix} 50 \\\\ 80 \\end{pmatrix}\\). The inverse is determined as \\[\\begin{equation*} \\begin{pmatrix} 2 &amp; 1 \\\\ 3 &amp; 2 \\end{pmatrix}^{-1}= \\frac{1}{4-3} \\begin{pmatrix} 2 &amp; -1 \\\\ -3 &amp; 2 \\end{pmatrix} =\\begin{pmatrix} 2 &amp; -1 \\\\ -3 &amp; 2 \\end{pmatrix}. \\end{equation*}\\] Finally, we obtain \\(\\displaystyle\\begin{pmatrix} y_{1} \\\\ y_{2} \\end{pmatrix} = \\begin{pmatrix} 2 &amp; -1 \\\\ -3 &amp; 2 \\end{pmatrix}\\, \\begin{pmatrix} 50 \\\\ 80 \\end{pmatrix} =\\begin{pmatrix} 20 \\\\ 10 \\end{pmatrix}\\). 9.5.1 More on the Determinant of a Matrix\\(^\\ast\\) When determining the inverse \\(A^{-1}\\), the special number - the determinant of the original matrix \\(A\\) - plays an important role. In the following chapters, this number is used, for example, to check for maxima and minima of multivariate functions. Below we define the determinant explicitly. Definition 9.14 (determinant) Let \\(A\\) be a \\(2\\times 2\\) matrix. the term \\(a_{22}a_{11}-a_{21}a_{12}\\) is the determinant of \\(A\\) and is denoted by \\(|A|\\) or \\(\\det(A)\\). Similarly, the determinant of an arbitrarily define a dimensional, square matrix. However, the calculation of the determinant slightly more complicated for \\(n&gt;2\\). We therefore restrict ourselves to \\(3√ó3\\) matrices for illustration. Theorem 9.4 (invertibility) A square matrix is non-singular (i.e.¬†invertible) if and only if (iff) its determinant is non-zero. Example 1.1 (Determinant of a $3\\times 3$ matrix) The following matrix is given \\[\\begin{equation*} A= \\begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23}\\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{bmatrix}. \\end{equation*}\\] The calculation of the determinant can be done using the catchy Rule of Sarrus (also called Hunter Fence Rule): The determinant of the \\(3\\times 3\\) matrix \\(A\\) is: \\[\\begin{align*} \\det(A) &amp;= a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}-a_{31}a_{22}a_{13}-a_{32}a_{23}a_{11}-a_{33}a_{21}a_{12}\\\\ &amp;= a_{11} (a_{22} a_{33} - a_{23} a_{32}) - a_{12} (a_{21} a_{33} - a_{23} a_{31}) + a_{13} (a_{21} a_{32} - a_{22} a_{31}) \\end{align*}\\] Sarrus‚Äô rule is restricted to \\(3√ó3\\) matrices. More generally, the calculation is done using subdeterminants. Consider the \\(2\\times 2\\) submatrices \\[\\begin{equation*} A_{11}= \\begin{bmatrix} a_{22} &amp; a_{23}\\\\ a_{32} &amp; a_{33} \\end{bmatrix}, A_{12}=\\begin{bmatrix} a_{21} &amp; a_{23}\\\\ a_{31} &amp; a_{33} \\end{bmatrix}, A_{13}=\\begin{bmatrix} a_{21} &amp; a_{22}\\\\ a_{31} &amp; a_{32} \\end{bmatrix}. \\end{equation*}\\] The determinant of the \\(3\\times 3\\) matrix \\(A\\) is: \\[\\begin{align*} \\det(A) &amp;= a_{11}|A_{11}|-a_{12}|A_{12}|+a_{13}|A_{13}|\\\\ &amp;= a_{11} (a_{22} a_{33} - a_{23} a_{32}) - a_{12} (a_{21} a_{33} - a_{23} a_{31}) + a_{13} (a_{21} a_{32} - a_{22} a_{31}) \\end{align*}\\] Note that the signs are alternating. Theorem 9.5 (Properties of the determinants) Let \\(A\\) be a square matrix. Then: \\(\\det(A^\\top)=\\det(A)\\), \\(\\det(A\\, B) = \\det(A) \\, \\det(B)\\), \\(\\det(A+B)\\not= \\det(A) + \\det(B)\\), im general. (‚Äúin general‚Äù should be understood as follows: It there may be instances where equality holds; equality is but not given in all cases.) Example 9.15 (determinant) Note that \\[\\begin{equation*} det\\begin{pmatrix} 3 &amp; 2 \\\\ 1 &amp; 4 \\end{pmatrix} =10 \\end{equation*}\\] as well as \\[\\begin{equation*} det\\begin{pmatrix} 3 &amp; 1 \\\\ 2 &amp; 4% \\end{pmatrix} =10. \\end{equation*}\\] Exercise 9.8 (determinant) Show that: \\(\\det(A^{-1})=1/\\det(A)\\). Solution By the definition of the inverse matrix: \\[AA^{-1}=I_n,\\] where \\(I_n\\) is the identity matrix. It holds: \\[\\det(I_n) = 1,\\] so \\[\\det(AA^{-1} = \\det(A) \\det(A^{-1}) = 1 \\Rightarrow \\det(A^{-1})=\\frac 1{\\det(A)}.\\] 9.5.2 Rank and determinant\\(^\\ast\\) Definition 9.15 (rank of a matrix) The row rank (column rank) of a matrix \\(A\\) (\\(rg(A)\\)) corresponds to the number of linearly independent rows (columns). It the following applies: row rank = column rank. Theorem 9.6 (Determinants of singular matrices) A matrix whose row (column) is a multiple of another row (column) is called singular. In this case are the rows (columns) are not linearly independent, the matrix has therefore not full row rank (column rank). Example 9.16 (Determinants of singular matrices) One can see that \\[\\begin{equation*} det\\begin{pmatrix} 3 &amp; 2 \\\\ 9 &amp; 6% \\end{pmatrix} =0, \\end{equation*}\\] \\[\\begin{equation*} det\\begin{pmatrix} 3 &amp; 6 \\\\ 6 &amp; 12% \\end{pmatrix} =0 \\end{equation*}\\] Theorem 9.7 (Determinant when adding the multiple of a column/row) If the matrix \\(B\\) from another matrix \\(A\\) through Addition of the multiple of a row (column) to another row (column) is generated, then the value of the determinant remains unchanged, i.e.¬†are the determinants of \\(A\\) and \\(B\\) identical. Example 9.17 (Determinant when adding the multiple of a column/row) \\[\\begin{equation*} det(A)=det\\left( \\begin{array}{cc} 3 &amp; 2 \\\\ 1 &amp; 4 \\end{array} \\right) =10, \\end{equation*}\\] \\[\\begin{equation*} det(B)=det\\left( \\begin{array}{cc} 3 &amp; 2 \\\\ 7 &amp; 8 \\end{array} \\right) =10 \\end{equation*}\\] Theorem 9.8 (determinant of a triangular matrix) The determinant of an upper (lower) triangular matrix corresponds to the product of the diagonal elements. Example 9.18 (determinant of a triangular matrix) \\[\\begin{equation*} det(A)=det\\left( \\begin{array}{cc} 3 &amp; 2 \\\\ 0 &amp; 4 \\end{array} \\right) =12, \\end{equation*}\\] \\[\\begin{equation*} det(B)=det\\left( \\begin{array}{cc} 3 &amp; 0 \\\\ 3 &amp; 4 \\end{array} \\right) =12. \\end{equation*}\\] Theorem 9.9 (Determinants when multiplying by a scalar) Can be a matrix \\(B\\) from another \\(n\\times n\\) matrix \\(A\\) by multiplying a row (column) by a scalar generate \\(\\lambda\\) then the determinant of \\(B\\) is just that \\(\\lambda\\) times the determinant of \\(A\\). becomes \\(B\\) by multiplying all elements of \\(A\\) by \\(\\lambda\\) is generated, then the determinant of \\(B\\) is the Determinant of \\(A\\) multiplied by \\(\\lambda ^{n}\\). Example 9.19 (Determinants when multiplying by a scalar) \\[\\begin{equation*} \\det(A)=\\det\\left( \\begin{array}{cc} 3 &amp; 2 \\\\ 1 &amp; 4 \\end{array} \\right) =10 \\end{equation*}\\] \\[\\begin{equation*} \\det(B)=\\det\\left( \\begin{array}{cc} 3 &amp; 2 \\\\ 3 &amp; 12% \\end{array} \\right) =30 \\end{equation*}\\] "],["calculus-with-n-variables.html", "Chapter 10 Calculus with \\(n\\) variables 10.1 Continuity of a function 10.2 Partial derivatives 10.3 Partial derivatives of higher order 10.4 Derivation of implicit functions\\(^\\ast\\)", " Chapter 10 Calculus with \\(n\\) variables So far in calculus we have looked at functions with one variable. However, application examples in linear algebra have already shown that typical problems involve functions of several variables. For example, a firm‚Äôs output level typically depends on several input variables. Therefore we extend the notions of continuity and differentiability to functions of several variables. This is the basis for the (constrained) optimization of functions of several variables. 10.1 Continuity of a function Let \\(x = (x_1, ... , x_n)\\) be a point in \\(\\mathbb {R}^n\\) , and \\(f (x) = f (x_1, ... , x_n ) = y\\) denote a function with \\(n\\) variables. In the univariate case (\\(n = 1\\)), it was sufficient to consider how the function approaches the point \\(f (a)\\) from the right and from the left to determine whether \\(f\\) is continuous at point \\(a\\): \\[\\lim_{ x\\rightarrow a^-} f (x) = \\lim_{x\\rightarrow a^+} f (x) = f (a).\\] In the multivariate case, there are infinitely many ways to approach \\(f (a)\\) (see figure on the right). The definition of continuity for functions in \\(\\mathbb {R}\\) is: a function \\(f : D\\rightarrow \\mathbb{R}\\) is continuous in \\(a \\in D\\) if for every sequence with \\(\\lim_{n\\rightarrow\\infty} x_n = a\\) applies: \\(\\lim_{n\\rightarrow \\infty} f (x_n) = f (a)\\). That is, for every sequence whose subsequent terms are almost all ‚Äúclose‚Äù to \\(a\\), the associated function values are almost all ‚Äúclose‚Äù to \\(f (a)\\), where ‚Äúclose‚Äù is determined through the (Euclidean) distance \\(|x_n ‚àí a|.\\) In the multivariate case, continuity is defined analogously for a function in \\(\\mathbb {R}^n\\) by (again) taking the Euclidean distance as a basis: \\[d(x,a)= \\sqrt{ \\sum_{i=1}^{n} (x_i-a_i)^2} = ||{\\bf x}-{\\bf a}||.\\] Special case \\(\\mathbb{R}^2\\) : \\[d(x,a)= \\sqrt{ (x_1-a_1)^2 + (x_2-a_2)^2}.\\] Definition 10.1 (Continuity of functions with n variables) A function \\(f\\) in \\(\\mathbb {R}^n\\) is continuous at point \\({\\bf a} = (a_1,\\ldots, a_n)^\\top\\), if for every \\(\\varepsilon&gt;0\\) there exists \\(\\delta&gt;0\\) such that from \\(||{\\bf x} - {\\bf a}||&lt;\\delta\\) follows \\(||f({\\bf x}) - f({\\bf a})||&lt;\\varepsilon.\\) 10.2 Partial derivatives If a function has a continuous derivative, it is said to be differentiable. We now extend the concept of derivatives for functions \\(f (x_1, ... , x_n)\\) in \\(\\mathbb {R}^n\\). The (first) partial derivative of \\(f\\) after the \\(i\\)-th variable \\(x_i\\) is obtained by deriving \\(f\\) after \\(x_i\\), where the remaining variables \\(x_1, ... , x_{i‚àí1}, x_{i+1}, ... , x_n\\) are treated as constants. Definition 10.2 (Partial Derivative) Let \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) be differentiable in each variable. The (first) partial derivatives of \\(f\\) for \\(i = 1, ... , n\\) are given by: \\[ \\frac{ \\partial f(x_1, ... x_n)}{ \\partial x_i} =\\lim_{ \\Delta x_i \\rightarrow 0} \\frac{f(x_1, ... , x_{i-1} , x_i+ \\Delta x_i, x_{i+1}, ... , x_n) -f(x_1, ... , x_n) }{ \\Delta x_i }. \\] Shorthand: \\[\\frac{ \\partial f}{ \\partial x_i } = f_{x_i}=f_i.\\] Since the partial derivatives are univariate derivatives, the usual derivation rules apply. In the bivariate case (two variables: \\(n = 2\\)), i.e.¬†\\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\), the following applies: \\(f_{x_1}(x_1,x_2)= \\frac{ \\partial f(x_1, x_2)}{ \\partial x_1} =\\lim _{ \\Delta x_1 \\rightarrow 0} \\frac{f(x_1, + \\Delta x_1, x_{2} -f(x_1,x_2) }{ \\Delta x_1 }\\) (partial derivative to \\(x_1\\)) \\(f_{x_2}(x_1,x_2)= \\frac{ \\partial f(x_1, x_2)}{ \\partial x_2} =\\lim _{ \\Delta x_2 \\rightarrow 0} \\frac{f(x_1,x_2 + \\Delta x_2) -f(x_1,x_2) }{ \\Delta x_2 }\\) (partial derivative with respect to \\(x_2\\)) The following figure illustrates the partial derivatives: Details Example 10.1 (Partial derivatives of a function of two variables) Let \\(f (x_1,x_2) = x_1^2 x_2\\). If \\(x_2\\) is kept constant, then the function is quadratic in \\(x_1\\) with the scaling factor \\(x_2\\). If \\(x_1\\) is kept constant, then the function is linear in \\(x_2\\) with slope \\(x_1^2\\) . This is reflected in the partial derivatives: \\[ f_{x_1}=\\frac{ \\partial f (x_1, x_2)}{ \\partial x_1 } = 2x_1x_2, \\] \\[ f_{x_2}=\\frac{ \\partial f (x_1, x_2)}{ \\partial x_2 } = x_1^2. \\] Exercise 10.1 (marginal productivity) Determine and interpret the partial derivatives of the production function \\(f (L,K) = 10L^{1/2} K^{1/2}\\). Here \\(L\\) represents the labor factor and \\(K\\) the capital factor. Answer Submit Partial derivatives \\(\\frac{\\partial f}{\\partial x_i}\\) depend in general on the values of the remaining variables \\(x_1, \\ldots , x_{i‚àí1}, x_{i+1},\\ldots, x_n\\). Functions in the class of additive separable functions have the property that their partial derivatives are independent of the other variables. Definition 10.3 (Additive separable functions) A function \\(f (x_1, ... , x_n)\\) is additive separable if it can be written as follows: \\[f (x_1, ... , x_n) = g_1 (x_1) + g_2 (x_2) + \\ldots + g_n (x_n),\\] where \\(g_i\\) , \\(i = 1, ... , n\\), are univariate functions. In the case of an additive separable function, \\[\\frac{\\partial f}{\\partial x_i} = g^\\prime_i(x_i).\\] Example 10.2 (Alex's utility function is an additive separable) Alex‚Äôs utility function, which we examined in the example 1.3, is additive separable because: \\[U(x,y) = \\underbrace{\\sqrt{x}}_{g(x)} + \\underbrace{\\sqrt{y}}_{g(y)}.\\] Therefore: \\[U_x(x,y) = U_x(x) = (\\sqrt{x})^\\prime = \\frac 12(x)^{-\\frac12} = \\frac 12\\cdot \\frac 1{x^{ \\frac12}} = \\frac1{2\\sqrt{x}}.\\] and \\[U_y(x,y) = U_y(y) = (\\sqrt{y})^\\prime = \\frac1{2\\sqrt{y}}.\\] The chain rule applies to partial derivatives. Theorem 10.1 (chain rule) Let \\(f (x_1(t), x_2(t))\\) be an additive separable function whose variables \\(x_1\\) and \\(x_2\\) both depend on \\(t\\) (e.g.¬†time). Then: \\[\\begin{equation} \\frac{df}{dt} = \\frac{\\partial f}{\\partial x_1} \\frac{dx_1}{dt} + \\frac{ \\partial f}{ \\partial x_2 } \\frac{dx_2}{dt} \\tag{10.1} \\end{equation}\\] Proof \\[\\begin{align*}\\frac{\\text{d} f}{\\text{d} t} &amp; = \\lim_{\\Delta t\\rightarrow 0} \\frac{f(x_1(t+\\Delta t), x_2(t+\\Delta t)) - f(x_1(t),x_2(t))} {\\Delta t}\\\\ &amp;= \\lim_{\\Delta t\\rightarrow 0} \\frac{f(x_1(t+\\Delta t), x_2(t+\\Delta t)) - f(x_1(t), x_2(t+\\Delta t))}{\\Delta t} \\\\ &amp; + \\lim_{\\Delta t\\rightarrow 0} \\frac{f(x_1(t), x_2(t+\\Delta t)) - f(x_1(t),x_2(t))} {\\Delta t}\\\\ &amp;= \\lim_{\\Delta t\\rightarrow 0} \\frac{f(x_1(t+\\Delta t), x_2(t+\\Delta t)) - f(x_1(t), x_2(t+\\Delta t))}{\\underbrace{\\Delta x_1}_{=x_1(t+\\Delta t)-x_1(t)}} \\frac{\\Delta x_1}{\\Delta t} \\\\[5pt] &amp;\\phantom{=\\,} + \\lim_{\\Delta t\\rightarrow 0} \\frac{f(x_1(t), x_2(t+\\Delta t)) - f(x_1(t),x_2(t))}{\\Delta x_2} \\frac{\\Delta x_2}{\\Delta t}\\\\ &amp;= \\frac{\\partial f}{\\partial x_1} \\frac{\\text{d} x_1}{\\text{d}}+ \\frac{\\partial f}{\\partial x_2}\\frac{\\text{d} x_2}{\\text{d} t} \\end{align*}\\] Example 10.3 (chain rule) Let \\(f (x_1,x_2) = 3x_1 + 5x_2\\) with \\(x_1(t) = t^2\\) and \\(x_2(t) = 4t^3\\) . The chain rule gives \\(\\frac{df}{dt} = 3\\frac{ d t^2}{ \\ dt} + 5\\frac{d4t^3}{dt} =6t+60t^2\\) The same result can be obtained by directly substituting the functions \\(x_1(t)\\) and \\(x_2(t)\\) into \\(f\\) and then deriving them. Example 10.4 (Chain rule for the utility function) If you want to consider the utility function from example 1.3 as a function of externalities/emissions (e.g.¬†CO\\(2\\)) that are associated with the consumption of the two goods, and given the emission functions: \\[t(x) = \\frac12x, x&gt;0; ~ t(y)=2y-1, y\\geq 1\\] one can derive the utility function according to the externality \\(t\\) as follows: \\(x,y\\) as functions of \\(t\\) (switch the emission functions to \\(x,y\\)): \\[x(t)=2t \\text{ and } y(t)=\\frac12(t+1).\\] Use the above chain rule to derive \\(U(x(t),y(t))\\) from \\(t\\): \\[\\begin{align}\\frac{dU}{dt} &amp;= \\color{blue}{\\frac{\\partial U}{\\partial x}}\\cdot \\color{red}{\\frac{dx}{ dt}} + \\color{green}{\\frac{\\partial U}{\\partial y}}\\cdot \\color{purple}{\\frac{dy}{dt}}\\\\ &amp;=\\color{blue}{\\frac1{2\\sqrt{x}}}\\cdot \\color{red}{2} + \\color{green}{\\frac1{2\\sqrt{y}}}\\cdot \\ color{purple}{\\frac12}\\\\ &amp;=\\frac1{\\sqrt{\\underbrace{x}}_{=2t}} + \\frac1{4\\sqrt{\\underbrace{y}}_{=0.5(t+1)}}\\\\ &amp;=\\frac1{\\sqrt{2t}} + \\frac1{4\\sqrt{0.5(t+1)}}. \\end{align}\\] 10.3 Partial derivatives of higher order Analogous to the univariate case, partial derivatives of higher order are obtained by multiple derivations. Definition 10.4 (Partial derivatives of the second order) Let \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) be a sufficiently differentiable function. The second order partial derivatives are given by: \\[\\frac{ \\partial^2 f(x_1, \\ldots, x_n)}{ \\partial x_i \\partial x_j} : = \\frac{ \\partial f_{x_i} (x_1, ..., x_n)}{ \\partial x_j} ,\\ \\ \\ i,j=1, ... , n.\\] Shorthand: \\[\\frac{ \\partial^2 f}{ \\partial x_i \\partial x_j} = f_{x_ix_j}=f_{ij}.\\] The number of second-order partial derivatives is \\(n^2\\) and results from the number of combinations of \\(i,j = 1, ... , n\\). The derivatives \\(f_{ij}, i \\neq j\\), are called cross derivatives. Example 10.5 (Partial derivatives of the second order) Let \\(f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}\\). The second order partial derivatives are given by: \\(f_{11}(x_1, x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_1^2}\\) \\(f_{12}(x_1, x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_1\\partial x_2}\\) \\(f_{21}(x_1, x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_2\\partial x_1}\\) \\(f_{22}(x_1, x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_2^2}.\\) For a function \\(f(x_1,x_2)=x_1^2\\cdot x_2\\), the second order partial derivatives are given by: \\(f_{11} (x_1,x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_1^2} = \\frac{ \\partial f_1 (x_1, x_2)}{ \\partial x_1} = 2x_2,\\) \\(f_{12} (x_1,x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_1\\partial x_2} = \\frac{ \\partial f_1 (x_1, x_2)}{ \\partial x_2} = 2x_1,\\) \\(f_{21} (x_1,x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_2\\partial x_1} = \\frac{ \\partial f_2 (x_1, x_2)}{ \\partial x_1} = 2x_1,\\) \\(f_{22} (x_1,x_2) = \\frac{ \\partial^2 f (x_1, x_2)}{ \\partial x_2^2} = \\frac{ \\partial f_2 (x_1, x_2)}{ \\partial x_2} = 0.\\) Submit 10.3.1 The gradient vector and the Hessian matrix The first-order, resp.¬†second-order partial derivatives are conveniently captured in vector, resp.¬†matrix form. Definition 10.5 (Gradient vector) Let \\(f:\\mathbb R^n\\rightarrow\\mathbb R\\) be a differentiable function. The gradient vector is the vector of the first-order partial derivatives: \\[\\begin{equation*} \\nabla f = \\begin{bmatrix} f_1\\\\ f_2\\\\ \\vdots\\\\ f_n \\end{bmatrix} \\quad\\text{ or }\\quad \\nabla f^\\top = \\begin{bmatrix} f_1 &amp; f_2 &amp; \\cdots &amp; f_n \\end{bmatrix}. \\end{equation*}\\] The operator \\(\\nabla\\), an upside-down \\(\\Delta\\), is called nabla. The term gradient refers to the elements of the vector indicating the grade or steepness of the function in each direction. Example 10.6 (Gradient Vector) Let \\(f(x_1,x_2)=5-2x_1+3x_2\\). The first derivatives are \\[\\begin{equation*} f_1=-2, \\quad f_2=3. \\phantom{movethistotheleftmovemove} \\end{equation*}\\] The gradient vector is \\[\\begin{equation*} \\nabla f = \\begin{bmatrix} -2\\\\ 3 \\end{bmatrix} \\end{equation*}\\] Definition 10.6 (Hessian matrix) Let \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) be a doubly differentiable function. The Hesse/ Hessian matrix contains the second-order partial derivatives: \\(H = \\begin{bmatrix} f_{11} \\ \\ f_{12} \\ \\ ... \\ \\ f_{1n} \\\\ f_{21} \\ \\ f_{22} \\ \\ ... \\ \\ f_{2n} \\\\ ..\\ \\ .. \\ \\ .. \\ \\ .. \\ \\ .. \\\\ f_{n1} \\ \\ f_{n2} \\ \\ ... \\ \\ f_{nn} \\end{bmatrix}\\) Example 10.7 (Gradient and Hessian matrix) Let \\(f (x_1, x_2) = x_1^2 x_2\\). The first partial derivatives (summarized as a vector, the so-called gradient) and the Hessian matrix are given as: \\[] G(x_1, x_2) =\\nabla f= \\begin{bmatrix} 2x_1 \\cdot x_2 \\\\ x_1^2 \\end{bmatrix} \\] \\[H(x_1, x_2) = \\begin{bmatrix} 2x_2 \\ \\ 2x_1 \\\\ 2x_1 \\ \\ 0 \\ \\ \\end{bmatrix}. \\] Theorem 10.2 (Young's theorem, Schwarz's theorem) Let \\(f (x_1, ... ,x_n)\\) be a function with continuous partial derivatives of first and second order. Then the order of differentiation in cross-derivatives is irrelevant. Formally: \\(f_{ij} = f_{ji}, \\ \\ i,j = 1, ... , n\\). It follows from Young‚Äôs theorem that the Hessian matrix is symmetric. Exercise 10.2 (The Gradient vector and the Hessian matrix) For the function \\(f(x,y) = x^2 -5xy^2\\) compute the Gradient vector and the Hessian matrix. Answer The Gradiant vector is: \\[ G(x, y) = \\nabla f=\\begin{bmatrix} f_x\\\\ f_y\\end{bmatrix}=\\begin{bmatrix} 2x- 5y^2\\\\ - 10xy \\end{bmatrix}. \\] The Hessian matrix is: \\[H(x,y) = \\begin{bmatrix} f_{xx} &amp; f_{xy}\\\\ f_{yx}&amp; f_{yy}\\end{bmatrix}= \\begin{bmatrix} 2 &amp; -10y\\\\ -10y &amp; -10x\\end{bmatrix}.\\] 10.4 Derivation of implicit functions\\(^\\ast\\) So far we always have functions in explicit form expressed, i.e.¬†in the form \\[\\begin{equation*} y=F(x_1,\\ldots,x_n). \\end{equation*}\\] In many economic problems, however, lies one functional relationship between two variables \\(x\\) and \\(y\\) in implicit form: \\[\\begin{equation*} F(x_1,\\ldots,x_n,y)=0. \\end{equation*}\\] This equation defines the variable \\(y\\) as implicit Function of the variables \\(x_1,\\ldots,x_n\\), i.e.¬†\\(y=y(x_1,\\ldots,x_n)\\). In some cases it is possible to use an implicit function convert to an explicit function by rearranging; in many cases this is not possible (e.g.: \\(F(x,y)=x^3 \\text{e}^y - 2y \\text{e}^x + 2=0\\)). Interestingly, in these cases, the derivative \\(y&#39;(x)\\) can still be determined. Example 10.8 (Implicit functions) Let \\(F(x,y)=2y+4x-10=0\\). Then: \\(y=f(x)=5-2x\\). Let \\(F(x,y)=\\text{e}^{x^2+y}-5=0\\). Then: \\(y=\\ln(5)-x^2\\). Let \\(F(x,y)=x^2-3xy + y^3-7=0\\). Then \\(y=y(x)\\) can be determined numerically (see figure). It turns out that \\(F(x,y)=0\\) is not necessarily a Function \\(f:\\mathbb R\\rightarrow\\mathbb R\\), \\(y=f(x)\\), describes; the Function term is to be understood as ‚Äúlocal‚Äù. Example 10.9 (Profit maximization) We also consider a profit-maximizing company Production function \\(y=f(x)\\). A unit of input \\(x\\) costs \\(w\\) euros. At a price level of \\(p\\) euro/unit, the profit is given as \\[\\begin{equation*} \\Pi(x) = p\\cdot f(x) - w\\cdot x. \\end{equation*}\\] At maximum profit applies: \\[\\begin{equation} p\\, f^\\prime(x) - w=0.\\tag{10.2} \\end{equation}\\] For exogenous variables \\(p\\) and \\(w\\), the company chooses \\(x\\) such that (10.2) holds. The possibility of implicit differentiation means that one does not rely on production functions where (10.2) is explicitly resolved, that is, \\(x\\) can not be determined explicitly as a function of \\(p\\) and \\(w\\). Theorem 3.1 (Derivation of implicit functions) Let \\(F(x,y)=c\\) be an implicit function with continuous derivatives of first-order in a neighborhood around \\((x_0,y_0)\\). If \\(F_y(x_0,y_0)\\not=0\\), then there is a continuous function \\(y=y(x)\\) defined on an interval \\(I\\) around \\(x_0\\) such that \\(F(x,y(x))=c\\) for all \\(x\\in I\\), \\(y(x_0)=y_0\\), and It applies \\[\\begin{equation} y^\\prime(x_0)= -\\frac{F_x(x_0,y_0)} {F_y(x_0,y_0)}. \\tag{10.3} \\end{equation}\\] Equation (10.3) is calculated using the chain rule (10.1): \\[\\begin{equation*} \\frac{\\partial}{\\partial x} F(x_0,y(x_0))= F_x(x_0,y(x_0)) + F_y(x_0,y(x_0)) \\cdot y^\\prime(x_0), \\end{equation*}\\] where the derivative is \\(0\\) since the function \\(F(x,y(x))\\) is constant in \\(x\\in I\\). Example 10.10 (Implicit Derivation) Look at the equation \\[\\begin{equation*} F(x,y)=x^2-3xy + y^3-7=0, \\end{equation*}\\] at point \\((x_0,y_0)=(4,3).\\) It applies \\[\\begin{align*} F_x (x,y)&amp;= 2x-3y\\quad \\text{and } F_x(4,3)=-1, \\\\ F_y (x,y)&amp;= -3x + 3y^2\\quad \\text{ and } F_y(4,3)=15. \\end{align*}\\] Since \\(F_y\\not=0\\) are the condition for the implicit Differentiation fulfilled and it applies \\[\\begin{equation*} f^\\prime(x_0) = -\\frac{F_x(x_0,y_0)} {F_y(x_0,y_0)} = \\frac{1}{15}. \\end{equation*}\\] 10.4.1 Contour lines / indifference curves\\(^\\ast\\) Consider a function \\(y=f(x_1,x_2)\\). This can a production function, a utility function, or a cost function. Often it is useful to consider a certain function value that is achieved by different combinations of the input variables \\((x_1,x_2)\\) (e.g.¬†all consumption bundles of two goods that provide the same utility level, or all input combinations that provide the same production output): \\[\\begin{equation*} \\{(x_1,x_2)|f(x_1,x_2)=y_0\\}. \\end{equation*}\\] The graphical representation of such sets in the \\(x_1\\)-\\(x_2\\) coordinate system results in so-called contour lines or indifference curves (in the case of utility functions). Contour lines can also be created using the implicit differentiation. Let \\(f(x_1,x_2)=2 x_1 + 3 x_2\\) describe a consumer utility. For any indifference curve, i.e.¬†any curve such that the equation \\(2 x_1+3 x_2=y\\) is satisfied for fixed \\(y\\), holds: \\[\\begin{equation*} \\frac{\\text{d} x_2}{\\text{d} x_1} = -\\frac{2}{3}. \\end{equation*}\\] "],["optimization-ii.html", "Chapter 11 Optimization II 11.1 First-order conditions 11.2 Second-order conditions 11.3 Optimization under constraints: Lagrange method", " Chapter 11 Optimization II We now deal with finding extremes (maximum and minimum) of functions of several variables. 11.1 First-order conditions As in the univariate case, we will first identify stationary points of multivariate functions \\(f (x_1, ... , x_n).\\) For the sake of simplicity, we use the notation \\({\\bf x} = (x_1, ... , x_n)\\) for points in \\(\\mathbb {R} ^n\\). Without constraints, the possible solution set of an optimization problem is the entire \\(\\mathbb {R} ^n.\\) With constraints, the solution set is restricted to a subset \\(X \\subset \\mathbb {R} ^n.\\) Definition 6.2 (Stationary points) The function \\(f: \\mathbb{R} ^n \\rightarrow \\mathbb{R}\\) has a stationary point at \\({\\bf x^‚àó} = (x_1^‚àó , \\ldots , x_n ^‚àó )\\), if: \\[\\begin{align} f_1(x_1^‚àó , \\ldots , x_n^‚àó) =&amp; 0\\\\ f_2(x_1^‚àó , \\ldots , x_n^‚àó) =&amp; 0\\\\ \\ldots &amp;\\\\ f_n(x_1^‚àó , \\ldots , x_n^‚àó) =&amp; 0 \\end{align}\\] As in the one-dimensional case, not all stationary points are extremes. In addition to inflection points, there are the so-called saddle points, at which the function attains a maximum in one direction and a minimum in another direction. As in the univariate case, a necessary condition for \\(f\\) to have a minimum or maximum at \\({\\bf x^‚àó}\\) is that \\({\\bf x^‚àó}\\) is a stationary point. Theorem 11.1 (Necessary conditions) Let \\(f: \\mathbb{R} ^n \\rightarrow \\mathbb{R}\\) be differentiable. If \\(f\\) is a local maximum \\(\\color{red}{\\text{(a local minimum)}}\\) at the position \\(x^‚àó = (x_1^‚àó ,\\ldots. , x_n ^‚àó)\\) has, so \\(f (x_1^‚àó , \\ldots , x_n^‚àó) ‚â• f (x_1,\\ldots , x_n)\\) \\(\\color{red}{f (x_1^‚àó , \\ldots , x_n^‚àó) \\leq f (x_1,\\ldots , x_n)}\\) for all points \\((x_1, \\ldots , x_n)\\) in a neighborhood of \\(x^‚àó\\) , then holds: \\[\\begin{align*}f_1(x_1^‚àó, \\ldots , x_n ^‚àó )&amp; = 0\\\\ f_2(x_1^‚àó, \\ldots , x_n^‚àó )&amp; = 0\\\\ &amp;~~~\\vdots\\\\ f_n(x_1^‚àó, \\ldots , x_n^‚àó)&amp; = 0. \\end{align*}\\] Graph (a) shows the tangent plane at the maximum of the function. Graph (b) shows the contour lines, i.e.¬†a view from above, where the function values are the same on each line. Example 11.1 (Price discrimination in monopoly) A monopolist sells an identical product in two separate markets. The inverse demand functions are: \\(p_1(x_1) = 12 ‚àí x_1\\) \\(p_2(x_2) = 10 ‚àí 2x_2\\), where \\(p_i\\) are the prices and \\(x_i\\) are the output quantities on the respective markets. The firm‚Äôs cost function is \\(C(x_1,x_2) = 1/2 (x_1 + x_2)^2.\\) The profit function is, therefore: \\(\\pi(x_1,x_2) = p_1x_1 + p_2x_2 ‚àí C(x_1,x_2) = 12x_1 ‚àí x_1^2 + 10x_2 ‚àí 2x_2^2 ‚àí 1/2 (x_1 + x_2)^2\\) . The first-order conditions are: \\(\\pi_1(x_1^‚àó,x_2^‚àó) = 12 ‚àí 2_1x^‚àó ‚àí (x_1^‚àó + x_2^‚àó ) = 0\\) \\(\\pi_2(x_1^‚àó,x_2^‚àó) = 10 ‚àí 4x_2^‚àó ‚àí (x_1^‚àó + x_2^‚àó ) = 0\\) These conditions show that in order to maximize profit, the marginal returns in both markets must necessarily be the same, since the marginal costs \\((x_1^‚àó + x_2^‚àó )\\) are identical. The profit-maximizing supply quantities are then: \\(x_1^‚àó = 3.57\\) and \\(x_2^‚àó = 1.29\\) (higher sales volume in market \\(1\\)). The optimal prices are \\(p_1^‚àó = 8.43\\) and \\(p_2^‚àó = 7.43\\) (the price is higher in market \\(1\\)). 11.2 Second-order conditions The first-order conditions are merely necessary but not sufficient for an extreme value. Second-order conditions allow checking whether a stationary point is a minimum or a maximum. Intuitively: If at a stationary point \\(x^‚àó\\) a small movement in any direction away from \\(x^‚àó\\) is accompanied by a decreasing (increasing) function value, then \\(f\\) at the position \\(x^‚àó\\) a local maximum (minimum). We consider the second-order conditions in the bivariate case (\\(n = 2\\)). Theorem 6.2 (Second order conditions) Let \\(f: \\mathbb{R} ^2 \\rightarrow \\mathbb{R}\\) be a function with continuous second partial derivatives in a neighborhood of the stationary point \\((x_1^‚àó , x_2^‚àó )\\). Let: \\[D = f_{x_1x_1} (x_1^‚àó ,x_2^‚àó ) f_{x_2x_2} (x_1^‚àó,x_2^‚àó ) ‚àí f_{x_1x_2}^2 (x_1^‚àó ,x_2^‚àó ) .\\] If \\(D &gt; 0\\) and \\(f_{x_1x_1} (x_1^‚àó ,x_2^‚àó ) &gt; 0\\), then \\(f\\) has \\((x_1^‚àó ,x_2 ^‚àó )\\) a local minimum. If \\(D &gt; 0\\) and \\(f_{x_1x_1} (x_1^‚àó ,x_2^‚àó ) &lt; 0\\), then \\(f\\) has \\((x_1^‚àó ,x_2 ^‚àó )\\) a local maximum. If \\(D &lt; 0\\), then \\(f\\) has a saddle point at \\((x_1^‚àó ,x_2^‚àó )\\). If \\(D = 0\\), then a conclusion is not possible. Interpretation: \\(D\\) is the determinant of the Hessian matrix. Example 11.2 (Stationary points I) We determine the local extrema and saddle points of the function: \\[f (x,y) = 3x^2 ‚àí 2xy + y^2 ‚àí 8y.\\] The first-order conditions are: \\(f_x=6x ‚àí 2y = 0\\) \\(f_y=‚àí2x + 2y ‚àí 8 = 0\\) Solution: \\(x^*=2, y^*=6.\\) Hence, there is a stationary point at \\((x,y) = (2,6)\\). The Hessian matrix i: \\[\\begin{bmatrix} f_{xx} \\ \\ f_{xy} \\\\ f_{xy} \\ \\ f_{yy} \\end{bmatrix} = \\begin{bmatrix} 6 \\ \\ \\ -2 \\\\ -2 \\ \\ \\ \\ 2\\end{bmatrix} \\] So \\(D = 6 \\cdot 2 ‚àí (‚àí2)^2 = 12 ‚àí 4 = 8 &gt; 0\\). Together with \\(f_{xx} = 6 &gt; 0\\) it follows that \\(f\\) has a local minimum at \\((2,6)\\). Example 11.3 (Stationary points II) We determine all local extrema and saddle points of: \\[f (x,y) = 4xy ‚àí x^4 ‚àí y^4.\\] The first order conditions are: \\(f_x=4y ‚àí 4x^3 = 0\\), so \\(y = x^3.\\) \\(f_y=4x ‚àí 4y^3 = 0\\), so \\(x = y^3\\) The stationary points are \\((0,0)\\), \\((1,1)\\), \\((‚àí1, ‚àí 1)\\). With \\(f_{xx} (x,y) = ‚àí12x^2\\) , \\(f_{yy} (x,y) = ‚àí12y^2\\) , \\(f_{xy} (x,y) = 4\\) follows: \\[\\begin{equation*} \\begin{array}[t]{c|cccc} \\hline % (x_0,y_0) &amp; f_{xx}(x_0,y_0) &amp; f_{yy}(x_0,y_0) &amp; f_{xy}(x_0,y_0) &amp; D=f_{xx} f_{yy} - f_{xy}^2\\\\\\hline (0,0) &amp; 0 &amp; 0 &amp; 4 &amp; -16\\\\ (1,1) &amp; -12 &amp; -12 &amp; 4 &amp; 128\\\\ (-1,-1) &amp; -12 &amp; -12 &amp; 4 &amp; 128\\\\\\hline \\end{array} \\end{equation*}\\] Hence \\(f\\) has local maxima at the positions \\((1,1)\\) and \\((‚àí1, ‚àí 1)\\); whereas \\((0,0)\\) is a saddle point. Generalizing to functions of \\(n\\) variables\\(^\\ast\\) To generalize to the case with \\(n\\) variables, note that \\(D\\) is the determinant of the Hessian matrix. In addition, \\(f_{xx}\\) corresponds to the determinant of the \\(1 √ó 1\\) sub-matrix of the Hessian matrix, which starts in row 1 and column 1. In the general case with \\(n\\) variables, the determinants of the \\(k √ó k\\) submatrices of the Hessian matrix together determine whether a stationary point corresponds to a maximum or a minimum. If the determinants are all positive, then the Hessian is positive definite and the function has a minimum at the stationary point. If the signs of the determinants alternate starting with a negative sign, then the Hessian matrix is negative definite and the function has a maximum at the stationary point. Exercise 11.1 (Extrema of multivariate function) For the function: \\[f(x,y)=x^2+ y^2+xy+x+5y\\] determine maximum and minimum points. Answer The partial derivatives are: \\[f_x(x,y)=2x+y+1,\\] \\[f_y(x,y)=2y+x+5.\\] Determine the zeros of the gradient: sets the two partial derivatives equal to zero, the system yields: \\[2x+y+1 = 0,\\] \\[x+2y+5=0.\\] Using Gaussian elimination (e.g.¬†multiply the second equation by \\(2\\) and subtract from the first equation): \\[2x+y+1 = 0,\\] \\[-\\] \\[2x+4y+10=0.\\] \\[\\leadsto -3y-9=0\\rightarrow y=-3.\\] Inserting it into the second equation gives: \\[x+2(-3)+5=0\\rightarrow x=1.\\] So the only zero point of the gradient is: \\[x=1,y=-3.\\] Check whether maximum or minimum: Hesse matrix: \\[H(x,y)=\\begin{pmatrix}2&amp;1\\\\1&amp;2\\end{pmatrix}\\] \\(\\det(H)\\) \\[\\det(H)=2\\cdot 2-1\\cdot1 = 1&gt;0\\] \\(f_{xx}\\) \\[f_{xx}(x,y)=2 &gt;0,\\] So the stationary point is the minimum of the function. 11.3 Optimization under constraints: Lagrange method We now turn to the following problem: \\[\\max_{x_1,x_2} f (x_1,x_2), \\text{(objective function)},\\] under the condition: \\[g(x_1,x_2) = 0, \\text{(constraint/ restriction)}.\\] Note: \\(f\\) is called objective function. \\(g = 0\\) is the constraint or restriction. Throughout we assume that \\(f\\) and \\(g\\) are continuously differentiable. (A function is continuously differentiable if it is differentiable and the derivative is continuous.) To solve the problem we introduce the new variable \\(\\lambda\\), the so-called Lagrange multiplier and form the Lagrange function: \\[\\mathcal{L} (x_1,x_2, \\lambda)=f(x_1,x_2)+ \\lambda g(x_1,x_2).\\] Now one determines the stationary points of \\(\\mathcal{L}\\) with respect to the variables \\(x_1,x_2\\) and \\(\\lambda\\) using the first-order conditions: \\[\\begin{align} \\frac{ \\partial \\mathcal{L} }{ \\partial x_1 } &amp;=f_1(x_1^*,x_2^*)+ \\lambda ^*g_1(x_1^*,x_2^*)=0 \\\\ \\frac{ \\partial \\mathcal{L} }{ \\partial x_2 } &amp;=f_2(x_1^*,x_2^*)+ \\lambda ^*g_2(x_1^*,x_2^*)=0 \\\\ \\frac{ \\partial \\mathcal{L} }{ \\partial \\lambda } &amp;=g(x_1^*,x_2^*)=0 \\end{align}\\] Note that \\(\\frac{ \\partial \\mathcal{L} }{ \\partial \\lambda } =0\\) delivers the constraint itself. In order for the Lagrange method to be applicable, the following must apply: \\(g_1(x_1^* ,x_2^*) \\neq 0\\) or \\(g_2(x_1^‚àó ,x_2^‚àó) \\neq 0.\\) That is, \\((x_1^‚àó ,x_2^‚àó )\\) is not a stationary point of \\(g.\\) Theorem 11.2 (Lagrangian method) Let \\(f\\) and \\(g\\) be continuously differentiable. Furthermore, let \\((x_1^‚àó, x_2^‚àó)\\) be a solution to the problem: \\[\\max_{x_1,x_2} f (x_1,x_2)\\] under the condition: \\[g(x_1,x_2) = 0.\\] Suppose further that \\((x_1^‚àó,x_2^‚àó)\\) is not a stationary point of \\(g\\). Then there exists a real number \\(\\lambda^‚àó\\) such that \\((x_1^‚àó, x_2^‚àó,\\lambda^‚àó)\\) is a stationary point of the Lagrangian: \\[\\mathcal{L} (x_1,x_2, \\lambda)=f(x_1,x_2)+ \\lambda g(x_1,x_2). \\] In other words, at the position \\((x_1^‚àó, x_2^‚àó,\\lambda^‚àó)\\) the following applies: \\(\\frac{ \\partial \\mathcal{L} }{ \\partial x_1 } =0\\), \\(\\frac{ \\partial \\mathcal{L} }{ \\partial x_2 } =0\\), \\(\\frac{ \\partial \\mathcal{L} }{ \\partial \\lambda } =0.\\) Example 11.4 (Optimization with Lagrangian method) We solve the following optimization problem: \\[\\max_{ x_1,x_2} x_1^{0.25} x_2^{0.75}\\] under the condition: \\[100 ‚àí 2x_1 ‚àí 4x_2 = 0.\\] The Lagrangian is: \\[\\mathcal{L} (x_1,x_2, \\lambda)= x_1^{0.25}x_2^{0.75} + \\lambda(100-2x_1-4x_2).\\] The first-order conditions are: \\[\\begin{align} 0.25x_1^{ ‚àí0.75} x_2{ 0.75} ‚àí 2\\lambda &amp;= 0\\\\ 0.75x_1^{ 0.25} x_2^{‚àí0.25} ‚àí 4\\lambda &amp;= 0\\\\ 100 ‚àí 2x_1 ‚àí 4x_2 &amp;= 0. \\end{align}\\] Eliminating \\(\\lambda\\) in the first two equations yields: \\(x_2 = 3/ 2 x_1\\) and substituting into the third equation gives \\(x_1^‚àó = 12.5\\) and \\(x_2^‚àó = 18.75.\\) For \\(\\lambda^‚àó\\) we get \\(\\lambda^‚àó = 0.25x_1^{ ‚àí0.75} x_2^{ 0.75} /2 = 0.75x_1^{ 0.25} x_2^{ ‚àí0 .25} /4 = 0.169425.\\) The green line contains all function values that satisfy the constraint. The red dot marks the maximum on the restriction set. In generall holds: The value \\(\\lambda^ ‚àó\\) is given as: \\[\\lambda ^*= -\\frac{ f_1(x_1^*,x_2^*) }{ g_1(x_1^*,x_2^*) } = -\\frac{ f_2(x_1^*,x_2^*) } { g_2(x_1^*,x_2^*) }.\\] The value of the Lagrange multiplier \\(\\lambda^ ‚àó\\) (multiplied by \\(‚àí1\\) if necessary - this depends on the form of the constraint, e.g.¬†\\(x+y-100=0\\) and \\(100-x-y=0\\)) corresponds to the sensitivity of the optimal solution to a slight relaxation of the constraint. This value is also called the shadow price of the constraint. The second-order conditions are set up using the Hessian matrix of the Lagrange function: \\[H(x,y,\\lambda)= \\begin{pmatrix} \\mathcal L_{11}&amp; \\mathcal L_{12}&amp; \\mathcal L_{13}\\\\ \\mathcal L_{21}&amp; \\mathcal L_{22}&amp; \\mathcal L_{23}\\\\ \\mathcal L_{31}&amp; \\mathcal L_{32}&amp; \\mathcal L_{33} \\end{pmatrix},\\] which consists of the second order partial derivatives of the Lagrange function. Plugging in the obtained values \\(x^*,y^*,\\lambda^*\\) gives: \\[H^*= \\begin{pmatrix} \\mathcal L^*_{11}&amp; \\mathcal L^*_{12}&amp; \\mathcal L^*_{13}\\\\ \\mathcal L^*_{21}&amp; \\mathcal L^*_{22}&amp; \\mathcal L^*_{23}\\\\ \\mathcal L^*_{31}&amp; \\mathcal L^*_{32}&amp; \\mathcal L^*_{33} \\end{pmatrix} = \\begin{bmatrix} f_{11}+ \\lambda^*g_{11} \\ \\ \\ f_{12}+ \\lambda ^*g_{12} \\ \\ \\ g_1 \\\\ f_{21}+ \\lambda^*g_{21} \\ \\ \\ f_{22}+ \\lambda ^*g_{22} \\ \\ \\ g_2 \\\\ g_1 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ g_2 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0 \\end{bmatrix}\\] The determinant of this \\(3 √ó 3\\) Hessian matrix is: \\[\\begin{align}\\det(H^*) &amp;= \\mathcal L^*_{11}(\\mathcal L^*_{22}\\mathcal L^*_{33}-\\mathcal L^*_{23}\\mathcal L^*_{32})-\\mathcal L^*_{12}(\\mathcal L^*_{21}\\mathcal L^*_{33}-\\mathcal L^*_{23}\\mathcal L^*_{31}) +\\mathcal L^*_{13}(\\mathcal L^*_{21}\\mathcal L^*_{32}-\\mathcal L^*_{22}\\mathcal L^*_{31}) \\\\ &amp;=\\mathcal L^*_{11} \\cdot (-\\mathcal L^*_{23}\\mathcal L^*_{32})-\\mathcal L^*_{12} \\cdot (-\\mathcal L^*_{23}\\mathcal L^*_{31}) + \\mathcal L^*_{13}(\\mathcal L^*_{21}\\mathcal L^*_{32}-\\mathcal L^*_{22}\\mathcal L^*_{31}) \\\\ &amp;=-(f_{11}+ \\lambda^*g_{11}) \\cdot g_2^2+ 2(f_{12}+ \\lambda ^*g_{12}) \\cdot g_2g_1-(f_{22}+ \\lambda^*g_{22})g_1^2. \\tag{11.1} \\end{align}\\] We will calculate the determinant using software (excel). Theorem 11.3 (Sufficient conditions for a local maximum/minimum) Let \\((x_1^‚àó, x_2^‚àó ,\\lambda^‚àó )\\) be a stationary point of the Lagrangian: \\[\\mathcal{L} (x_1,x_2, \\lambda)=f(x_1,x_2)+ \\lambda g(x_1,x_2).\\] Then: \\((x_1^‚àó ,x_2^‚àó )\\) is a local maximum of \\(f\\) under the constraint \\(g(x_1,x_2) = 0\\), if \\(\\det(H^‚àó ) &gt; 0\\); (ii)\\((x_1^‚àó ,x_2^‚àó )\\) is a local minimum of \\(f\\) under the constraint \\(g(x_1,x_2) = 0\\), if \\(\\det(H^‚àó ) &lt; 0\\). Example 11.5 (Optimization with the Lagrange method) We continue the previous example 11.4 . The Hessian matrix is: \\(H^*(x_1,x_2)= \\begin{bmatrix} - \\frac{0.1875x_2^{0.75}}{x_1^{1.75}} \\ \\ \\frac{0.1875}{x_1 ^{0.75}x_2^{0.25}} \\ \\ -2 \\\\ \\frac{0.1875}{x_1^{0.75}x_2^{0.25}} \\ \\ -\\frac{0 ,1875x_1^{0.25}}{x_2^{1.25}} \\ \\ -4 \\\\-2 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ -4 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0 \\end{bmatrix}\\) The determinant at \\((x_1^‚àó , x_2^‚àó , Œª^‚àó )\\) is \\(\\det(H^*) = 0.5783.\\)So \\(f\\) has a maximum at \\((x_1^‚àó , x_2^‚àó ).\\) Example 11.6 (utility maximization) We consider the example of utility maximization 1.1 from Chapter 1. The problem to be solved is: \\[\\max_{x,y} U(x,y) = \\max_{x,y} \\sqrt x + \\sqrt y,\\] under the condition \\(x + 3y = 100\\) (budget constraint). For the Lagrange method, we rewrite the budget constraint in the form \\(100 ‚àí x ‚àí 3y = 0\\). The Lagrangian is: \\[\\mathcal{L} (x,y, \\lambda)= \\sqrt{x} + \\sqrt{y} + \\lambda (100-x-3y).\\] The first order conditions (FOC) are: \\[\\begin{align} \\frac{ \\partial \\mathcal{L} }{ \\partial x } (x,y, \\lambda )= \\frac{1}{2 \\sqrt{x} } - \\lambda &amp;=0 \\\\ \\frac{ \\partial \\mathcal{L} }{ \\partial y } (x,y, \\lambda )= \\frac{1}{2 \\sqrt{y} } - 3\\lambda &amp;=0 \\\\ \\frac{ \\partial \\mathcal{L} }{ \\partial \\lambda } (x,y, \\lambda )= 100-x-3y =0. \\end{align}\\] The solution is \\(x^‚àó = 75\\), \\(y^‚àó = 100/12 = 8.3333\\) and \\(Œª^‚àó = 0.05774\\). Here \\(\\lambda^‚àó\\) expresses the marginal utility, i.e.¬†the rate of change of the optimal utility when the budget constraint is relaxed. The Hessian is: \\[H(x,y,\\lambda)=\\begin{pmatrix}\\frac{\\partial^2\\mathcal L}{\\partial x^2}&amp; \\frac{\\partial^2\\mathcal L}{\\partial x\\partial y}&amp; \\frac{\\partial^2\\mathcal L}{\\partial x\\partial\\lambda}\\\\ \\frac{\\partial^2\\mathcal L}{\\partial y\\partial x}&amp; \\frac{\\partial^2\\mathcal L}{\\partial y^2}&amp; \\frac{\\partial^2\\mathcal L}{\\partial y\\partial\\lambda}\\\\ \\frac{\\partial^2\\mathcal L}{\\partial \\lambda\\partial x}&amp; \\frac{\\partial^2\\mathcal L}{\\lambda\\partial y}&amp; \\frac{\\partial^2\\mathcal L}{\\partial\\lambda^2} \\end{pmatrix} = \\begin{pmatrix}-\\frac{1}{4x^{3/2}}&amp; 0&amp; -1\\\\ 0&amp; -\\frac{1}{4y^{3/2}}&amp; -3\\\\ -1&amp; -3&amp; 0 \\end{pmatrix} \\] Plugging in \\(x^‚àó = 75\\), \\(y^‚àó = 100/12 = 8,3333\\) and \\(Œª^‚àó = 0,05774\\) gives \\[H^*=\\begin{pmatrix}-0,0003849&amp; 0&amp; -1\\\\ 0&amp; -0,0103923&amp; -3\\\\ -1&amp; -3&amp; \\end{pmatrix} \\] The determinant of the Hessian (Formula (11.1)): \\[\\det(H^*) = \\frac{1}{4(x^*)^{3/2}} \\cdot (-3)^2 + \\frac{1}{4(y^*)^{3/2}} \\cdot (-1)^2 = 0,0139&gt;0,\\] or in Excel: so it is a maximum. Exercise 11.2 (Lagrangian method) Let \\(f(x,y)=3x+2y+5\\), where \\(x&gt;0\\), \\(y&gt;0\\) holds. Determine the point where the extreme of \\(f\\) is reached under the constraint \\(x^2+2y^2=275\\). Is the point a maximum or a minimum? Answer The Lagrange-Function: \\[\\mathcal L(x,y,\\lambda) = 3x+2y+5+\\lambda(275-x^2-2y^2).\\] The FOC: \\[\\begin{align}\\frac{ \\partial \\mathcal{L} }{ \\partial x } (x,y, \\lambda )&amp;= 3 - 2\\lambda\\cdot x =0 \\leadsto x=\\color{blue}{\\frac3{2\\lambda}} \\\\ \\frac{ \\partial \\mathcal{L} }{ \\partial y } (x,y, \\lambda )&amp;= 2-4\\lambda \\cdot y=0 \\leadsto y=\\frac2{4\\lambda} = \\color{red}{\\frac 1{2\\lambda} }\\\\ \\frac{ \\partial \\mathcal{L} }{ \\partial \\lambda } (x,y, \\lambda )&amp;= 275-x^2-2y^2 =0. \\end{align}\\] Plugging in the expressions for \\(x,y\\) from the first two euqations in the last one gives: \\[\\begin{align}275 - \\left(\\color{blue}{\\frac3{2\\lambda}}\\right)^2 - 2\\cdot \\left(\\color{red}{\\frac1{2\\lambda}}\\right)^2 &amp;=0\\\\ 275 - \\frac 9{4\\lambda^2} - \\frac 2{4\\lambda^2}&amp;=0\\\\ -\\frac{11}{4\\lambda^2}&amp;=-275\\\\ \\lambda^2&amp;=\\frac{-11}{-275\\cdot 4}=0,01=(0,1)^2\\\\ \\lambda^*&amp;=0,1. \\end{align}\\] Plugging in \\(\\lambda^*=0,1\\) in the expressions for \\(x,y\\) delivers: \\[x^*=\\color{blue}{\\frac3{2\\cdot 0,1}}=15\\text{ und } y^*=\\color{red}{\\frac 1{2\\cdot 0,1} }=5.\\] The Hessian is: \\[H(x,y,\\lambda)=\\begin{pmatrix}-2\\lambda&amp;0&amp;-2x\\\\0&amp;-4\\lambda&amp;-4y\\\\-2x&amp;-4y&amp;0\\end{pmatrix}\\] \\(H^*=H(x^*,y^*,\\lambda^*)\\) (plug in the calculated values for \\((x^*,y^*,\\lambda^*)\\) into the Hessian): \\[H^*=H(x^*,y^*,\\lambda^*)=\\begin{pmatrix}-0,20&amp;0&amp;-30\\\\0&amp;-0,4&amp;-20\\\\-30&amp;-20&amp;0\\end{pmatrix}\\] The determinant is (calculate with Excel): \\[\\det(H^*) = 440&gt;0\\] So, it is a maximum in \\((x^*,y^*,\\lambda^*)\\). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
